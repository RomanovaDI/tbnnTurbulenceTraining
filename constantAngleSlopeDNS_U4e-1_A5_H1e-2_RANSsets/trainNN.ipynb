{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network development for turbulence modeling in URANS simulations of non-Newtonian media slope flows"
   ]
  },
  {
   "attachments": {
    "NIIMexLinear.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URANS mathematical model:\n",
    "\\begin{equation}\n",
    "\t\\label{vof}\n",
    "\t\\left\\{\n",
    "\t\t\\begin{aligned}\n",
    "\t\t\t&\\boldsymbol{\\nabla} \\cdot \\bar{\\boldsymbol{u}} = 0,\\\\\n",
    "\t\t\t&\\frac{\\partial \\bar{\\alpha}}{\\partial t} + \\boldsymbol{\\nabla} \\cdot (\\bar{\\boldsymbol{u}} \\bar{\\alpha}) = 0,\\\\\n",
    "\t\t\t&\\frac{\\partial (\\rho \\bar{\\boldsymbol{u}})}{\\partial t} + \\boldsymbol{\\nabla} \\cdot (\\rho \\bar{\\boldsymbol{u}} \\bar{\\boldsymbol{u}}) = -\\boldsymbol{\\nabla} \\bar{p} + \\boldsymbol{\\nabla} \\cdot \\bar{\\boldsymbol{\\tau}} + \\rho \\bar{\\boldsymbol{f}}.\n",
    "\t\t\\end{aligned}\n",
    "\t\\right.\n",
    "\\end{equation}\n",
    "Here $\\bar{\\boldsymbol{u}}$ is the speed of the mixture, horizontal bar means Reynolds averaging, $\\bar{\\alpha}$ is the volume fraction of the selected phase, $\\bar{\\boldsymbol{\\tau}} = \\bar{\\boldsymbol{\\tau}}_{Re} + \\bar{\\boldsymbol{\\tau}}_m$ is the stress tensor calculated as sum of Reynolds stress tensor and viscous stress tensor, $\\bar{\\boldsymbol{\\tau}}_m = 2 \\mu \\bar{\\boldsymbol{s}}$ is the viscous stress tensor, which is a function of the strain rate tensor $\\bar{\\boldsymbol{s}} = 0.5 \\left[ \\boldsymbol{\\nabla} \\bar{\\boldsymbol{u}} + (\\boldsymbol{\\nabla} \\bar{\\boldsymbol{u}})^T\\right]$, $\\mu = \\nu \\rho$ is dynamic viscosityof a mixture which is calculated as a product of density and kinematic viscosity of mixture, $\\nu = \\nu_1 \\bar{\\alpha} + \\nu_0 (1 -\\bar{\\alpha})$ is the kinemsatic viscosity of mixture calculated according to the principle of the weighted average, $\\nu_0$ is a constant, $\\nu_1 = min (\\nu_*, (\\tau_* + K \\dot{\\gamma}^n) / \\dot{\\gamma})$ is Herschel-Bulkley reology ratio, $\\rho = \\rho_1 \\bar{\\alpha} + \\rho_0 (1 - \\bar{\\alpha})$ is the mixture density, $\\rho_0$ and $\\rho_1$ are constants, $\\bar{p}$ is the pressure, $\\bar{\\boldsymbol{f}}$ is the density of the body forces.\n",
    "\n",
    "The $\\bar{\\boldsymbol{\\tau}}_{Re}$ Reynolds stress tensor is calculetaed using Tensor Basis Neural Network (TBNN) according to the principle presented in the work of Pope [1]. It is presented as function of strain rate $\\bar{\\boldsymbol{s}} = 0.5 \\left[ \\boldsymbol{\\nabla} \\bar{\\boldsymbol{u}} + (\\boldsymbol{\\nabla} \\bar{\\boldsymbol{u}})^T\\right]$ and rotation rate $\\bar{\\boldsymbol{r}} = 0.5 \\left[ \\boldsymbol{\\nabla} \\bar{\\boldsymbol{u}} - (\\boldsymbol{\\nabla} \\bar{\\boldsymbol{u}})^T\\right]$ tensors, and 10 their isotropic combinations $T^i$ and 5 invariants $\\lambda_i$. Calculations performed for normalized tensors $\\bar{\\tau}_{Re}'$, $\\bar{\\boldsymbol{s}}'$, $\\bar{\\boldsymbol{r}}'$. The scaling parameters $U_0$, $h_0$, $\\rho$ used for normalization:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\label{norm}\n",
    "\t\\left\\{\n",
    "\t\t\\begin{aligned}\n",
    "\t\t\t&\\bar{\\boldsymbol{\\tau}}_{Re} = \\bar{\\boldsymbol{\\tau}}_{Re}' \\rho U_0 h_0,\\\\\n",
    "\t\t\t&\\bar{\\boldsymbol{s}} = \\bar{\\boldsymbol{s}}' U_0^2 / h_0,\\\\\n",
    "\t\t\t&\\bar{\\boldsymbol{r}} = \\bar{\\boldsymbol{r}}' U_0^2 / h_0.\n",
    "\t\t\\end{aligned}\n",
    "\t\\right.\n",
    "\\end{equation}\n",
    "\n",
    "In what follows, we omit the apostrophe symbol and keep in mind that we are considering normalized tensors.\n",
    "\n",
    "Normalized Reynolds stress tensor is\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\label{MLReynolds}\n",
    "\t\\bar{\\boldsymbol{\\tau}}_{Re} = \\sum\\limits_{n=1}^{10} g^{(n)} (\\lambda_1, ... , \\lambda_5) \\boldsymbol{T}^{(n)}.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\begin{aligned}\n",
    "\t\t&\\boldsymbol{T}^{(1)} = \\bar{\\boldsymbol{s}},\n",
    "\t\t&&\\boldsymbol{T}^{(6)} = \\bar{\\boldsymbol{r}}^2 \\bar{\\boldsymbol{s}} + \\bar{\\boldsymbol{s}} \\bar{\\boldsymbol{r}}^2 - \\frac{2}{3}\\boldsymbol{I} \\cdot Tr(\\bar{\\boldsymbol{s}} \\bar{\\boldsymbol{r}}^2),\\\\\n",
    "\t\t&\\boldsymbol{T}^{(2)} = \\bar{\\boldsymbol{s}} \\bar{\\boldsymbol{r}} - \\bar{\\boldsymbol{r}} \\bar{\\boldsymbol{s}},\n",
    "\t\t&&\\boldsymbol{T}^{(7)} = \\bar{\\boldsymbol{r}} \\bar{\\boldsymbol{s}} \\bar{\\boldsymbol{r}}^2 - \\bar{\\boldsymbol{r}}^2 \\bar{\\boldsymbol{s}} \\bar{\\boldsymbol{r}},\\\\\n",
    "\t\t&\\boldsymbol{T}^{(3)} = \\bar{\\boldsymbol{s}}^2 - \\frac{1}{3} \\boldsymbol{I} \\cdot Tr(\\bar{\\boldsymbol{s}}^2),\n",
    "\t\t&&\\boldsymbol{T}^{(8)} = \\bar{\\boldsymbol{s}} \\bar{\\boldsymbol{r}} \\bar{\\boldsymbol{s}}^2 - \\bar{\\boldsymbol{s}}^2 \\bar{\\boldsymbol{r}} \\bar{\\boldsymbol{s}},\\\\\n",
    "\t\t&\\boldsymbol{T}^{(4)} = \\bar{\\boldsymbol{r}}^2 - \\frac{1}{3}\\boldsymbol{I} \\cdot Tr(\\bar{\\boldsymbol{r}}^2),\n",
    "\t\t&&\\boldsymbol{T}^{(9)} = \\bar{\\boldsymbol{r}}^2 \\bar{\\boldsymbol{s}}^2 + \\bar{\\boldsymbol{s}}^2 \\bar{\\boldsymbol{r}}^2 - \\frac{2}{3} \\boldsymbol{I} \\cdot Tr(\\bar{\\boldsymbol{s}}^2 \\bar{\\boldsymbol{r}}^2),\\\\\n",
    "\t\t&\\boldsymbol{T}^{(5)} = \\bar{\\boldsymbol{r}} \\bar{\\boldsymbol{s}}^2 - \\bar{\\boldsymbol{s}}^2 \\bar{\\boldsymbol{r}},\n",
    "\t\t&&\\boldsymbol{T}^{(10)} = \\bar{\\boldsymbol{r}} \\bar{\\boldsymbol{s}}^2 \\bar{\\boldsymbol{r}}^2 - \\bar{\\boldsymbol{r}}^2 \\bar{\\boldsymbol{s}}^2 \\bar{\\boldsymbol{r}},\n",
    "\t\\end{aligned}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\t\\lambda_1 = Tr(\\bar{\\boldsymbol{s}}^2),\\ \\ \\ \\ \\lambda_2 = Tr(\\bar{\\boldsymbol{r}}^2),\\ \\ \\ \\ \\lambda_3 = Tr(\\bar{\\boldsymbol{s}}^3),\\ \\ \\ \\ \\lambda_4 = Tr(\\bar{\\boldsymbol{r}}^2 \\bar{\\boldsymbol{s}}),\\ \\ \\ \\ \\lambda_5 = Tr(\\bar{\\boldsymbol{r}}^2 \\bar{\\boldsymbol{s}}^2).\n",
    "\\end{equation}\n",
    "\n",
    "Calculations performed for turbulent flow in inclined chute with the rectangular cross-section. Scheme of flow is shown in figure below.\n",
    "\n",
    "<div>\n",
    "<img src=\"attachment:NIIMexLinear.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "In the considered flow\n",
    "\\begin{equation}\n",
    "    U_0 = 0.4\\ \\text{m}/\\text{s},\\ \\ \\ h_0 = 0.01\\ \\text{m},\\ \\ \\ \\theta = 25^\\circ,\\ \\ \\ L = 0.1\\ \\text{m}.\n",
    "\\end{equation}\n",
    "\n",
    "Reynolds number of flow is \n",
    "\\begin{equation}\n",
    "    \\text{Re} = U_0 h_0 / \\nu_{eff},\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nu_{eff} = \\frac{\\tau_* + K (U_0/h_0)^n}{\\rho (U_0 / h_0)}.\n",
    "\\end{equation}\n",
    "\n",
    "Constants in calculation are set as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nu_* = 10^7\\ \\text{m}^2/\\text{s},\\ \\ \\ \\tau_* = 2 \\cdot 10^{-3}\\ \\text{m}^2/\\text{s}^2,\\ \\ \\ K = 10^{-4}\\ \\text{m}^2/\\text{s},\\ \\ \\ n = 0.8,\\ \\ \\ \\rho = 100\\ \\text{kg}/\\text{m}^3.\n",
    "\\end{equation}\n",
    "\n",
    "So effective viscosity and Reynolds number are:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\nu_{eff} = 10^{-6}\\ \\text{m}^2/\\text{s},\\ \\ \\ \\text{Re} = 4000.\n",
    "\\end{equation}\n",
    "\n",
    "The mesh cell linear size must be $dx = \\frac{h_0}{\\text{Re}^{3/4}} = 2 \\cdot 10^{-5}$. Time step $dt = 5 \\cdot 10^{-5}$.\n",
    "\n",
    "Mesh size for computational domain size of 0.1x0.011x0.002 m$^3$ is $27.5 \\cdot 10^7$.\n",
    "\n",
    "[1] S. B. Pope. A more general effective-viscosity hypothesis.Journal of Fluid Mechanics,72(2):331–340, 1975."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above was global formulation for TBNN (Tensor Based Neural Network) with implemengtation into mathematical model. Now let's try to realize ML-turbulence model as a correction step for variables $\\bar{\\boldsymbol{u}}$, $\\bar{\\alpha}$, $\\bar{p}$.\n",
    "\n",
    "Will use tensors $\\boldsymbol{T}^{(i)}$, invariants $\\lambda_i$ and variables $\\bar{\\boldsymbol{u}}$, $\\bar{p}$, $\\bar{\\alpha}$ as a features of NN (Neural Network). As a targets will be the differenses between DNS and RANS values for $\\boldsymbol{u}$, $\\alpha$ and $p$.\n",
    "\n",
    "Let's start with importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\r\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/tensorflow/docs\n",
    "#!pip install -q -U keras-tuner\n",
    "#!pip install pydot\n",
    "#!pip install pydotplus\n",
    "#!pip install graphviz\n",
    "#!pip install pyyaml h5py\n",
    "#!pip install keras-tuner --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 16:14:16.479039: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 16:14:18.258374: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-23 16:14:18.675756: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-23 16:14:18.675802: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-23 16:14:18.899211: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-23 16:14:23.287575: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 16:14:23.287776: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-23 16:14:23.287793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "import tensorflow_docs.plots\n",
    "import keras_tuner as kt\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import subprocess as sp\n",
    "import fileinput as fi\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle\n",
    "#from IPython.display import set_matplotlib_formats\n",
    "#set_matplotlib_formats('svg')\n",
    "import matplotlib_inline.backend_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "import linecache\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Visualization tools for tensorflow_docs.\n",
    "\n",
    "Use this module for plotting and visualization code that is too long to inline\n",
    "into a notebook.\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "#COLOR_CYCLE = prop_cycle.by_key()['color']\n",
    "COLOR_CYCLE=['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a',\n",
    "             '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#8c564b', '#c49c94',\n",
    "             '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7', '#bcbd22', '#dbdb8d',\n",
    "             '#17becf', '#9edae5']\n",
    "\n",
    "def _smooth(values, std):\n",
    "    \"\"\"Smooths a list of values by convolving with a Gaussian distribution.\n",
    "\n",
    "    Assumes equal spacing.\n",
    "\n",
    "    Args:\n",
    "        values: A 1D array of values to smooth.\n",
    "        std: The standard deviation of the Gaussian distribution. The units are\n",
    "            array elements.\n",
    "\n",
    "    Returns:\n",
    "        The smoothed array.\n",
    "    \"\"\"\n",
    "    width = std * 4\n",
    "    x = np.linspace(-width, width, min(2 * width + 1, len(values)))\n",
    "    kernel = np.exp(-(x / 5)**2)\n",
    "\n",
    "    values = np.array(values)\n",
    "    weights = np.ones_like(values)\n",
    "\n",
    "    smoothed_values = np.convolve(values, kernel, mode='same')\n",
    "    smoothed_weights = np.convolve(weights, kernel, mode='same')\n",
    "\n",
    "    return smoothed_values / smoothed_weights\n",
    "\n",
    "\n",
    "class HistoryPlotter(object):\n",
    "    \"\"\"A class for plotting a named set of Keras-histories.\n",
    "\n",
    "    The class maintains colors for each key from plot to plot.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, metric=None, smoothing_std=None):\n",
    "        self.color_table = {}\n",
    "        self.metric = metric\n",
    "        self.smoothing_std = smoothing_std\n",
    "\n",
    "    def plot(self, histories, metric=None, smoothing_std=None, yMin=0, yMax=0, log=False):\n",
    "        \"\"\"Plots a {name: history} dictionary of Keras histories.\n",
    "\n",
    "        Colors are assigned to the name-key, and maintained from call to call.\n",
    "        Training metrics are shown as a solid line, validation metrics dashed.\n",
    "\n",
    "        Args:\n",
    "            histories: {name: history} a dictionary of Keras histories.\n",
    "            metric: which metric to plot from all the histories.\n",
    "            smoothing_std: the standard deviation of the smoothing kernel applied\n",
    "                before plotting. The units are in array-indices.\n",
    "        \"\"\"\n",
    "        if metric is None:\n",
    "            metric = self.metric\n",
    "        if smoothing_std is None:\n",
    "            smoothing_std = self.smoothing_std\n",
    "\n",
    "        yAv = np.empty(0)\n",
    "        yL = np.empty(0)\n",
    "        \n",
    "        for name, history in histories.items():\n",
    "            # Remember name->color associations.\n",
    "            if name in self.color_table:\n",
    "                color = self.color_table[name]\n",
    "            else:\n",
    "                color = COLOR_CYCLE[len(self.color_table) % len(COLOR_CYCLE)]\n",
    "                self.color_table[name] = color\n",
    "\n",
    "            train_value = history.history[metric]\n",
    "            if smoothing_std is not None:\n",
    "                train_value = _smooth(train_value, std=smoothing_std)\n",
    "\n",
    "            plt.plot(\n",
    "                history.epoch,\n",
    "                train_value,\n",
    "                color=color,\n",
    "                label=name.title())\n",
    "            \n",
    "            yAv = np.append(yAv, np.average(train_value))\n",
    "            yL = np.append(yL, np.asarray(train_value).min())\n",
    "        \n",
    "        yAv = yAv[np.isfinite(yAv)]\n",
    "        yL = yL[np.isfinite(yL)]\n",
    "        if yMin == 0:\n",
    "            yLimL = yL.min()\n",
    "        else:\n",
    "            yLimL = yMin\n",
    "        if yMax == 0:\n",
    "            yLimH = yAv.max()\n",
    "        else:\n",
    "            yLimH = yMax\n",
    "\n",
    "        if log:\n",
    "            plt.yscale('log')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel(metric.replace('_', ' ').title())\n",
    "        #plt.legend()\n",
    "        #fig.tight_layout()\n",
    "        #plt.subplots_adjust(top = 0.85)\n",
    "        plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
    "        #fig.savefig('pics/v_p_rho.png', dpi=300)\n",
    "\n",
    "        plt.ylim([yLimL,yLimH])\n",
    "        plt.xlim(\n",
    "            [0, max([history.epoch[-1] for name, history in histories.items()])])\n",
    "        plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeStepsList():\n",
    "    timeStepsList = np.loadtxt(\"timeStepsList.txt\", dtype=str)\n",
    "    index = np.argsort(timeStepsList.astype('float32'))\n",
    "    timeStepsList = timeStepsList[index]\n",
    "    #return list(timeStepsList[1:-2])\n",
    "    return list(timeStepsList[1:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTensor(fileName, folder, time, sz):\n",
    "    arr = pd.read_csv(folder+time+'/'+fileName[0],\n",
    "                      header=None,\n",
    "                      skiprows=23, \n",
    "                      nrows=sz, \n",
    "                      dtype=str)\n",
    "    arr.iloc[:,0] = arr.iloc[:,0].str.replace('[(,)]', '', regex=True)\n",
    "    arr = arr.iloc[:,0].str.split(expand=True)\n",
    "    arr.columns = [fileName[0]+'0', fileName[0]+'1', fileName[0]+'2', \n",
    "                   fileName[0]+'3', fileName[0]+'4', fileName[0]+'5', \n",
    "                   fileName[0]+'6', fileName[0]+'7', fileName[0]+'8']\n",
    "    arr = arr.astype('float32')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSymmTensor(fileName, folder, time, sz):\n",
    "    arr = pd.read_csv(folder+time+'/'+fileName[0], \n",
    "                      header=None, \n",
    "                      skiprows=23, \n",
    "                      nrows=sz, \n",
    "                      dtype=str)\n",
    "    arr.iloc[:,0] = arr.iloc[:,0].str.replace('[(,)]', '', regex=True)\n",
    "    arr = arr.iloc[:,0].str.split(expand=True)\n",
    "    arr.columns = [fileName[0]+'0', fileName[0]+'1', fileName[0]+'2',\n",
    "                   fileName[0]+'3', fileName[0]+'4', fileName[0]+'5', \n",
    "                   fileName[0]+'6', fileName[0]+'7', fileName[0]+'8']\n",
    "    arr = arr.astype('float32')\n",
    "    return arr[[fileName[0]+'0', fileName[0]+'1', fileName[0]+'2', fileName[0]+'4',\\\n",
    "                   fileName[0]+'5', fileName[0]+'8']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSkewSymmTensor(fileName, folder, time, sz):\n",
    "    arr = pd.read_csv(folder+time+'/'+fileName[0], \n",
    "                      header=None, \n",
    "                      skiprows=23, \n",
    "                      nrows=sz, \n",
    "                      dtype=str)\n",
    "    arr.iloc[:,0] = arr.iloc[:,0].str.replace('[(,)]', '', regex=True)\n",
    "    arr = arr.iloc[:,0].str.split(expand=True)\n",
    "    arr.columns = [fileName[0]+'0', fileName[0]+'1', fileName[0]+'2', \n",
    "                   fileName[0]+'3', fileName[0]+'4', fileName[0]+'5', \n",
    "                   fileName[0]+'6', fileName[0]+'7', fileName[0]+'8']\n",
    "    arr = arr.astype('float32')\n",
    "    return arr[[fileName[0]+'1', fileName[0]+'2', fileName[0]+'5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readVector(fileName, folder, time, sz):\n",
    "    arr = pd.read_csv(folder+time+'/'+fileName[0], \n",
    "                      header=None, \n",
    "                      skiprows=23, \n",
    "                      nrows=sz, \n",
    "                      dtype=str)\n",
    "    arr.iloc[:,0] = arr.iloc[:,0].str.replace('[(,)]', '', regex=True)\n",
    "    arr = arr.iloc[:,0].str.split(expand=True)\n",
    "    arr.columns = [fileName[0]+'0', fileName[0]+'1', fileName[0]+'2']\n",
    "    arr = arr.astype('float32')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readScalar(fileName, folder, time, sz):\n",
    "    arr = pd.read_csv(folder+time+'/'+fileName[0], \n",
    "                      header=None, \n",
    "                      skiprows=23, \n",
    "                      nrows=sz, \n",
    "                      dtype=str)\n",
    "    arr.columns = [fileName[0]]\n",
    "    arr = arr.astype('float32')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTarget(data):\n",
    "    data['dU0'] = data['ref/U0'] - data['res/U0']\n",
    "    data['dU1'] = data['ref/U1'] - data['res/U1']\n",
    "    data['dU2'] = data['ref/U2'] - data['res/U2']\n",
    "    data['dAW'] = data['ref/alpha.water'] - data['res/alpha.water']\n",
    "    data['dp'] = data['ref/p_rgh'] - data['res/p_rgh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInit(fullData):\n",
    "    data = fullData[['dU0', 'dU1', 'dU2', 'dAW', 'dp']].copy()\n",
    "    data['dU0'] = fullData['dU0']# / fullData['res/Uref0']\n",
    "    data['dU1'] = fullData['dU1']# / fullData['res/Uref1']\n",
    "    data['dU2'] = fullData['dU2']# / fullData['res/Uref2']\n",
    "    data['dAW'] = fullData['dAW']# / fullData['res/AWref']\n",
    "    data['dp'] = fullData['dp']# / fullData['res/p_rghref']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparePrediction(dataPredicted, fullData):\n",
    "    data = dataPredicted.copy()\n",
    "    data['dU0'] = (fullData['dU0'] - dataPredicted['dU0'])# / fullData['ref/U0']\n",
    "    data['dU1'] = (fullData['dU1'] - dataPredicted['dU1'])# / fullData['ref/U1']\n",
    "    data['dU2'] = (fullData['dU2'] - dataPredicted['dU2'])# / fullData['ref/U2']\n",
    "    data['dAW'] = (fullData['dAW'] - dataPredicted['dAW'])# / fullData['ref/alpha.water']\n",
    "    data['dp'] = (fullData['dp'] - dataPredicted['dp'])# / fullData['ref/p_rgh']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formDataset(TSL, TSLlen, folder, FsScalars, FsVectors, FsTensors, FsSymmTensors, \\\n",
    "                FsSkewSymmTensors, size):\n",
    "    data = pd.DataFrame()\n",
    "    for time in TSL:\n",
    "        #if TSLlen == 1:\n",
    "        #    time = TSL\n",
    "        kwargs = {'folder':folder, 'time':time, 'sz':size}\n",
    "        scalars = FsScalars.apply(readScalar, axis=1, **kwargs)\n",
    "        vectors = FsVectors.apply(readVector, axis=1, **kwargs)\n",
    "        tensors = FsTensors.apply(readTensor, axis=1, **kwargs)\n",
    "        symmTensors = FsSymmTensors.apply(readSymmTensor, axis=1, **kwargs)\n",
    "        skewSymmTensors = FsSkewSymmTensors.apply(readSkewSymmTensor, axis=1, **kwargs)\n",
    "        tmp = pd.concat(\\\n",
    "                        list(scalars[:])+\\\n",
    "                        list(vectors[:])+\\\n",
    "                        list(tensors[:])+\\\n",
    "                        list(symmTensors[:])+\\\n",
    "                        list(skewSymmTensors[:]), axis=1)\n",
    "        #data = data.append(tmp, ignore_index=True)\n",
    "        data = pd.concat([data, tmp], ignore_index=True)\n",
    "        prepareTarget(data)\n",
    "        if TSLlen == 1:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePredictionOld(arr, arrType, time, folder, fileName):\n",
    "    sp.run('mkdir -p '+folder+time+'/pred', shell=True, check=True)\n",
    "    sp.run('cp '+folder+time+'/patterns/'+fileName+'PatternBeginning '+folder+time+'/pred/'+ fileName,\n",
    "           shell=True, check=True)\n",
    "    with open(folder+time+'/pred/'+fileName, 'a') as f:\n",
    "        f.write(str(len(arr))+'\\n(\\n')\n",
    "    with fi.FileInput(folder+time+'/pred/'+fileName, inplace=True) as file:\n",
    "        for line in file:\n",
    "            print(line.replace('folderName', '\"'+time+'\"'), end='')\n",
    "    with fi.FileInput(folder+time+'/pred/'+fileName, inplace=True) as file:\n",
    "        for line in file:\n",
    "            print(line.replace('fieldName', fileName), end='')\n",
    "    if arrType == 'vector':\n",
    "        arr = arr.astype(str)\n",
    "        arr = '( '+arr.iloc[:,0]+' '+arr.iloc[:,1]+' '+arr.iloc[:,2]+' )'\n",
    "    elif arrType == 'scalar':\n",
    "        arr = arr.astype(str)\n",
    "    arr.to_csv(folder+time+'/pred/'+fileName, mode='a', index=False, header=False)\n",
    "    with open(folder+time+'/pred/'+fileName, 'a') as\\\n",
    "        fout, fi.input(folder+time+'/'+'patterns/'+fileName+'PatternEnding') as fin:\n",
    "            for line in fin:\n",
    "                fout.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePrediction(arr, arrType, time, folder, fileName):\n",
    "    sp.run('mkdir -p '+folder+time+'/pred', shell=True, check=True)\n",
    "    #sp.run('cp '+folder+time+'/res/'+fileName+' '+folder+time+'/pred/'+ fileName,\\\n",
    "    #       shell=True, check=True)\n",
    "    cellnum = int(linecache.getline(folder+time+'/pred/'+ fileName, 22))\n",
    "    if cellnum != len(arr):\n",
    "        printf('Cell number error')\n",
    "    ind = 22\n",
    "    #for i in range(ind):\n",
    "    with open(folder+time+'/'+time+'/'+fileName, 'a') as f:\n",
    "        f.write(str(len(arr))+'\\n(\\n')\n",
    "    with fi.FileInput(folder+time+'/'+time+'/'+fileName, inplace=True) as file:\n",
    "        for line in file:\n",
    "            print(line.replace('folderName', '\"'+time+'\"'), end='')\n",
    "    with fi.FileInput(folder+time+'/'+time+'/'+fileName, inplace=True) as file:\n",
    "        for line in file:\n",
    "            print(line.replace('fieldName', fileName), end='')\n",
    "    if arrType == 'vector':\n",
    "        arr = arr.astype(str)\n",
    "        arr = '( '+arr.iloc[:,0]+' '+arr.iloc[:,1]+' '+arr.iloc[:,2]+' )'\n",
    "    elif arrType == 'scalar':\n",
    "        arr = arr.astype(str)\n",
    "    arr.to_csv(folder+time+'/'+time+'/'+fileName, mode='a', index=False, header=False)\n",
    "    with open(folder+time+'/'+time+'/'+fileName, 'a') as\\\n",
    "        fout, fi.input(folder+time+'/'+'patterns/'+fileName+'PatternEnding') as fin:\n",
    "            for line in fin:\n",
    "                fout.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below all features listed. alpha.water is $\\bar{\\alpha}$, 'alpha.water', 'U' and 'p_rgh' are initial values. Parameters from res/ folder are calculated without turbulence model using base interFoam solver. 'Uref', 'AWref' and 'p_rghref' are reference values calculated using DNS data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MLturbRANSfolder = 'TIF'\n",
    "KEturbRANSfolder = 'KEIF'\n",
    "KWturbRANSfolder = 'KWIF'\n",
    "deltaT = 1e-05\n",
    "size = 37500#300000\n",
    "FsScalarsLabels = [\\\n",
    "    ['init/alpha.water'], ['res/alpha.water'], ['ref/alpha.water'], ['init/p_rgh'], ['res/p_rgh'],\\\n",
    "    ['ref/p_rgh'], ['res/I0'], ['res/I1'], ['res/I2'], ['res/I3'], ['res/I4'],\\\n",
    "    ['res/magGradP'], ['res/magGradAW'], ['res/inv1GradU'], ['res/inv2GradU']\\\n",
    "    ]\n",
    "FsScalars = pd.DataFrame(FsScalarsLabels)\n",
    "FsVectorLabels = [['init/U'], ['res/U'], ['ref/U'], ['res/gradP'], ['res/gradAW']]\n",
    "FsVectors = pd.DataFrame(FsVectorLabels)\n",
    "FsTensorLabels = [['res/gradU']]\n",
    "FsTensors = pd.DataFrame(FsTensorLabels)\n",
    "FsSymmTensorsLabels = [\\\n",
    "    ['res/T0'], ['res/T1'], ['res/T2'], ['res/T3'], ['res/T4'], ['res/T5'], \\\n",
    "    ['res/T6'], ['res/T7'], ['res/T8'], ['res/T9']\\\n",
    "    ]\n",
    "FsSymmTensors = pd.DataFrame(FsSymmTensorsLabels)\n",
    "FsSkewSymmTensorsLabels = [['res/rotationRateTensor']]\n",
    "FsSkewSymmTensors = pd.DataFrame(FsSkewSymmTensorsLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FsScalarsTestLabels = [\\\n",
    "    ['init/alpha.water'], ['res/alpha.water'], ['ref/alpha.water'], ['init/p_rgh'], ['res/p_rgh'],\\\n",
    "    ['ref/p_rgh']]\n",
    "FsScalarsTest = pd.DataFrame(FsScalarsTestLabels)\n",
    "FsVectorTestLabels = [['res/U'], ['ref/U']]\n",
    "FsVectorsTest = pd.DataFrame(FsVectorTestLabels)\n",
    "FsTensorTestLabels = []\n",
    "FsTensorsTest = pd.DataFrame(FsTensorTestLabels)\n",
    "FsSymmTensorsTestLabels = []\n",
    "FsSymmTensorsTest = pd.DataFrame(FsSymmTensorsTestLabels)\n",
    "FsSkewSymmTensorsTestLabels = []\n",
    "FsSkewSymmTensorsTest = pd.DataFrame(FsSkewSymmTensorsTestLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_labels = ['dU0', 'dU1', 'dU2', 'dAW', 'dp']\n",
    "tensor_labels = [\\\n",
    "    'res/T00', 'res/T01', 'res/T02', 'res/T04', 'res/T05', 'res/T08',\\\n",
    "    'res/T10', 'res/T11', 'res/T12', 'res/T14', 'res/T15', 'res/T18',\\\n",
    "    'res/T20', 'res/T21', 'res/T22', 'res/T24', 'res/T25', 'res/T28',\\\n",
    "    'res/T30', 'res/T31', 'res/T32', 'res/T34', 'res/T35', 'res/T38',\\\n",
    "    'res/T40', 'res/T41', 'res/T42', 'res/T44', 'res/T45', 'res/T48',\\\n",
    "    'res/T50', 'res/T51', 'res/T52', 'res/T54', 'res/T55', 'res/T58',\\\n",
    "    'res/T60', 'res/T61', 'res/T62', 'res/T64', 'res/T65', 'res/T68',\\\n",
    "    'res/T70', 'res/T71', 'res/T72', 'res/T74', 'res/T75', 'res/T78',\\\n",
    "    'res/T80', 'res/T81', 'res/T82', 'res/T84', 'res/T85', 'res/T88',\\\n",
    "    'res/T90', 'res/T91', 'res/T92', 'res/T94', 'res/T95', 'res/T98',\\\n",
    "    'res/rotationRateTensor1', 'res/rotationRateTensor2', 'res/rotationRateTensor5',\n",
    "    'res/gradU0', 'res/gradU1', 'res/gradU2', 'res/gradU3', 'res/gradU4',\\\n",
    "    'res/gradU5', 'res/gradU6', 'res/gradU7', 'res/gradU8']\n",
    "grad_labels = [\\\n",
    "    'res/gradP0', 'res/gradP1', 'res/gradP2', 'res/gradAW0', 'res/gradAW1', 'res/gradAW2',\\\n",
    "    'res/gradU0', 'res/gradU1', 'res/gradU2', 'res/gradU3', 'res/gradU4', 'res/gradU5',\\\n",
    "    'res/gradU6', 'res/gradU7', 'res/gradU8']\n",
    "vector_labels = ['init/U0', 'init/U1', 'init/U2', 'res/U0', 'res/U1', 'res/U2']\n",
    "param_labels = ['init/alpha.water', 'init/p_rgh', 'res/p_rgh', 'res/alpha.water']\n",
    "invar_labels = ['res/I0', 'res/I1', 'res/I2', 'res/I3', 'res/I4',\\\n",
    "    'res/magGradP', 'res/magGradAW', 'res/inv1GradU', 'res/inv2GradU']\n",
    "long_input_labels = invar_labels\n",
    "short_input_labels = tensor_labels + grad_labels + vector_labels +\\\n",
    "                    param_labels\n",
    "features_labels = long_input_labels + short_input_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(time, MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "#                         FsSymmTensors, FsSkewSymmTensors, size, \n",
    "#                           short_input_labels, long_input_labels, target_labels):\n",
    "#     trainData = formDataset([time], 1, MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "#                         FsSymmTensors, FsSkewSymmTensors, size)\n",
    "#     print('data was loaded\\n')\n",
    "#     trainData.sample(frac=1)\n",
    "#     train_target = trainData.loc[:, target_labels]\n",
    "#     train_features_short = trainData.loc[:, short_input_labels]\n",
    "#     train_features_long = trainData.loc[:, long_input_labels]\n",
    "#     return ([train_features_long, train_features_short], train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batch_generator(mode, MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "#                         FsSymmTensors, FsSkewSymmTensors, size, \n",
    "#                        short_input_labels, long_input_labels, target_labels):\n",
    "#     TSL = timeStepsList()\n",
    "#     print(\"TSL\\n\")\n",
    "#     print(TSL)\n",
    "#     print(\"\\n\")\n",
    "#     print(\"mode: \", mode, \"\\n\")\n",
    "#     if (mode == 'train'):\n",
    "#         TSL = TSL[:2]\n",
    "#     #elif (mode == 'validation'):\n",
    "#     #    TSL = TSL[5]\n",
    "#     elif (mode == 'test'):\n",
    "#         TSL = TSL[-2:]\n",
    "#     print(TSL, \"\\n\")\n",
    "    \n",
    "#     idx = -1\n",
    "#     while True: \n",
    "#         if idx < len(TSL):\n",
    "#             idx += 1\n",
    "#         else:\n",
    "#             idx = 0\n",
    "#         yield load_data(TSL[idx], MLturbRANSfolder, FsScalars, FsVectors, FsTensors,  \n",
    "#                         FsSymmTensors, FsSkewSymmTensors, size, \n",
    "#                         short_input_labels, long_input_labels, target_labels)\n",
    "#         print(idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_batch_generator = batch_generator('train', MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "#                        FsSymmTensors, FsSkewSymmTensors, size, \n",
    "#                       short_input_labels, long_input_labels, target_labels)\n",
    "#validation_batch_generator = batch_generator('validation', MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "#                        FsSymmTensors, FsSkewSymmTensors, size, \n",
    "#                       short_input_labels, long_input_labels, target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSL = np.asarray(timeStepsList())\n",
    "TSLlen = len(TSL)\n",
    "train_ind = np.concatenate([np.arange(0, 3, dtype=int), np.arange(4, TSLlen-1,  dtype=int)])\n",
    "testCenterData_ind = np.asarray([3])\n",
    "testLastData_ind = np.asarray([TSLlen-1])\n",
    "#TSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.8 s, sys: 2.8 s, total: 58.6 s\n",
      "Wall time: 59.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainData = formDataset(TSL[train_ind], len(TSL[train_ind]), MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "                        FsSymmTensors, FsSkewSymmTensors, size)\n",
    "#valData = formDataset([TSL[5]], 1, MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "#                        FsSymmTensors, FsSkewSymmTensors, size)\n",
    "#testData = formDataset(testTSL, len(testTSL), MLturbRANSfolder, FsScalars, FsVectors, \n",
    "#                       FsTensors, FsSymmTensors, FsSkewSymmTensors, size)\n",
    "testCenterData = formDataset(TSL[testCenterData_ind], 1, MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "                        FsSymmTensors, FsSkewSymmTensors, size)\n",
    "testLastData = formDataset(TSL[testLastData_ind], 1, MLturbRANSfolder, FsScalarsTest, FsVectorsTest,\n",
    "                           FsTensorsTest, FsSymmTensorsTest, FsSkewSymmTensorsTest, size)\n",
    "\n",
    "#testKEData = formDataset(testTSL, len(testTSL), KEturbRANSfolder, ResFsScalars, ResFsVectors,\n",
    "#                         ResFsTensors, ResFsSymmTensors, ResFsSkewSymmTensors, size)\n",
    "testKECenterData = formDataset(TSL[testCenterData_ind], 1, MLturbRANSfolder, FsScalarsTest, FsVectorsTest,\n",
    "                               FsTensorsTest, FsSymmTensorsTest, FsSkewSymmTensorsTest, size)\n",
    "testKELastData = formDataset(TSL[testLastData_ind], 1, MLturbRANSfolder, FsScalarsTest, FsVectorsTest,\n",
    "                             FsTensorsTest, FsSymmTensorsTest, FsSkewSymmTensorsTest, size)\n",
    "\n",
    "#testKWData = formDataset(testTSL, len(testTSL), KWturbRANSfolder, ResFsScalars, ResFsVectors,\n",
    "#                         ResFsTensors, ResFsSymmTensors, ResFsSkewSymmTensors, size)\n",
    "testKWCenterData = formDataset(TSL[testCenterData_ind], 1, MLturbRANSfolder, FsScalarsTest, FsVectorsTest,\n",
    "                               FsTensorsTest, FsSymmTensorsTest, FsSkewSymmTensorsTest, size)\n",
    "testKWLastData = formDataset(TSL[testLastData_ind], 1, MLturbRANSfolder, FsScalarsTest, FsVectorsTest,\n",
    "                             FsTensorsTest, FsSymmTensorsTest, FsSkewSymmTensorsTest, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.10004'], dtype='<U7')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TSL[testCenterData_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>init/alpha.water</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>3.339814e-01</td>\n",
       "      <td>0.467691</td>\n",
       "      <td>-7.999938e-09</td>\n",
       "      <td>7.687532e-34</td>\n",
       "      <td>5.704928e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res/alpha.water</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>3.340204e-01</td>\n",
       "      <td>0.467671</td>\n",
       "      <td>-3.575929e-28</td>\n",
       "      <td>2.042943e-32</td>\n",
       "      <td>6.133118e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref/alpha.water</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>3.339814e-01</td>\n",
       "      <td>0.467691</td>\n",
       "      <td>-7.999938e-09</td>\n",
       "      <td>7.687532e-34</td>\n",
       "      <td>5.704928e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init/p_rgh</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>-2.028101e+01</td>\n",
       "      <td>66.111633</td>\n",
       "      <td>-3.628040e+02</td>\n",
       "      <td>-2.283010e-01</td>\n",
       "      <td>5.770228e-04</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>85.767517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res/p_rgh</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>-2.632509e+01</td>\n",
       "      <td>85.860275</td>\n",
       "      <td>-1.049436e+03</td>\n",
       "      <td>-8.408502e+00</td>\n",
       "      <td>-2.570473e-02</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>613.136536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dU0</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>-1.623830e-04</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>-4.131871e-01</td>\n",
       "      <td>-1.624823e-04</td>\n",
       "      <td>-9.298325e-06</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.051517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dU1</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>-6.552331e-07</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>-7.560493e-02</td>\n",
       "      <td>-6.500954e-05</td>\n",
       "      <td>-3.995976e-07</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.056412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dU2</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>1.705530e-05</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>-5.742306e-02</td>\n",
       "      <td>-1.246966e-04</td>\n",
       "      <td>2.437085e-05</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.201294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dAW</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>-3.333305e-05</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>-2.780432e-02</td>\n",
       "      <td>-1.851791e-34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>6.047501e+00</td>\n",
       "      <td>63.704384</td>\n",
       "      <td>-7.789141e+02</td>\n",
       "      <td>-1.360654e-02</td>\n",
       "      <td>2.051947e-02</td>\n",
       "      <td>0.594414</td>\n",
       "      <td>1108.751221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count          mean        std           min  \\\n",
       "init/alpha.water  150000.0  3.339814e-01   0.467691 -7.999938e-09   \n",
       "res/alpha.water   150000.0  3.340204e-01   0.467671 -3.575929e-28   \n",
       "ref/alpha.water   150000.0  3.339814e-01   0.467691 -7.999938e-09   \n",
       "init/p_rgh        150000.0 -2.028101e+01  66.111633 -3.628040e+02   \n",
       "res/p_rgh         150000.0 -2.632509e+01  85.860275 -1.049436e+03   \n",
       "...                    ...           ...        ...           ...   \n",
       "dU0               150000.0 -1.623830e-04   0.004841 -4.131871e-01   \n",
       "dU1               150000.0 -6.552331e-07   0.001708 -7.560493e-02   \n",
       "dU2               150000.0  1.705530e-05   0.003400 -5.742306e-02   \n",
       "dAW               150000.0 -3.333305e-05   0.000966 -2.780432e-02   \n",
       "dp                150000.0  6.047501e+00  63.704384 -7.789141e+02   \n",
       "\n",
       "                           25%           50%       75%          max  \n",
       "init/alpha.water  7.687532e-34  5.704928e-10  1.000000     1.000001  \n",
       "res/alpha.water   2.042943e-32  6.133118e-10  1.000000     1.000000  \n",
       "ref/alpha.water   7.687532e-34  5.704928e-10  1.000000     1.000001  \n",
       "init/p_rgh       -2.283010e-01  5.770228e-04  0.023684    85.767517  \n",
       "res/p_rgh        -8.408502e+00 -2.570473e-02  0.016261   613.136536  \n",
       "...                        ...           ...       ...          ...  \n",
       "dU0              -1.624823e-04 -9.298325e-06  0.000094     0.051517  \n",
       "dU1              -6.500954e-05 -3.995976e-07  0.000070     0.056412  \n",
       "dU2              -1.246966e-04  2.437085e-05  0.000189     0.201294  \n",
       "dAW              -1.851791e-34  0.000000e+00  0.000000     0.023367  \n",
       "dp               -1.360654e-02  2.051947e-02  0.594414  1108.751221  \n",
       "\n",
       "[107 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>init/alpha.water</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>3.339851e-01</td>\n",
       "      <td>0.467747</td>\n",
       "      <td>-7.999938e-09</td>\n",
       "      <td>7.687532e-34</td>\n",
       "      <td>5.704928e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res/alpha.water</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>3.340192e-01</td>\n",
       "      <td>0.467718</td>\n",
       "      <td>-3.575929e-28</td>\n",
       "      <td>2.042943e-32</td>\n",
       "      <td>6.133118e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref/alpha.water</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>3.339851e-01</td>\n",
       "      <td>0.467747</td>\n",
       "      <td>-7.999938e-09</td>\n",
       "      <td>7.687532e-34</td>\n",
       "      <td>5.704928e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init/p_rgh</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>-2.028061e+01</td>\n",
       "      <td>66.144440</td>\n",
       "      <td>-3.628040e+02</td>\n",
       "      <td>-2.283010e-01</td>\n",
       "      <td>5.770228e-04</td>\n",
       "      <td>0.023684</td>\n",
       "      <td>85.767517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res/p_rgh</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>-2.632704e+01</td>\n",
       "      <td>85.884491</td>\n",
       "      <td>-1.049436e+03</td>\n",
       "      <td>-8.408502e+00</td>\n",
       "      <td>-2.570473e-02</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>613.136536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dU0</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>-1.623808e-04</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>-4.131871e-01</td>\n",
       "      <td>-1.624823e-04</td>\n",
       "      <td>-9.298325e-06</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.051517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dU1</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>-6.552274e-07</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>-7.560493e-02</td>\n",
       "      <td>-6.500954e-05</td>\n",
       "      <td>-3.995976e-07</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.056412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dU2</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>1.705526e-05</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>-5.742306e-02</td>\n",
       "      <td>-1.246966e-04</td>\n",
       "      <td>2.437085e-05</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.201294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dAW</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>-3.333308e-05</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>-2.780432e-02</td>\n",
       "      <td>-1.851791e-34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dp</th>\n",
       "      <td>37500.0</td>\n",
       "      <td>6.047902e+00</td>\n",
       "      <td>63.672375</td>\n",
       "      <td>-7.789141e+02</td>\n",
       "      <td>-1.360654e-02</td>\n",
       "      <td>2.051947e-02</td>\n",
       "      <td>0.594414</td>\n",
       "      <td>1108.751221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count          mean        std           min  \\\n",
       "init/alpha.water  37500.0  3.339851e-01   0.467747 -7.999938e-09   \n",
       "res/alpha.water   37500.0  3.340192e-01   0.467718 -3.575929e-28   \n",
       "ref/alpha.water   37500.0  3.339851e-01   0.467747 -7.999938e-09   \n",
       "init/p_rgh        37500.0 -2.028061e+01  66.144440 -3.628040e+02   \n",
       "res/p_rgh         37500.0 -2.632704e+01  85.884491 -1.049436e+03   \n",
       "...                   ...           ...        ...           ...   \n",
       "dU0               37500.0 -1.623808e-04   0.004842 -4.131871e-01   \n",
       "dU1               37500.0 -6.552274e-07   0.001708 -7.560493e-02   \n",
       "dU2               37500.0  1.705526e-05   0.003400 -5.742306e-02   \n",
       "dAW               37500.0 -3.333308e-05   0.000967 -2.780432e-02   \n",
       "dp                37500.0  6.047902e+00  63.672375 -7.789141e+02   \n",
       "\n",
       "                           25%           50%       75%          max  \n",
       "init/alpha.water  7.687532e-34  5.704928e-10  1.000000     1.000001  \n",
       "res/alpha.water   2.042943e-32  6.133118e-10  1.000000     1.000000  \n",
       "ref/alpha.water   7.687532e-34  5.704928e-10  1.000000     1.000001  \n",
       "init/p_rgh       -2.283010e-01  5.770228e-04  0.023684    85.767517  \n",
       "res/p_rgh        -8.408502e+00 -2.570473e-02  0.016261   613.136536  \n",
       "...                        ...           ...       ...          ...  \n",
       "dU0              -1.624823e-04 -9.298325e-06  0.000094     0.051517  \n",
       "dU1              -6.500954e-05 -3.995976e-07  0.000070     0.056412  \n",
       "dU2              -1.246966e-04  2.437085e-05  0.000189     0.201294  \n",
       "dAW              -1.851791e-34  0.000000e+00  0.000000     0.023367  \n",
       "dp               -1.360654e-02  2.051947e-02  0.594414  1108.751221  \n",
       "\n",
       "[107 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCenterData.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = trainData.loc[:, target_labels]\n",
    "train_features_short = trainData.loc[:, short_input_labels]\n",
    "train_features_long = trainData.loc[:, long_input_labels]\n",
    "train_features = trainData.loc[:, features_labels]\n",
    "\n",
    "test_target = testCenterData.loc[:, target_labels]\n",
    "test_features_short = testCenterData.loc[:, short_input_labels]\n",
    "test_features_long = testCenterData.loc[:, long_input_labels]\n",
    "test_features = testCenterData.loc[:, features_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fitTBNN(model,\n",
    "                        max_epochs=100,\n",
    "                        initial_learning_rate=1.0,\n",
    "                        decay_step=100.0,\n",
    "                        loss='mean_absolute_error'):\n",
    "    \n",
    "    learning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(\n",
    "        initial_learning_rate, decay_step, 1)\n",
    "    \n",
    "    metrics_list=[]\n",
    "    if loss=='mean_absolute_error':\n",
    "        metrics_list=[loss]\n",
    "    else:\n",
    "        metrics_list=[loss, 'mean_absolute_error']\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "        loss=loss,\n",
    "        metrics=metrics_list)\n",
    "    \n",
    "    history = model.fit(\n",
    "        [train_features_long, train_features_short],\n",
    "        train_target,\n",
    "        epochs=max_epochs,\n",
    "        # Suppress logging.\n",
    "        verbose=0,\n",
    "        # Calculate validation results on 1% of the training data.\n",
    "        validation_split = 0.6)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit(model,\n",
    "                    max_epochs=1000,\n",
    "                    initial_learning_rate=1.0,\n",
    "                    decay_step=10.0,\n",
    "                    loss='mean_absolute_error'):\n",
    "    \n",
    "    learning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(\n",
    "        initial_learning_rate, decay_step, 1)\n",
    "    \n",
    "    metrics_list=[]\n",
    "    if loss=='mean_absolute_error':\n",
    "        metrics_list=[loss]\n",
    "    else:\n",
    "        metrics_list=[loss, 'mean_absolute_error']\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "        loss=loss,\n",
    "        metrics=metrics_list)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_features,\n",
    "        train_target,\n",
    "        epochs=max_epochs,\n",
    "        # Suppress logging.\n",
    "        verbose=0,\n",
    "        # Calculate validation results on 1% of the training data.\n",
    "        validation_split = 0.6)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 16:15:29.628570: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-12-23 16:15:29.628752: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (romanovadi-surface-pro-7): /proc/driver/nvidia/version does not exist\n",
      "2022-12-23 16:15:29.630269: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "normalizer_tensors = tf.keras.layers.Normalization(axis=-1, name='tensorInputNormalization')\n",
    "normalizer_tensors.adapt(train_features_short)\n",
    "normalizer_no_tensors = tf.keras.layers.Normalization(axis=-1, name='generalInputNormalization')\n",
    "normalizer_no_tensors.adapt(train_features_long)\n",
    "normalizer_all = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer_all.adapt(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_long = keras.Input(shape=(len(train_features_long.columns),), name='generalInput')\n",
    "inputs_short = keras.Input(shape=(len(train_features_short.columns),), name='tensorInput')\n",
    "norm_long = normalizer_no_tensors1(inputs_long)\n",
    "norm_short = normalizer_tensors1(inputs_short)\n",
    "denseLayer1 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones(),\n",
    "                           name='1stDenseLayer')(norm_long)\n",
    "denseLayer2 = layers.Dense(len(train_features_short.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones(),\n",
    "                           name='2ndDenseLayer')(denseLayer1)\n",
    "concatenate = layers.Concatenate(name='concatenationLayer')([denseLayer2, norm_short])\n",
    "outputs = layers.Dense(len(train_target.columns),\n",
    "                       activation='linear',\n",
    "                       kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                       bias_initializer=tf.keras.initializers.Ones(),\n",
    "                       name='output')(concatenate)\n",
    "\n",
    "TBNNModel2Concat = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "norm_long = normalizer_no_tensors(inputs_long)\n",
    "norm_short = normalizer_tensors(inputs_short)\n",
    "denseLayer1 = layers.Dense(len(train_features_short.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(norm_long)\n",
    "multiply = layers.Multiply()([denseLayer1, norm_short])\n",
    "outputs = layers.Dense(len(train_target.columns),\n",
    "                       activation='linear',\n",
    "                       kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                       bias_initializer=tf.keras.initializers.Ones())(multiply)\n",
    "\n",
    "TBNNModel1 = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "norm_long = normalizer_no_tensors(inputs_long)\n",
    "norm_short = normalizer_tensors(inputs_short)\n",
    "denseLayer1 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(norm_long)\n",
    "denseLayer2 = layers.Dense(len(train_features_short.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(denseLayer1)\n",
    "multiply = layers.Multiply()([denseLayer2, norm_short])\n",
    "outputs = layers.Dense(len(train_target.columns),\n",
    "                       activation='linear',\n",
    "                       kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                       bias_initializer=tf.keras.initializers.Ones())(multiply)\n",
    "\n",
    "TBNNModel2 = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "concatNN = TBNNModel2Concat([inputs_long, inputs_short], training=False)\n",
    "multiplyNN = TBNNModel2([inputs_long, inputs_short], training=False)\n",
    "concatenate = layers.Concatenate()([concatNN, multiplyNN])\n",
    "outputs = layers.Dense(len(train_target.columns),\n",
    "                       activation='linear',\n",
    "                       kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                       bias_initializer=tf.keras.initializers.Ones())(concatenate)\n",
    "\n",
    "TBNNModel2ConcatMultiply = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "norm_long = normalizer_no_tensors(inputs_long)\n",
    "norm_short = normalizer_tensors(inputs_short)\n",
    "denseLayer1 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(norm_long)\n",
    "denseLayer2 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(denseLayer1)\n",
    "denseLayer3 = layers.Dense(len(train_features_short.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(denseLayer2)\n",
    "multiply = layers.Multiply()([denseLayer3, norm_short])\n",
    "outputs = layers.Dense(len(train_target.columns),\n",
    "                       activation='linear',\n",
    "                       kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                       bias_initializer=tf.keras.initializers.Ones())(multiply)\n",
    "\n",
    "TBNNModel3 = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "norm_long = normalizer_no_tensors(inputs_long)\n",
    "norm_short = normalizer_tensors(inputs_short)\n",
    "denseLayer1 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(norm_long)\n",
    "denseLayer2 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(denseLayer1)\n",
    "denseLayer3 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(denseLayer2)\n",
    "denseLayer4 = layers.Dense(len(train_features_short.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(denseLayer3)\n",
    "multiply = layers.Multiply()([denseLayer4, norm_short])\n",
    "outputs = layers.Dense(len(train_target.columns),\n",
    "                       activation='linear',\n",
    "                       kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                       bias_initializer=tf.keras.initializers.Ones())(multiply)\n",
    "\n",
    "TBNNModel4 = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "norm_long = normalizer_no_tensors(inputs_long)\n",
    "norm_short = normalizer_tensors(inputs_short)\n",
    "denseLayer1 = layers.Dense(64,\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(norm_short)\n",
    "denseLayer2 = layers.Dense(len(train_features_long.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(denseLayer1)\n",
    "multiply = layers.Multiply()([denseLayer2, norm_long])\n",
    "outputs = layers.Dense(len(train_target.columns),\n",
    "                       activation='linear',\n",
    "                       kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                       bias_initializer=tf.keras.initializers.Ones())(multiply)\n",
    "\n",
    "TBNNModel2Swaped = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_model_2_linear = keras.Sequential([\n",
    "    normalizer_all,\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(len(train_target.columns),\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_model_3 = keras.Sequential([\n",
    "    normalizer_all,\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(len(train_target.columns),\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_model_4 = keras.Sequential([\n",
    "    normalizer_all,\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(64,\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones()),\n",
    "    layers.Dense(len(train_target.columns),\n",
    "                 activation='linear',\n",
    "                 kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                 bias_initializer=tf.keras.initializers.Ones())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TBNN_builder(hp):\n",
    "    inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "    inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "    norm_long = normalizer_no_tensors(inputs_long)\n",
    "    norm_short = normalizer_tensors(inputs_short)\n",
    "    hp_units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n",
    "    hp_activation = hp.Choice('activation', values=['linear', 'elu', 'softplus'])\n",
    "    denseLayer1 = layers.Dense(hp_units,\n",
    "                               activation=hp_activation,\n",
    "                               kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                               bias_initializer=tf.keras.initializers.Ones())(norm_long)\n",
    "    denseLayer2 = layers.Dense(hp_units,\n",
    "                               activation=hp_activation,\n",
    "                               kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                               bias_initializer=tf.keras.initializers.Ones())(denseLayer1)\n",
    "    denseLayer3 = layers.Dense(len(train_features_short.columns),\n",
    "                               activation='linear',\n",
    "                               kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                               bias_initializer=tf.keras.initializers.Ones())(denseLayer2)\n",
    "    multiply = layers.Multiply()([denseLayer3, norm_short])\n",
    "    outputs = layers.Dense(len(train_target.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(multiply)\n",
    "\n",
    "    TBNN = keras.Model(\n",
    "        inputs=[inputs_long, inputs_short],\n",
    "        outputs=outputs,\n",
    "    )\n",
    "    \n",
    "    hp_initial_learning_rate = hp.Float('initial_learning_rate', 1.0, 10.0)\n",
    "    hp_decay_step = hp.Int('decay_step', 2, 53, step=1)\n",
    "    \n",
    "    learning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(\n",
    "        float(hp_initial_learning_rate), hp_decay_step, 1)\n",
    "    \n",
    "    hp_loss = hp.Choice('loss', values=[\n",
    "        'mean_absolute_error',\n",
    "        'mean_absolute_percentage_error',\n",
    "        'mean_squared_error'])\n",
    "    \n",
    "    TBNN.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "        loss=hp_loss,\n",
    "        metrics='mean_absolute_error')\n",
    "    \n",
    "#    history = model.fit(\n",
    "#        [train_features_long, train_features_short],\n",
    "#        train_target,\n",
    "#        epochs=max_epochs,\n",
    "#        # Suppress logging.\n",
    "#        verbose=0,\n",
    "#        # Calculate validation results on 1% of the training data.\n",
    "#        validation_split = 0.6)\n",
    "\n",
    "    return TBNN\n",
    "#hp_units = hp.Int('units', min_value=32, max_value=512, step=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner = kt.Hyperband(TBNN_builder,\n",
    "#                     objective='mean_absolute_error',\n",
    "#                     max_epochs=20,\n",
    "#                     factor=3,\n",
    "#                     directory='TBNN',\n",
    "#                     project_name='TBNNoptimizing')\n",
    "tuner = kt.BayesianOptimization(TBNN_builder,\n",
    "                                objective='mean_absolute_error',\n",
    "                                max_trials=200,\n",
    "                                directory='TBNN',\n",
    "                                project_name='TBNNoptimizing',\n",
    "                                overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21 Complete [00h 07m 30s]\n",
      "mean_absolute_error: 31.15664291381836\n",
      "\n",
      "Best mean_absolute_error So Far: 0.03475264832377434\n",
      "Total elapsed time: 03h 04m 27s\n",
      "\n",
      "Search: Running Trial #22\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |256               |512               \n",
      "activation        |elu               |softplus          \n",
      "initial_learnin...|1                 |1                 \n",
      "decay_step        |29                |53                \n",
      "loss              |mean_absolute_p...|mean_absolute_e...\n",
      "\n",
      "Epoch 1/100\n",
      "   1/2344 [..............................] - ETA: 54:42 - loss: 30252910772224.0000 - mean_absolute_error: 387040.4688WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0090s). Check your callbacks.\n",
      "2344/2344 [==============================] - 13s 5ms/step - loss: 1106377179136.0000 - mean_absolute_error: 17836.1523 - val_loss: 100128022528.0000 - val_mean_absolute_error: 2749.9419\n",
      "Epoch 2/100\n",
      "2344/2344 [==============================] - 15s 6ms/step - loss: 84422475776.0000 - mean_absolute_error: 2458.0198 - val_loss: 69548130304.0000 - val_mean_absolute_error: 2201.0156\n",
      "Epoch 3/100\n",
      "2344/2344 [==============================] - 29s 12ms/step - loss: 56504983552.0000 - mean_absolute_error: 1983.0232 - val_loss: 43767402496.0000 - val_mean_absolute_error: 1773.1466\n",
      "Epoch 4/100\n",
      "2344/2344 [==============================] - 6s 3ms/step - loss: 34834972672.0000 - mean_absolute_error: 1591.7231 - val_loss: 27245150208.0000 - val_mean_absolute_error: 1432.2230\n",
      "Epoch 5/100\n",
      "2344/2344 [==============================] - 10s 4ms/step - loss: 22715375616.0000 - mean_absolute_error: 1292.7991 - val_loss: 18749474816.0000 - val_mean_absolute_error: 1175.4451\n",
      "Epoch 6/100\n",
      "2344/2344 [==============================] - 7s 3ms/step - loss: 16143744000.0000 - mean_absolute_error: 1077.4658 - val_loss: 13987779584.0000 - val_mean_absolute_error: 990.9642\n",
      "Epoch 7/100\n",
      "2344/2344 [==============================] - 17s 7ms/step - loss: 12308751360.0000 - mean_absolute_error: 915.9537 - val_loss: 10906352640.0000 - val_mean_absolute_error: 858.6349\n",
      "Epoch 8/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 9548320768.0000 - mean_absolute_error: 807.6609 - val_loss: 8437336064.0000 - val_mean_absolute_error: 763.2916\n",
      "Epoch 9/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 7630885376.0000 - mean_absolute_error: 716.7654 - val_loss: 6999105536.0000 - val_mean_absolute_error: 675.7834\n",
      "Epoch 10/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 6181933568.0000 - mean_absolute_error: 639.2921 - val_loss: 5507385344.0000 - val_mean_absolute_error: 606.9229\n",
      "Epoch 11/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 5098308608.0000 - mean_absolute_error: 579.6929 - val_loss: 4528214016.0000 - val_mean_absolute_error: 553.4542\n",
      "Epoch 12/100\n",
      "2344/2344 [==============================] - 8s 3ms/step - loss: 4220130560.0000 - mean_absolute_error: 529.7300 - val_loss: 3752133888.0000 - val_mean_absolute_error: 506.1171\n",
      "Epoch 13/100\n",
      "2344/2344 [==============================] - 6s 3ms/step - loss: 3549244928.0000 - mean_absolute_error: 486.8501 - val_loss: 3338368512.0000 - val_mean_absolute_error: 464.7903\n",
      "Epoch 14/100\n",
      "2344/2344 [==============================] - 7s 3ms/step - loss: 2990542336.0000 - mean_absolute_error: 452.7405 - val_loss: 2748604928.0000 - val_mean_absolute_error: 434.2213\n",
      "Epoch 15/100\n",
      "2344/2344 [==============================] - 9s 4ms/step - loss: 2552898048.0000 - mean_absolute_error: 421.6853 - val_loss: 2282920704.0000 - val_mean_absolute_error: 407.9725\n",
      "Epoch 16/100\n",
      "2344/2344 [==============================] - 8s 3ms/step - loss: 2209557760.0000 - mean_absolute_error: 396.6141 - val_loss: 2069464704.0000 - val_mean_absolute_error: 383.9010\n",
      "Epoch 17/100\n",
      "2344/2344 [==============================] - 8s 3ms/step - loss: 1934235776.0000 - mean_absolute_error: 373.3920 - val_loss: 1766376832.0000 - val_mean_absolute_error: 361.9135\n",
      "Epoch 18/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 1699600384.0000 - mean_absolute_error: 354.7989 - val_loss: 1611262848.0000 - val_mean_absolute_error: 345.1633\n",
      "Epoch 19/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 1507707392.0000 - mean_absolute_error: 335.3037 - val_loss: 1373319424.0000 - val_mean_absolute_error: 325.6340\n",
      "Epoch 20/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 1350633088.0000 - mean_absolute_error: 320.5793 - val_loss: 1244436480.0000 - val_mean_absolute_error: 311.0857\n",
      "Epoch 21/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 1210615936.0000 - mean_absolute_error: 306.1552 - val_loss: 1149069568.0000 - val_mean_absolute_error: 299.8372\n",
      "Epoch 22/100\n",
      "2344/2344 [==============================] - 5s 2ms/step - loss: 1090052736.0000 - mean_absolute_error: 292.7768 - val_loss: 1083404544.0000 - val_mean_absolute_error: 285.3531\n",
      "Epoch 23/100\n",
      "2344/2344 [==============================] - 6s 3ms/step - loss: 987134784.0000 - mean_absolute_error: 280.6908 - val_loss: 950466176.0000 - val_mean_absolute_error: 274.3329\n",
      "Epoch 24/100\n",
      "1264/2344 [===============>..............] - ETA: 5s - loss: 881722368.0000 - mean_absolute_error: 265.1407"
     ]
    }
   ],
   "source": [
    "logdir=\"logs_kerasTuner/\"\n",
    "tuner.search([train_features_long, train_features_short],\n",
    "             train_target,\n",
    "             epochs=100,\n",
    "             validation_split=0.5,\n",
    "             callbacks=[\n",
    "                 tf.keras.callbacks.TensorBoard(logdir)\n",
    "             ])\n",
    "             #, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "#print(f\"\"\"\n",
    "#The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "#layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "#is {best_hps.get('learning_rate')}.\n",
    "#\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 693860), started 20:04:26 ago. (Use '!kill 693860' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-22c86ce21e4bf12f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-22c86ce21e4bf12f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs_kerasTuner/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['linear', 'elu', 'softplus']))\n",
    "HP_INITIAL_LEARNING_RATE = hp.HParam('initial_learning_rate', hp.Discrete([1.0, 10.0]))\n",
    "HP_DECAY_STEP = hp.HParam('decay_step', hp.Discrete([2, 10, 50]))\n",
    "HP_LOSS = hp.HParam('loss', hp.Discrete([\n",
    "        'mean_absolute_error',\n",
    "#        'mean_absolute_percentage_error',\n",
    "        'mean_squared_error']))\n",
    "METRIC = 'mean_absolute_error'\n",
    "                    \n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_ACTIVATION, HP_INITIAL_LEARNING_RATE, HP_DECAY_STEP, HP_LOSS],\n",
    "    metrics=[hp.Metric(METRIC, display_name='Accuracy')],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TBNNoptimize(hparams):\n",
    "    inputs_long = keras.Input(shape=(len(train_features_long.columns),))\n",
    "    inputs_short = keras.Input(shape=(len(train_features_short.columns),))\n",
    "    norm_long = normalizer_no_tensors(inputs_long)\n",
    "    norm_short = normalizer_tensors(inputs_short)\n",
    "    denseLayer1 = layers.Dense(64,\n",
    "                               activation=hparams[HP_ACTIVATION],\n",
    "                               kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                               bias_initializer=tf.keras.initializers.Ones())(norm_long)\n",
    "    denseLayer2 = layers.Dense(len(train_features_short.columns),\n",
    "                               activation=hparams[HP_ACTIVATION],\n",
    "                               kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                               bias_initializer=tf.keras.initializers.Ones())(denseLayer1)\n",
    "    multiply = layers.Multiply()([denseLayer2, norm_short])\n",
    "    outputs = layers.Dense(len(train_target.columns),\n",
    "                           activation='linear',\n",
    "                           kernel_initializer=tf.keras.initializers.Ones(),\n",
    "                           bias_initializer=tf.keras.initializers.Ones())(multiply)\n",
    "\n",
    "    TBNN2 = keras.Model(\n",
    "        inputs=[inputs_long, inputs_short],\n",
    "        outputs=outputs,\n",
    "    )\n",
    "    \n",
    "    learning_rate_fn = keras.optimizers.schedules.InverseTimeDecay(\n",
    "        hparams[HP_INITIAL_LEARNING_RATE], hparams[HP_DECAY_STEP], 1)\n",
    "    \n",
    "    metrics_list=[]\n",
    "    if hparams[HP_LOSS]=='mean_absolute_error':\n",
    "        metrics_list=[hparams[HP_LOSS]]\n",
    "    else:\n",
    "        metrics_list=[hparams[HP_LOSS], 'mean_absolute_error']\n",
    "    \n",
    "    TBNN2.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "        loss=hparams[HP_LOSS],\n",
    "        metrics=metrics_list)\n",
    "    \n",
    "    TBNN2.fit(\n",
    "        [train_features_long, train_features_short],\n",
    "        train_target,\n",
    "        epochs=100)\n",
    "        # Suppress logging.\n",
    "        #verbose=0,\n",
    "        # Calculate validation results on 1% of the training data.\n",
    "        #validation_split = 0.5)\n",
    "    loss = TBNN2.evaluate([test_features_long, test_features_short],\n",
    "        test_target)\n",
    "\n",
    "    return loss[0]\n",
    "#hp_units = hp.Int('units', min_value=32, max_value=512, step=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        loss = TBNNoptimize(hparams)\n",
    "        tf.summary.scalar(METRIC, loss, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "#!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'activation': 'elu', 'initial_learning_rate': 1.0, 'decay_step': 2, 'loss': 'mean_absolute_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 20.2721 - mean_absolute_error: 20.2721\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6.4981 - mean_absolute_error: 6.4981\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.9953 - mean_absolute_error: 5.9953\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.6806 - mean_absolute_error: 5.6806\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.4551 - mean_absolute_error: 5.4551\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.3160 - mean_absolute_error: 5.3160\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.2066 - mean_absolute_error: 5.2066\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.1076 - mean_absolute_error: 5.1076\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.0223 - mean_absolute_error: 5.0223\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.9556 - mean_absolute_error: 4.9556\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.9060 - mean_absolute_error: 4.9060\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.8649 - mean_absolute_error: 4.8649\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.8281 - mean_absolute_error: 4.8281\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.7923 - mean_absolute_error: 4.7923\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.7564 - mean_absolute_error: 4.7564\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.7279 - mean_absolute_error: 4.7279\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.6983 - mean_absolute_error: 4.6983\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.6717 - mean_absolute_error: 4.6717\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.6487 - mean_absolute_error: 4.6487\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.6321 - mean_absolute_error: 4.6321\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.6153 - mean_absolute_error: 4.6153\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5981 - mean_absolute_error: 4.5981\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5828 - mean_absolute_error: 4.5828\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5696 - mean_absolute_error: 4.5696\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5582 - mean_absolute_error: 4.5582\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5446 - mean_absolute_error: 4.5446\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5305 - mean_absolute_error: 4.5305\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5194 - mean_absolute_error: 4.5194\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.5095 - mean_absolute_error: 4.5095\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4990 - mean_absolute_error: 4.4990\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4875 - mean_absolute_error: 4.4875\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4782 - mean_absolute_error: 4.4782\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4695 - mean_absolute_error: 4.4695\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4603 - mean_absolute_error: 4.4603\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4504 - mean_absolute_error: 4.4504\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4413 - mean_absolute_error: 4.4413\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4321 - mean_absolute_error: 4.4321\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4220 - mean_absolute_error: 4.4220\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4146 - mean_absolute_error: 4.4146\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4057 - mean_absolute_error: 4.4057\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3975 - mean_absolute_error: 4.3975\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3906 - mean_absolute_error: 4.3906\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3839 - mean_absolute_error: 4.3839\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3761 - mean_absolute_error: 4.3761\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3704 - mean_absolute_error: 4.3704\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3638 - mean_absolute_error: 4.3638\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 9s 2ms/step - loss: 4.3566 - mean_absolute_error: 4.3566\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3517 - mean_absolute_error: 4.3517\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3438 - mean_absolute_error: 4.3438\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3370 - mean_absolute_error: 4.3370\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3308 - mean_absolute_error: 4.3308\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3260 - mean_absolute_error: 4.3260\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3200 - mean_absolute_error: 4.3200\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3146 - mean_absolute_error: 4.3146\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3091 - mean_absolute_error: 4.3091\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3044 - mean_absolute_error: 4.3044\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2999 - mean_absolute_error: 4.2999\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 4.2955 - mean_absolute_error: 4.2955\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2906 - mean_absolute_error: 4.2906\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 4s 939us/step - loss: 4.2855 - mean_absolute_error: 4.2855\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 4s 933us/step - loss: 4.2804 - mean_absolute_error: 4.2804\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 4s 935us/step - loss: 4.2759 - mean_absolute_error: 4.2759\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 4s 954us/step - loss: 4.2717 - mean_absolute_error: 4.2717\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 4.2672 - mean_absolute_error: 4.2672\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 965us/step - loss: 4.2635 - mean_absolute_error: 4.2635\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 4s 951us/step - loss: 4.2590 - mean_absolute_error: 4.2590\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 4s 937us/step - loss: 4.2553 - mean_absolute_error: 4.2553\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 4s 938us/step - loss: 4.2512 - mean_absolute_error: 4.2512\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 4s 935us/step - loss: 4.2469 - mean_absolute_error: 4.2469\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 4s 932us/step - loss: 4.2436 - mean_absolute_error: 4.2436\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 4s 944us/step - loss: 4.2400 - mean_absolute_error: 4.2400\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 979us/step - loss: 4.2364 - mean_absolute_error: 4.2364\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 4.2325 - mean_absolute_error: 4.2325\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2289 - mean_absolute_error: 4.2289\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2261 - mean_absolute_error: 4.2261\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2229 - mean_absolute_error: 4.2229\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2191 - mean_absolute_error: 4.2191\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 981us/step - loss: 4.2157 - mean_absolute_error: 4.2157\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 4s 935us/step - loss: 4.2125 - mean_absolute_error: 4.2125\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 4.2094 - mean_absolute_error: 4.2094\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2066 - mean_absolute_error: 4.2066\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2031 - mean_absolute_error: 4.2031\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 4.2005 - mean_absolute_error: 4.2005\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1975 - mean_absolute_error: 4.1975\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1944 - mean_absolute_error: 4.1944\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 4.1917 - mean_absolute_error: 4.1917\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1893 - mean_absolute_error: 4.1893\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 4.1869 - mean_absolute_error: 4.1869\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1840 - mean_absolute_error: 4.1840\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1819 - mean_absolute_error: 4.1819\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1791 - mean_absolute_error: 4.1791\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1768 - mean_absolute_error: 4.1768\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1743 - mean_absolute_error: 4.1743\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 4.1720 - mean_absolute_error: 4.1720\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1700 - mean_absolute_error: 4.1700\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1673 - mean_absolute_error: 4.1673\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1653 - mean_absolute_error: 4.1653\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1631 - mean_absolute_error: 4.1631\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1609 - mean_absolute_error: 4.1609\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 4.1584 - mean_absolute_error: 4.1584\n",
      "1172/1172 [==============================] - 1s 723us/step - loss: 4.1569 - mean_absolute_error: 4.1569\n",
      "--- Starting trial: run-1\n",
      "{'activation': 'elu', 'initial_learning_rate': 1.0, 'decay_step': 2, 'loss': 'mean_squared_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 114038712.0000 - mean_squared_error: 114038712.0000 - mean_absolute_error: 233.6688\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 30274888.0000 - mean_squared_error: 30274888.0000 - mean_absolute_error: 143.8847\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 966us/step - loss: 18369282.0000 - mean_squared_error: 18369282.0000 - mean_absolute_error: 115.0772\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12273026.0000 - mean_squared_error: 12273026.0000 - mean_absolute_error: 96.8746\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8843033.0000 - mean_squared_error: 8843033.0000 - mean_absolute_error: 84.0147\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6613325.0000 - mean_squared_error: 6613325.0000 - mean_absolute_error: 74.2436\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5025086.0000 - mean_squared_error: 5025086.0000 - mean_absolute_error: 66.1670\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4029431.2500 - mean_squared_error: 4029431.2500 - mean_absolute_error: 59.8043\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3267260.5000 - mean_squared_error: 3267260.5000 - mean_absolute_error: 54.5268\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2669730.7500 - mean_squared_error: 2669730.7500 - mean_absolute_error: 49.9785\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2176427.0000 - mean_squared_error: 2176427.0000 - mean_absolute_error: 45.9463\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1818891.6250 - mean_squared_error: 1818891.6250 - mean_absolute_error: 42.5019\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1530110.0000 - mean_squared_error: 1530110.0000 - mean_absolute_error: 39.5077\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1300241.3750 - mean_squared_error: 1300241.3750 - mean_absolute_error: 36.7582\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1116973.6250 - mean_squared_error: 1116973.6250 - mean_absolute_error: 34.3108\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 963373.1875 - mean_squared_error: 963373.1875 - mean_absolute_error: 32.2532\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 8s 2ms/step - loss: 845081.8750 - mean_squared_error: 845081.8750 - mean_absolute_error: 30.4111\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 742706.9375 - mean_squared_error: 742706.9375 - mean_absolute_error: 28.8026\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 660498.3125 - mean_squared_error: 660498.3125 - mean_absolute_error: 27.5324\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 589406.3125 - mean_squared_error: 589406.3125 - mean_absolute_error: 26.3887\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 526515.6250 - mean_squared_error: 526515.6250 - mean_absolute_error: 25.3462\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 471655.5938 - mean_squared_error: 471655.5938 - mean_absolute_error: 24.3140\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 424717.0938 - mean_squared_error: 424717.0938 - mean_absolute_error: 23.3809\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 384434.3125 - mean_squared_error: 384434.3125 - mean_absolute_error: 22.4963\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 346956.8750 - mean_squared_error: 346956.8750 - mean_absolute_error: 21.6876\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 314199.5000 - mean_squared_error: 314199.5000 - mean_absolute_error: 20.9599\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 284189.7188 - mean_squared_error: 284189.7188 - mean_absolute_error: 20.2697\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 964us/step - loss: 259327.0938 - mean_squared_error: 259327.0938 - mean_absolute_error: 19.6868\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 988us/step - loss: 237573.8750 - mean_squared_error: 237573.8750 - mean_absolute_error: 19.1532\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 216431.7344 - mean_squared_error: 216431.7344 - mean_absolute_error: 18.6391\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 197849.7500 - mean_squared_error: 197849.7500 - mean_absolute_error: 18.1830\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 181084.1875 - mean_squared_error: 181084.1875 - mean_absolute_error: 17.7410\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 165871.2344 - mean_squared_error: 165871.2344 - mean_absolute_error: 17.3121\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 151315.1406 - mean_squared_error: 151315.1406 - mean_absolute_error: 16.8913\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 138270.6719 - mean_squared_error: 138270.6719 - mean_absolute_error: 16.4880\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 126796.0625 - mean_squared_error: 126796.0625 - mean_absolute_error: 16.1293\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 115648.2266 - mean_squared_error: 115648.2266 - mean_absolute_error: 15.7610\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 105766.3828 - mean_squared_error: 105766.3828 - mean_absolute_error: 15.4028\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 97321.3047 - mean_squared_error: 97321.3047 - mean_absolute_error: 15.0682\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 89682.8672 - mean_squared_error: 89682.8672 - mean_absolute_error: 14.7556\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 81872.9453 - mean_squared_error: 81872.9453 - mean_absolute_error: 14.4376\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 75060.9375 - mean_squared_error: 75060.9375 - mean_absolute_error: 14.1436\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 69407.5703 - mean_squared_error: 69407.5703 - mean_absolute_error: 13.8770\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 63168.3203 - mean_squared_error: 63168.3203 - mean_absolute_error: 13.5828\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 58376.4258 - mean_squared_error: 58376.4258 - mean_absolute_error: 13.3212\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 53888.9062 - mean_squared_error: 53888.9062 - mean_absolute_error: 13.0685\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 50081.7617 - mean_squared_error: 50081.7617 - mean_absolute_error: 12.8286\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 46390.6562 - mean_squared_error: 46390.6562 - mean_absolute_error: 12.6216\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 43226.8203 - mean_squared_error: 43226.8203 - mean_absolute_error: 12.4345\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 40110.5391 - mean_squared_error: 40110.5391 - mean_absolute_error: 12.2173\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 37275.7656 - mean_squared_error: 37275.7656 - mean_absolute_error: 12.0332\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 34772.9688 - mean_squared_error: 34772.9688 - mean_absolute_error: 11.8423\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 32493.1211 - mean_squared_error: 32493.1211 - mean_absolute_error: 11.6684\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 30509.9473 - mean_squared_error: 30509.9473 - mean_absolute_error: 11.4901\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 28719.5879 - mean_squared_error: 28719.5879 - mean_absolute_error: 11.3207\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 27269.8984 - mean_squared_error: 27269.8984 - mean_absolute_error: 11.1932\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 25914.8359 - mean_squared_error: 25914.8359 - mean_absolute_error: 11.0877\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 24546.6211 - mean_squared_error: 24546.6211 - mean_absolute_error: 10.9514\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 23317.7715 - mean_squared_error: 23317.7715 - mean_absolute_error: 10.8351\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 22282.7363 - mean_squared_error: 22282.7363 - mean_absolute_error: 10.7323\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 21304.9277 - mean_squared_error: 21304.9277 - mean_absolute_error: 10.6369\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20319.3438 - mean_squared_error: 20319.3438 - mean_absolute_error: 10.5379\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 19506.0137 - mean_squared_error: 19506.0137 - mean_absolute_error: 10.4597\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 18709.1465 - mean_squared_error: 18709.1465 - mean_absolute_error: 10.3814\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 17944.3457 - mean_squared_error: 17944.3457 - mean_absolute_error: 10.2863\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 17224.6973 - mean_squared_error: 17224.6973 - mean_absolute_error: 10.2230\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 16574.8457 - mean_squared_error: 16574.8457 - mean_absolute_error: 10.1475\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 15954.4443 - mean_squared_error: 15954.4443 - mean_absolute_error: 10.0912\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 15338.1260 - mean_squared_error: 15338.1260 - mean_absolute_error: 10.0184\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 14802.9307 - mean_squared_error: 14802.9307 - mean_absolute_error: 9.9607\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 14279.4248 - mean_squared_error: 14279.4248 - mean_absolute_error: 9.8992\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13734.7949 - mean_squared_error: 13734.7949 - mean_absolute_error: 9.8430\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13229.5781 - mean_squared_error: 13229.5781 - mean_absolute_error: 9.7902\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12761.3906 - mean_squared_error: 12761.3906 - mean_absolute_error: 9.7365\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12307.9502 - mean_squared_error: 12307.9502 - mean_absolute_error: 9.6845\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 970us/step - loss: 11879.2871 - mean_squared_error: 11879.2871 - mean_absolute_error: 9.6342\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11445.4883 - mean_squared_error: 11445.4883 - mean_absolute_error: 9.5813\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11053.2617 - mean_squared_error: 11053.2617 - mean_absolute_error: 9.5342\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10665.8164 - mean_squared_error: 10665.8164 - mean_absolute_error: 9.4938\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10277.0078 - mean_squared_error: 10277.0078 - mean_absolute_error: 9.4437\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9916.4443 - mean_squared_error: 9916.4443 - mean_absolute_error: 9.3923\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9573.6025 - mean_squared_error: 9573.6025 - mean_absolute_error: 9.3590\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9251.2158 - mean_squared_error: 9251.2158 - mean_absolute_error: 9.3107\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8920.9434 - mean_squared_error: 8920.9434 - mean_absolute_error: 9.2701\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8598.6914 - mean_squared_error: 8598.6914 - mean_absolute_error: 9.2231\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8306.4473 - mean_squared_error: 8306.4473 - mean_absolute_error: 9.1863\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8013.0415 - mean_squared_error: 8013.0415 - mean_absolute_error: 9.1429\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 7748.5986 - mean_squared_error: 7748.5986 - mean_absolute_error: 9.1107\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 7463.6973 - mean_squared_error: 7463.6973 - mean_absolute_error: 9.0656\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 7202.1685 - mean_squared_error: 7202.1685 - mean_absolute_error: 9.0261\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6956.3540 - mean_squared_error: 6956.3540 - mean_absolute_error: 8.9964\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6732.9736 - mean_squared_error: 6732.9736 - mean_absolute_error: 8.9571\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6481.7856 - mean_squared_error: 6481.7856 - mean_absolute_error: 8.9172\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6265.9189 - mean_squared_error: 6265.9189 - mean_absolute_error: 8.8818\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6064.9155 - mean_squared_error: 6064.9155 - mean_absolute_error: 8.8501\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5870.3159 - mean_squared_error: 5870.3159 - mean_absolute_error: 8.8150\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5667.8979 - mean_squared_error: 5667.8979 - mean_absolute_error: 8.7819\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5479.1431 - mean_squared_error: 5479.1431 - mean_absolute_error: 8.7478\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5307.1108 - mean_squared_error: 5307.1108 - mean_absolute_error: 8.7189\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5124.8325 - mean_squared_error: 5124.8325 - mean_absolute_error: 8.6877\n",
      "1172/1172 [==============================] - 1s 691us/step - loss: 5029.9795 - mean_squared_error: 5029.9795 - mean_absolute_error: 8.6645\n",
      "--- Starting trial: run-2\n",
      "{'activation': 'elu', 'initial_learning_rate': 1.0, 'decay_step': 10, 'loss': 'mean_absolute_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 932us/step - loss: 12.6864 - mean_absolute_error: 12.6864\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 980us/step - loss: 4.3827 - mean_absolute_error: 4.3827\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 3.2473 - mean_absolute_error: 3.2473\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 2.9504 - mean_absolute_error: 2.9504\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.8033 - mean_absolute_error: 2.8033\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.7019 - mean_absolute_error: 2.7019\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6253 - mean_absolute_error: 2.6253\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.5716 - mean_absolute_error: 2.5716\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 2.5160 - mean_absolute_error: 2.5160\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.4839 - mean_absolute_error: 2.4839\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.4430 - mean_absolute_error: 2.4430\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.4142 - mean_absolute_error: 2.4142\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 2.3940 - mean_absolute_error: 2.3940\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.3658 - mean_absolute_error: 2.3658\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 2.3457 - mean_absolute_error: 2.3457\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.3263 - mean_absolute_error: 2.3263\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.3097 - mean_absolute_error: 2.3097\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 2.2952 - mean_absolute_error: 2.2952\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.2804 - mean_absolute_error: 2.2804\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.2672 - mean_absolute_error: 2.2672\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.2572 - mean_absolute_error: 2.2572\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.2437 - mean_absolute_error: 2.2437\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.2325 - mean_absolute_error: 2.2325\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 2.2235 - mean_absolute_error: 2.2235\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 966us/step - loss: 2.2123 - mean_absolute_error: 2.2123\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 4s 930us/step - loss: 2.2028 - mean_absolute_error: 2.2028\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 979us/step - loss: 2.1964 - mean_absolute_error: 2.1964\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1860 - mean_absolute_error: 2.1860\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 2.1769 - mean_absolute_error: 2.1769\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.1703 - mean_absolute_error: 2.1703\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.1613 - mean_absolute_error: 2.1613\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1539 - mean_absolute_error: 2.1539\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1480 - mean_absolute_error: 2.1480\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 2.1417 - mean_absolute_error: 2.1417\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1336 - mean_absolute_error: 2.1336\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1288 - mean_absolute_error: 2.1288\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1214 - mean_absolute_error: 2.1214\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1148 - mean_absolute_error: 2.1148\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1089 - mean_absolute_error: 2.1089\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1031 - mean_absolute_error: 2.1031\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0976 - mean_absolute_error: 2.0976\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 2.0929 - mean_absolute_error: 2.0929\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0872 - mean_absolute_error: 2.0872\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0819 - mean_absolute_error: 2.0819\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.0775 - mean_absolute_error: 2.0775\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.0733 - mean_absolute_error: 2.0733\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.0675 - mean_absolute_error: 2.0675\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0628 - mean_absolute_error: 2.0628\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.0588 - mean_absolute_error: 2.0588\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 2.0540 - mean_absolute_error: 2.0540\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 4s 932us/step - loss: 2.0511 - mean_absolute_error: 2.0511\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 985us/step - loss: 2.0455 - mean_absolute_error: 2.0455\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 2.0417 - mean_absolute_error: 2.0417\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0373 - mean_absolute_error: 2.0373\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.0334 - mean_absolute_error: 2.0334\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0299 - mean_absolute_error: 2.0299\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 2.0258 - mean_absolute_error: 2.0258\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.0221 - mean_absolute_error: 2.0221\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.0185 - mean_absolute_error: 2.0185\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0152 - mean_absolute_error: 2.0152\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.0115 - mean_absolute_error: 2.0115\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0080 - mean_absolute_error: 2.0080\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0047 - mean_absolute_error: 2.0047\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.0025 - mean_absolute_error: 2.0025\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 1.9987 - mean_absolute_error: 1.9987\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9946 - mean_absolute_error: 1.9946\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 1.9915 - mean_absolute_error: 1.9915\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9898 - mean_absolute_error: 1.9898\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 1.9853 - mean_absolute_error: 1.9853\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9822 - mean_absolute_error: 1.9822\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9794 - mean_absolute_error: 1.9794\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 1.9763 - mean_absolute_error: 1.9763\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 1.9743 - mean_absolute_error: 1.9743\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9713 - mean_absolute_error: 1.9713\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9677 - mean_absolute_error: 1.9677\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 4s 952us/step - loss: 1.9650 - mean_absolute_error: 1.9650\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 962us/step - loss: 1.9622 - mean_absolute_error: 1.9622\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 1.9605 - mean_absolute_error: 1.9605\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 1.9570 - mean_absolute_error: 1.9570\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9550 - mean_absolute_error: 1.9550\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 1.9524 - mean_absolute_error: 1.9524\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9495 - mean_absolute_error: 1.9495\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9465 - mean_absolute_error: 1.9465\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9442 - mean_absolute_error: 1.9442\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 1.9417 - mean_absolute_error: 1.9417\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9392 - mean_absolute_error: 1.9392\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 1.9368 - mean_absolute_error: 1.9368\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9344 - mean_absolute_error: 1.9344\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 1.9327 - mean_absolute_error: 1.9327\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 1.9306 - mean_absolute_error: 1.9306\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9276 - mean_absolute_error: 1.9276\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9253 - mean_absolute_error: 1.9253\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9232 - mean_absolute_error: 1.9232\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9209 - mean_absolute_error: 1.9209\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 1.9193 - mean_absolute_error: 1.9193\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 1.9175 - mean_absolute_error: 1.9175\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9150 - mean_absolute_error: 1.9150\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9123 - mean_absolute_error: 1.9123\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9103 - mean_absolute_error: 1.9103\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 1.9084 - mean_absolute_error: 1.9084\n",
      "1172/1172 [==============================] - 1s 669us/step - loss: 1.9069 - mean_absolute_error: 1.9069\n",
      "--- Starting trial: run-3\n",
      "{'activation': 'elu', 'initial_learning_rate': 1.0, 'decay_step': 10, 'loss': 'mean_squared_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 966us/step - loss: 398082336.0000 - mean_squared_error: 398082336.0000 - mean_absolute_error: 2054.9004\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 74321032.0000 - mean_squared_error: 74321032.0000 - mean_absolute_error: 787.1746\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 36672220.0000 - mean_squared_error: 36672220.0000 - mean_absolute_error: 522.5438\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20104144.0000 - mean_squared_error: 20104144.0000 - mean_absolute_error: 376.6822\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12739851.0000 - mean_squared_error: 12739851.0000 - mean_absolute_error: 286.2508\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8833928.0000 - mean_squared_error: 8833928.0000 - mean_absolute_error: 240.8925\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6685872.5000 - mean_squared_error: 6685872.5000 - mean_absolute_error: 206.7849\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5228521.5000 - mean_squared_error: 5228521.5000 - mean_absolute_error: 183.9664\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4242442.5000 - mean_squared_error: 4242442.5000 - mean_absolute_error: 164.8701\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3579933.2500 - mean_squared_error: 3579933.2500 - mean_absolute_error: 150.0509\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3097852.5000 - mean_squared_error: 3097852.5000 - mean_absolute_error: 136.9293\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2743930.2500 - mean_squared_error: 2743930.2500 - mean_absolute_error: 125.5490\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 2450239.7500 - mean_squared_error: 2450239.7500 - mean_absolute_error: 114.4136\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2193343.0000 - mean_squared_error: 2193343.0000 - mean_absolute_error: 105.2925\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1983042.8750 - mean_squared_error: 1983042.8750 - mean_absolute_error: 98.5240\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1805976.5000 - mean_squared_error: 1805976.5000 - mean_absolute_error: 92.5537\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1646712.6250 - mean_squared_error: 1646712.6250 - mean_absolute_error: 87.5245\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1510219.8750 - mean_squared_error: 1510219.8750 - mean_absolute_error: 83.1403\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1391045.1250 - mean_squared_error: 1391045.1250 - mean_absolute_error: 79.2272\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1283916.5000 - mean_squared_error: 1283916.5000 - mean_absolute_error: 75.8571\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1189740.5000 - mean_squared_error: 1189740.5000 - mean_absolute_error: 73.0589\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1108894.1250 - mean_squared_error: 1108894.1250 - mean_absolute_error: 70.3513\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1035143.6250 - mean_squared_error: 1035143.6250 - mean_absolute_error: 67.8849\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 966562.3750 - mean_squared_error: 966562.3750 - mean_absolute_error: 65.8595\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 965us/step - loss: 907056.0625 - mean_squared_error: 907056.0625 - mean_absolute_error: 64.1629\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 986us/step - loss: 851157.6875 - mean_squared_error: 851157.6875 - mean_absolute_error: 62.1755\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 800473.5000 - mean_squared_error: 800473.5000 - mean_absolute_error: 60.6145\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 755581.1875 - mean_squared_error: 755581.1875 - mean_absolute_error: 58.9737\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 712537.6875 - mean_squared_error: 712537.6875 - mean_absolute_error: 57.7092\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 676566.5000 - mean_squared_error: 676566.5000 - mean_absolute_error: 56.3242\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 639931.5000 - mean_squared_error: 639931.5000 - mean_absolute_error: 55.1297\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 610356.5000 - mean_squared_error: 610356.5000 - mean_absolute_error: 54.1184\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 579494.6250 - mean_squared_error: 579494.6250 - mean_absolute_error: 52.9824\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 553208.5000 - mean_squared_error: 553208.5000 - mean_absolute_error: 51.9819\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 526230.1250 - mean_squared_error: 526230.1250 - mean_absolute_error: 50.9659\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 502563.9688 - mean_squared_error: 502563.9688 - mean_absolute_error: 50.0574\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 479823.5625 - mean_squared_error: 479823.5625 - mean_absolute_error: 49.2386\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 459423.3750 - mean_squared_error: 459423.3750 - mean_absolute_error: 48.3843\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 440633.7188 - mean_squared_error: 440633.7188 - mean_absolute_error: 47.6633\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 421757.9062 - mean_squared_error: 421757.9062 - mean_absolute_error: 46.9237\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 405098.1875 - mean_squared_error: 405098.1875 - mean_absolute_error: 46.2344\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 388648.7500 - mean_squared_error: 388648.7500 - mean_absolute_error: 45.5556\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 375026.6875 - mean_squared_error: 375026.6875 - mean_absolute_error: 44.9444\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 360421.6250 - mean_squared_error: 360421.6250 - mean_absolute_error: 44.2614\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 347338.0312 - mean_squared_error: 347338.0312 - mean_absolute_error: 43.7158\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 334673.3750 - mean_squared_error: 334673.3750 - mean_absolute_error: 43.1361\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 323389.7812 - mean_squared_error: 323389.7812 - mean_absolute_error: 42.5668\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 311792.9375 - mean_squared_error: 311792.9375 - mean_absolute_error: 42.1438\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 301132.6562 - mean_squared_error: 301132.6562 - mean_absolute_error: 41.5898\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 971us/step - loss: 290766.0938 - mean_squared_error: 290766.0938 - mean_absolute_error: 41.0650\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 281987.2188 - mean_squared_error: 281987.2188 - mean_absolute_error: 40.5866\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 272547.0000 - mean_squared_error: 272547.0000 - mean_absolute_error: 40.1236\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 263586.1875 - mean_squared_error: 263586.1875 - mean_absolute_error: 39.6366\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 255997.8125 - mean_squared_error: 255997.8125 - mean_absolute_error: 39.2547\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 247706.9375 - mean_squared_error: 247706.9375 - mean_absolute_error: 38.8042\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 240106.4531 - mean_squared_error: 240106.4531 - mean_absolute_error: 38.4025\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 233175.6719 - mean_squared_error: 233175.6719 - mean_absolute_error: 38.0098\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 226479.7500 - mean_squared_error: 226479.7500 - mean_absolute_error: 37.6651\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 219701.5000 - mean_squared_error: 219701.5000 - mean_absolute_error: 37.2488\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 213819.8906 - mean_squared_error: 213819.8906 - mean_absolute_error: 36.9542\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 207390.0469 - mean_squared_error: 207390.0469 - mean_absolute_error: 36.5796\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 201961.7031 - mean_squared_error: 201961.7031 - mean_absolute_error: 36.2634\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 196575.3281 - mean_squared_error: 196575.3281 - mean_absolute_error: 35.9294\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 191358.7500 - mean_squared_error: 191358.7500 - mean_absolute_error: 35.6332\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 186334.6094 - mean_squared_error: 186334.6094 - mean_absolute_error: 35.3260\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 181513.2188 - mean_squared_error: 181513.2188 - mean_absolute_error: 35.0287\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 176854.3438 - mean_squared_error: 176854.3438 - mean_absolute_error: 34.7423\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 172349.3438 - mean_squared_error: 172349.3438 - mean_absolute_error: 34.4398\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 167965.0469 - mean_squared_error: 167965.0469 - mean_absolute_error: 34.1859\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 163918.1250 - mean_squared_error: 163918.1250 - mean_absolute_error: 33.9172\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 160001.8750 - mean_squared_error: 160001.8750 - mean_absolute_error: 33.6853\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 156096.5469 - mean_squared_error: 156096.5469 - mean_absolute_error: 33.4312\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 152378.3906 - mean_squared_error: 152378.3906 - mean_absolute_error: 33.1679\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 148692.7188 - mean_squared_error: 148692.7188 - mean_absolute_error: 32.9323\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 962us/step - loss: 145283.9531 - mean_squared_error: 145283.9531 - mean_absolute_error: 32.7221\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 142054.0000 - mean_squared_error: 142054.0000 - mean_absolute_error: 32.4924\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 138747.6406 - mean_squared_error: 138747.6406 - mean_absolute_error: 32.2733\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 135568.5000 - mean_squared_error: 135568.5000 - mean_absolute_error: 32.0579\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 132842.3594 - mean_squared_error: 132842.3594 - mean_absolute_error: 31.8087\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 129817.8438 - mean_squared_error: 129817.8438 - mean_absolute_error: 31.6192\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 127001.0703 - mean_squared_error: 127001.0703 - mean_absolute_error: 31.4405\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 124267.8750 - mean_squared_error: 124267.8750 - mean_absolute_error: 31.2298\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 121547.1484 - mean_squared_error: 121547.1484 - mean_absolute_error: 31.0357\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 8s 2ms/step - loss: 118956.5547 - mean_squared_error: 118956.5547 - mean_absolute_error: 30.8419\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 116828.1875 - mean_squared_error: 116828.1875 - mean_absolute_error: 30.6389\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 114322.4219 - mean_squared_error: 114322.4219 - mean_absolute_error: 30.4614\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 112043.6797 - mean_squared_error: 112043.6797 - mean_absolute_error: 30.2835\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 109863.0156 - mean_squared_error: 109863.0156 - mean_absolute_error: 30.0967\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 107758.7500 - mean_squared_error: 107758.7500 - mean_absolute_error: 29.9246\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 105453.5469 - mean_squared_error: 105453.5469 - mean_absolute_error: 29.7584\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 103489.2031 - mean_squared_error: 103489.2031 - mean_absolute_error: 29.5969\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 101377.4922 - mean_squared_error: 101377.4922 - mean_absolute_error: 29.4348\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 99460.0781 - mean_squared_error: 99460.0781 - mean_absolute_error: 29.2701\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 97556.0625 - mean_squared_error: 97556.0625 - mean_absolute_error: 29.0919\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 95657.7891 - mean_squared_error: 95657.7891 - mean_absolute_error: 28.9657\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 94044.1484 - mean_squared_error: 94044.1484 - mean_absolute_error: 28.8005\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 92306.8750 - mean_squared_error: 92306.8750 - mean_absolute_error: 28.6581\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 90537.5234 - mean_squared_error: 90537.5234 - mean_absolute_error: 28.4882\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 4s 955us/step - loss: 88917.6797 - mean_squared_error: 88917.6797 - mean_absolute_error: 28.3578\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 87332.7969 - mean_squared_error: 87332.7969 - mean_absolute_error: 28.2295\n",
      "1172/1172 [==============================] - 1s 755us/step - loss: 86401.5391 - mean_squared_error: 86401.5391 - mean_absolute_error: 28.1213\n",
      "--- Starting trial: run-4\n",
      "{'activation': 'elu', 'initial_learning_rate': 1.0, 'decay_step': 50, 'loss': 'mean_absolute_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 979us/step - loss: 199.0511 - mean_absolute_error: 199.0511\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 6.8658 - mean_absolute_error: 6.8658\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 3.9507 - mean_absolute_error: 3.9507\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 2.6761 - mean_absolute_error: 2.6761\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.3131 - mean_absolute_error: 2.3131\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 2.0459 - mean_absolute_error: 2.0459\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 1.8364 - mean_absolute_error: 1.8364\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.6665 - mean_absolute_error: 1.6665\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.5331 - mean_absolute_error: 1.5331\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.4290 - mean_absolute_error: 1.4290\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.3443 - mean_absolute_error: 1.3443\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 1.2683 - mean_absolute_error: 1.2683\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.1999 - mean_absolute_error: 1.1999\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 1.1364 - mean_absolute_error: 1.1364\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.0781 - mean_absolute_error: 1.0781\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 991us/step - loss: 1.0237 - mean_absolute_error: 1.0237\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 0.9731 - mean_absolute_error: 0.9731\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 0.9255 - mean_absolute_error: 0.9255\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.8810 - mean_absolute_error: 0.8810\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 0.8387 - mean_absolute_error: 0.8387\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.7986 - mean_absolute_error: 0.7986\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 0.7606 - mean_absolute_error: 0.7606\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 975us/step - loss: 0.7244 - mean_absolute_error: 0.7244\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 4s 936us/step - loss: 0.6892 - mean_absolute_error: 0.6892\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 978us/step - loss: 0.6559 - mean_absolute_error: 0.6559\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 0.6238 - mean_absolute_error: 0.6238\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 0.5933 - mean_absolute_error: 0.5933\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.5635 - mean_absolute_error: 0.5635\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.5354 - mean_absolute_error: 0.5354\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.5080 - mean_absolute_error: 0.5080\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.4814 - mean_absolute_error: 0.4814\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.4565 - mean_absolute_error: 0.4565\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 0.4318 - mean_absolute_error: 0.4318\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.4078 - mean_absolute_error: 0.4078\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.3848 - mean_absolute_error: 0.3848\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.3623 - mean_absolute_error: 0.3623\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.3405 - mean_absolute_error: 0.3405\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 0.3192 - mean_absolute_error: 0.3192\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 0.2985 - mean_absolute_error: 0.2985\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 0.2785 - mean_absolute_error: 0.2785\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.2590 - mean_absolute_error: 0.2590\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.2402 - mean_absolute_error: 0.2402\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.2219 - mean_absolute_error: 0.2219\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.2037 - mean_absolute_error: 0.2037\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 0.1864 - mean_absolute_error: 0.1864\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.1691 - mean_absolute_error: 0.1691\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 0.1523 - mean_absolute_error: 0.1523\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 984us/step - loss: 0.1360 - mean_absolute_error: 0.1360\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 4s 942us/step - loss: 0.1202 - mean_absolute_error: 0.1202\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 0.1049 - mean_absolute_error: 0.1049\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 0.0898 - mean_absolute_error: 0.0898\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 0.0756 - mean_absolute_error: 0.0756\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0619 - mean_absolute_error: 0.0619\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 0.0492 - mean_absolute_error: 0.0492\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0378 - mean_absolute_error: 0.0378\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 0.0289 - mean_absolute_error: 0.0289\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0239 - mean_absolute_error: 0.0239\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0226 - mean_absolute_error: 0.0226\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0219 - mean_absolute_error: 0.0219\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0212 - mean_absolute_error: 0.0212\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0206 - mean_absolute_error: 0.0206\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0202 - mean_absolute_error: 0.0202\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 0.0198 - mean_absolute_error: 0.0198\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0194 - mean_absolute_error: 0.0194\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0191\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 0.0189 - mean_absolute_error: 0.0189\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0187\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 0.0184 - mean_absolute_error: 0.0184\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0183 - mean_absolute_error: 0.0183\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0181 - mean_absolute_error: 0.0181\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0180 - mean_absolute_error: 0.0180\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0178 - mean_absolute_error: 0.0178\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0178 - mean_absolute_error: 0.0178\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 4s 939us/step - loss: 0.0176 - mean_absolute_error: 0.0176\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 969us/step - loss: 0.0175 - mean_absolute_error: 0.0175\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 0.0174 - mean_absolute_error: 0.0174\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0173 - mean_absolute_error: 0.0173\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0172 - mean_absolute_error: 0.0172\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 0.0172 - mean_absolute_error: 0.0172\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0170 - mean_absolute_error: 0.0170\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0170 - mean_absolute_error: 0.0170\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0169 - mean_absolute_error: 0.0169\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 0.0168 - mean_absolute_error: 0.0168\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0168 - mean_absolute_error: 0.0168\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0166 - mean_absolute_error: 0.0166\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 0.0165 - mean_absolute_error: 0.0165\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 0.0165 - mean_absolute_error: 0.0165\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 0.0164 - mean_absolute_error: 0.0164\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0163 - mean_absolute_error: 0.0163\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 0.0162 - mean_absolute_error: 0.0162\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 0.0162 - mean_absolute_error: 0.0162\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0161 - mean_absolute_error: 0.0161\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0160 - mean_absolute_error: 0.0160\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 0.0159 - mean_absolute_error: 0.0159\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 0.0159 - mean_absolute_error: 0.0159\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 0.0158 - mean_absolute_error: 0.0158\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 0.0158 - mean_absolute_error: 0.0158\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 0.0157 - mean_absolute_error: 0.0157\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 4s 952us/step - loss: 0.0156 - mean_absolute_error: 0.0156\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 0.0156 - mean_absolute_error: 0.0156\n",
      "1172/1172 [==============================] - 1s 727us/step - loss: 0.0156 - mean_absolute_error: 0.0156\n",
      "--- Starting trial: run-5\n",
      "{'activation': 'elu', 'initial_learning_rate': 1.0, 'decay_step': 50, 'loss': 'mean_squared_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13034396.0000 - mean_squared_error: 13034396.0000 - mean_absolute_error: 156.6752\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 182676.4844 - mean_squared_error: 182676.4844 - mean_absolute_error: 46.1154\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 38337.3672 - mean_squared_error: 38337.3672 - mean_absolute_error: 25.4236\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3225.3774 - mean_squared_error: 3225.3774 - mean_absolute_error: 14.5036\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 896.2070 - mean_squared_error: 896.2070 - mean_absolute_error: 9.5618\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 391.5396 - mean_squared_error: 391.5396 - mean_absolute_error: 7.4424\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 253.9791 - mean_squared_error: 253.9791 - mean_absolute_error: 5.9748\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 170.6542 - mean_squared_error: 170.6542 - mean_absolute_error: 5.0159\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 128.9511 - mean_squared_error: 128.9511 - mean_absolute_error: 4.3023\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 92.8410 - mean_squared_error: 92.8410 - mean_absolute_error: 3.7173\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 74.9881 - mean_squared_error: 74.9881 - mean_absolute_error: 3.2601\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 60.8205 - mean_squared_error: 60.8205 - mean_absolute_error: 2.9100\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 49.5137 - mean_squared_error: 49.5137 - mean_absolute_error: 2.5974\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 39.5814 - mean_squared_error: 39.5814 - mean_absolute_error: 2.3132\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 34.0027 - mean_squared_error: 34.0027 - mean_absolute_error: 2.0718\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 28.8982 - mean_squared_error: 28.8982 - mean_absolute_error: 1.8700\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 25.3573 - mean_squared_error: 25.3573 - mean_absolute_error: 1.7241\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 22.0702 - mean_squared_error: 22.0702 - mean_absolute_error: 1.5981\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 19.9684 - mean_squared_error: 19.9684 - mean_absolute_error: 1.5051\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 19.0164 - mean_squared_error: 19.0164 - mean_absolute_error: 1.4168\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 16.1250 - mean_squared_error: 16.1250 - mean_absolute_error: 1.3306\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 15.6148 - mean_squared_error: 15.6148 - mean_absolute_error: 1.3074\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 964us/step - loss: 14.1149 - mean_squared_error: 14.1149 - mean_absolute_error: 1.2302\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12.9122 - mean_squared_error: 12.9122 - mean_absolute_error: 1.1793\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11.5174 - mean_squared_error: 11.5174 - mean_absolute_error: 1.1385\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11.3038 - mean_squared_error: 11.3038 - mean_absolute_error: 1.0947\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10.4440 - mean_squared_error: 10.4440 - mean_absolute_error: 1.0566\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9.8657 - mean_squared_error: 9.8657 - mean_absolute_error: 1.0256\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9.2559 - mean_squared_error: 9.2559 - mean_absolute_error: 0.9746\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 8.6132 - mean_squared_error: 8.6132 - mean_absolute_error: 0.9491\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8.0939 - mean_squared_error: 8.0939 - mean_absolute_error: 0.9187\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8.0029 - mean_squared_error: 8.0029 - mean_absolute_error: 0.8866\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 7.3999 - mean_squared_error: 7.3999 - mean_absolute_error: 0.8704\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6.8504 - mean_squared_error: 6.8504 - mean_absolute_error: 0.8415\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6.3572 - mean_squared_error: 6.3572 - mean_absolute_error: 0.8151\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6.3985 - mean_squared_error: 6.3985 - mean_absolute_error: 0.7952\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6.0516 - mean_squared_error: 6.0516 - mean_absolute_error: 0.7716\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.9879 - mean_squared_error: 5.9879 - mean_absolute_error: 0.7686\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.4810 - mean_squared_error: 5.4810 - mean_absolute_error: 0.7339\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.2261 - mean_squared_error: 5.2261 - mean_absolute_error: 0.7186\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.1572 - mean_squared_error: 5.1572 - mean_absolute_error: 0.7014\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.7834 - mean_squared_error: 4.7834 - mean_absolute_error: 0.6858\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.8351 - mean_squared_error: 4.8351 - mean_absolute_error: 0.6783\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.3944 - mean_squared_error: 4.3944 - mean_absolute_error: 0.6551\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.4344 - mean_squared_error: 4.4344 - mean_absolute_error: 0.6533\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.1704 - mean_squared_error: 4.1704 - mean_absolute_error: 0.6290\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.0543 - mean_squared_error: 4.0543 - mean_absolute_error: 0.6219\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.8802 - mean_squared_error: 3.8802 - mean_absolute_error: 0.6076\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.7482 - mean_squared_error: 3.7482 - mean_absolute_error: 0.5990\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.5858 - mean_squared_error: 3.5858 - mean_absolute_error: 0.5876\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.6722 - mean_squared_error: 3.6722 - mean_absolute_error: 0.5771\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.4868 - mean_squared_error: 3.4868 - mean_absolute_error: 0.5634\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.4516 - mean_squared_error: 3.4516 - mean_absolute_error: 0.5596\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.3199 - mean_squared_error: 3.3199 - mean_absolute_error: 0.5512\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.2288 - mean_squared_error: 3.2288 - mean_absolute_error: 0.5401\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.0488 - mean_squared_error: 3.0488 - mean_absolute_error: 0.5277\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.0125 - mean_squared_error: 3.0125 - mean_absolute_error: 0.5241\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.0038 - mean_squared_error: 3.0038 - mean_absolute_error: 0.5172\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.8114 - mean_squared_error: 2.8114 - mean_absolute_error: 0.5087\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.8348 - mean_squared_error: 2.8348 - mean_absolute_error: 0.5029\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.7817 - mean_squared_error: 2.7817 - mean_absolute_error: 0.4952\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6592 - mean_squared_error: 2.6592 - mean_absolute_error: 0.4910\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6540 - mean_squared_error: 2.6540 - mean_absolute_error: 0.4799\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 2.5559 - mean_squared_error: 2.5559 - mean_absolute_error: 0.4716\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.5108 - mean_squared_error: 2.5108 - mean_absolute_error: 0.4675\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.5893 - mean_squared_error: 2.5893 - mean_absolute_error: 0.4655\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.4790 - mean_squared_error: 2.4790 - mean_absolute_error: 0.4536\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.3732 - mean_squared_error: 2.3732 - mean_absolute_error: 0.4519\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.2741 - mean_squared_error: 2.2741 - mean_absolute_error: 0.4443\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.2701 - mean_squared_error: 2.2701 - mean_absolute_error: 0.4410\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1528 - mean_squared_error: 2.1528 - mean_absolute_error: 0.4366\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 972us/step - loss: 2.2046 - mean_squared_error: 2.2046 - mean_absolute_error: 0.4264\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1608 - mean_squared_error: 2.1608 - mean_absolute_error: 0.4200\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0726 - mean_squared_error: 2.0726 - mean_absolute_error: 0.4176\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0958 - mean_squared_error: 2.0958 - mean_absolute_error: 0.4186\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0617 - mean_squared_error: 2.0617 - mean_absolute_error: 0.4091\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.9709 - mean_squared_error: 1.9709 - mean_absolute_error: 0.4026\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.0469 - mean_squared_error: 2.0469 - mean_absolute_error: 0.4019\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.8811 - mean_squared_error: 1.8811 - mean_absolute_error: 0.3972\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.8741 - mean_squared_error: 1.8741 - mean_absolute_error: 0.3904\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 1.9603 - mean_squared_error: 1.9603 - mean_absolute_error: 0.3931\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 8s 2ms/step - loss: 1.8273 - mean_squared_error: 1.8273 - mean_absolute_error: 0.3829\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.8633 - mean_squared_error: 1.8633 - mean_absolute_error: 0.3851\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.7836 - mean_squared_error: 1.7836 - mean_absolute_error: 0.3774\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.8023 - mean_squared_error: 1.8023 - mean_absolute_error: 0.3724\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.7323 - mean_squared_error: 1.7323 - mean_absolute_error: 0.3702\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.6799 - mean_squared_error: 1.6799 - mean_absolute_error: 0.3680\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.7103 - mean_squared_error: 1.7103 - mean_absolute_error: 0.3630\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.6307 - mean_squared_error: 1.6307 - mean_absolute_error: 0.3563\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.6959 - mean_squared_error: 1.6959 - mean_absolute_error: 0.3619\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.5809 - mean_squared_error: 1.5809 - mean_absolute_error: 0.3562\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.5528 - mean_squared_error: 1.5528 - mean_absolute_error: 0.3508\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.5837 - mean_squared_error: 1.5837 - mean_absolute_error: 0.3504\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.5697 - mean_squared_error: 1.5697 - mean_absolute_error: 0.3451\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.4768 - mean_squared_error: 1.4768 - mean_absolute_error: 0.3416\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 968us/step - loss: 1.5121 - mean_squared_error: 1.5121 - mean_absolute_error: 0.3429\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.5055 - mean_squared_error: 1.5055 - mean_absolute_error: 0.3406\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.4819 - mean_squared_error: 1.4819 - mean_absolute_error: 0.3382\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1.4916 - mean_squared_error: 1.4916 - mean_absolute_error: 0.3364\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 1.4436 - mean_squared_error: 1.4436 - mean_absolute_error: 0.3301\n",
      "1172/1172 [==============================] - 1s 743us/step - loss: 1.4851 - mean_squared_error: 1.4851 - mean_absolute_error: 0.3326\n",
      "--- Starting trial: run-6\n",
      "{'activation': 'elu', 'initial_learning_rate': 10.0, 'decay_step': 2, 'loss': 'mean_absolute_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 963us/step - loss: 8746.6377 - mean_absolute_error: 8746.6377\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 296.6032 - mean_absolute_error: 296.6032\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 191.8846 - mean_absolute_error: 191.8846\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 129.6682 - mean_absolute_error: 129.6682\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 95.0945 - mean_absolute_error: 95.0945\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 85.7739 - mean_absolute_error: 85.7739\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 78.6971 - mean_absolute_error: 78.6971\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 72.6139 - mean_absolute_error: 72.6139\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 69.6114 - mean_absolute_error: 69.6114\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 64.4216 - mean_absolute_error: 64.4216\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 61.3186 - mean_absolute_error: 61.3186\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 58.4811 - mean_absolute_error: 58.4811\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 56.4816 - mean_absolute_error: 56.4816\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 54.1536 - mean_absolute_error: 54.1536\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 52.2435 - mean_absolute_error: 52.2435\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 50.4059 - mean_absolute_error: 50.4059\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 49.1084 - mean_absolute_error: 49.1084\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 47.2994 - mean_absolute_error: 47.2994\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 45.8695 - mean_absolute_error: 45.8695\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 4s 958us/step - loss: 44.4610 - mean_absolute_error: 44.4610\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 966us/step - loss: 43.1259 - mean_absolute_error: 43.1259\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 42.0030 - mean_absolute_error: 42.0030\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 40.7056 - mean_absolute_error: 40.7056\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 39.5743 - mean_absolute_error: 39.5743\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 38.5039 - mean_absolute_error: 38.5039\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 37.9670 - mean_absolute_error: 37.9670\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 36.6255 - mean_absolute_error: 36.6255\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 35.7118 - mean_absolute_error: 35.7118\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 34.8145 - mean_absolute_error: 34.8145\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 34.0983 - mean_absolute_error: 34.0983\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 33.1667 - mean_absolute_error: 33.1667\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 32.3723 - mean_absolute_error: 32.3723\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 31.6207 - mean_absolute_error: 31.6207\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 31.1300 - mean_absolute_error: 31.1300\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 30.2339 - mean_absolute_error: 30.2339\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 29.5691 - mean_absolute_error: 29.5691\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 28.9199 - mean_absolute_error: 28.9199\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 28.2890 - mean_absolute_error: 28.2890\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 28.3717 - mean_absolute_error: 28.3717\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 27.1629 - mean_absolute_error: 27.1629\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 26.6065 - mean_absolute_error: 26.6065\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 26.0554 - mean_absolute_error: 26.0554\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 25.5209 - mean_absolute_error: 25.5209\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 24.9993 - mean_absolute_error: 24.9993\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 975us/step - loss: 24.4988 - mean_absolute_error: 24.4988\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 4s 943us/step - loss: 24.0091 - mean_absolute_error: 24.0091\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 23.5293 - mean_absolute_error: 23.5293\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 23.0707 - mean_absolute_error: 23.0707\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 22.6223 - mean_absolute_error: 22.6223\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 22.1841 - mean_absolute_error: 22.1841\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 21.7602 - mean_absolute_error: 21.7602\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 21.3456 - mean_absolute_error: 21.3456\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20.9421 - mean_absolute_error: 20.9421\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20.5480 - mean_absolute_error: 20.5480\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20.1660 - mean_absolute_error: 20.1660\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 19.7910 - mean_absolute_error: 19.7910\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 19.4286 - mean_absolute_error: 19.4286\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 19.0740 - mean_absolute_error: 19.0740\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 18.7273 - mean_absolute_error: 18.7273\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 18.3912 - mean_absolute_error: 18.3912\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 18.0611 - mean_absolute_error: 18.0611\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 17.7353 - mean_absolute_error: 17.7353\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 17.4195 - mean_absolute_error: 17.4195\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 17.1123 - mean_absolute_error: 17.1123\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 1ms/step - loss: 16.8107 - mean_absolute_error: 16.8107\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 16.5167 - mean_absolute_error: 16.5167\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 16.2291 - mean_absolute_error: 16.2291\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 15.9540 - mean_absolute_error: 15.9540\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 15.6811 - mean_absolute_error: 15.6811\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 984us/step - loss: 15.4143 - mean_absolute_error: 15.4143\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 4s 941us/step - loss: 15.1536 - mean_absolute_error: 15.1536\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 14.9024 - mean_absolute_error: 14.9024\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 14.6566 - mean_absolute_error: 14.6566\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 14.4190 - mean_absolute_error: 14.4190\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 14.1880 - mean_absolute_error: 14.1880\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13.9623 - mean_absolute_error: 13.9623\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 13.7426 - mean_absolute_error: 13.7426\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13.5271 - mean_absolute_error: 13.5271\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13.3191 - mean_absolute_error: 13.3191\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13.1152 - mean_absolute_error: 13.1152\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 12.9152 - mean_absolute_error: 12.9152\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 12.7199 - mean_absolute_error: 12.7199\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12.5312 - mean_absolute_error: 12.5312\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 12.3493 - mean_absolute_error: 12.3493\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 12.1718 - mean_absolute_error: 12.1718\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11.9997 - mean_absolute_error: 11.9997\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 11.8308 - mean_absolute_error: 11.8308\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 11.6671 - mean_absolute_error: 11.6671\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 11.5079 - mean_absolute_error: 11.5079\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 11.3508 - mean_absolute_error: 11.3508\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11.2013 - mean_absolute_error: 11.2013\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 11.0547 - mean_absolute_error: 11.0547\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 10.9148 - mean_absolute_error: 10.9148\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 10.7784 - mean_absolute_error: 10.7784\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 4s 956us/step - loss: 10.6461 - mean_absolute_error: 10.6461\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 4s 935us/step - loss: 10.5152 - mean_absolute_error: 10.5152\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 10.3905 - mean_absolute_error: 10.3905\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10.2680 - mean_absolute_error: 10.2680\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 10.1501 - mean_absolute_error: 10.1501\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10.0347 - mean_absolute_error: 10.0347\n",
      "1172/1172 [==============================] - 1s 715us/step - loss: 9.9720 - mean_absolute_error: 9.9720\n",
      "--- Starting trial: run-7\n",
      "{'activation': 'elu', 'initial_learning_rate': 10.0, 'decay_step': 2, 'loss': 'mean_squared_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3128138137600.0000 - mean_squared_error: 3128138137600.0000 - mean_absolute_error: 36604.1719\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1014786031616.0000 - mean_squared_error: 1014786031616.0000 - mean_absolute_error: 20877.5117\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 748056936448.0000 - mean_squared_error: 748056936448.0000 - mean_absolute_error: 16650.4297\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 594782846976.0000 - mean_squared_error: 594782846976.0000 - mean_absolute_error: 14541.3516\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 506078789632.0000 - mean_squared_error: 506078789632.0000 - mean_absolute_error: 12950.3809\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 435750436864.0000 - mean_squared_error: 435750436864.0000 - mean_absolute_error: 11814.4238\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 385397424128.0000 - mean_squared_error: 385397424128.0000 - mean_absolute_error: 10942.8330\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 340410171392.0000 - mean_squared_error: 340410171392.0000 - mean_absolute_error: 10239.0576\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 309514403840.0000 - mean_squared_error: 309514403840.0000 - mean_absolute_error: 9617.4248\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 283144519680.0000 - mean_squared_error: 283144519680.0000 - mean_absolute_error: 9109.3271\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 262141067264.0000 - mean_squared_error: 262141067264.0000 - mean_absolute_error: 8668.0342\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 241418616832.0000 - mean_squared_error: 241418616832.0000 - mean_absolute_error: 8289.6357\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 225989099520.0000 - mean_squared_error: 225989099520.0000 - mean_absolute_error: 7934.5171\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 211211337728.0000 - mean_squared_error: 211211337728.0000 - mean_absolute_error: 7630.2974\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 199268220928.0000 - mean_squared_error: 199268220928.0000 - mean_absolute_error: 7340.9844\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 187880947712.0000 - mean_squared_error: 187880947712.0000 - mean_absolute_error: 7087.1045\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 177321017344.0000 - mean_squared_error: 177321017344.0000 - mean_absolute_error: 6843.2339\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 168054996992.0000 - mean_squared_error: 168054996992.0000 - mean_absolute_error: 6618.2305\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 159578619904.0000 - mean_squared_error: 159578619904.0000 - mean_absolute_error: 6407.7485\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 961us/step - loss: 152099422208.0000 - mean_squared_error: 152099422208.0000 - mean_absolute_error: 6218.4878\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 145202937856.0000 - mean_squared_error: 145202937856.0000 - mean_absolute_error: 6037.4834\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 138852745216.0000 - mean_squared_error: 138852745216.0000 - mean_absolute_error: 5869.9736\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 132768219136.0000 - mean_squared_error: 132768219136.0000 - mean_absolute_error: 5706.0771\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 126782341120.0000 - mean_squared_error: 126782341120.0000 - mean_absolute_error: 5557.1934\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 121928638464.0000 - mean_squared_error: 121928638464.0000 - mean_absolute_error: 5408.0010\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 116919214080.0000 - mean_squared_error: 116919214080.0000 - mean_absolute_error: 5276.7090\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 112558260224.0000 - mean_squared_error: 112558260224.0000 - mean_absolute_error: 5144.8804\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 108247367680.0000 - mean_squared_error: 108247367680.0000 - mean_absolute_error: 5022.2515\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 103962230784.0000 - mean_squared_error: 103962230784.0000 - mean_absolute_error: 4905.7407\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 100507860992.0000 - mean_squared_error: 100507860992.0000 - mean_absolute_error: 4788.2759\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 97042268160.0000 - mean_squared_error: 97042268160.0000 - mean_absolute_error: 4683.4634\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 93890994176.0000 - mean_squared_error: 93890994176.0000 - mean_absolute_error: 4579.4233\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 90571186176.0000 - mean_squared_error: 90571186176.0000 - mean_absolute_error: 4483.9531\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 87565672448.0000 - mean_squared_error: 87565672448.0000 - mean_absolute_error: 4383.8364\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 84718927872.0000 - mean_squared_error: 84718927872.0000 - mean_absolute_error: 4295.7969\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 82010857472.0000 - mean_squared_error: 82010857472.0000 - mean_absolute_error: 4212.0220\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 79467151360.0000 - mean_squared_error: 79467151360.0000 - mean_absolute_error: 4134.7642\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 76958883840.0000 - mean_squared_error: 76958883840.0000 - mean_absolute_error: 4056.7773\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 74735828992.0000 - mean_squared_error: 74735828992.0000 - mean_absolute_error: 3984.9832\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 72582250496.0000 - mean_squared_error: 72582250496.0000 - mean_absolute_error: 3912.5466\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 70555099136.0000 - mean_squared_error: 70555099136.0000 - mean_absolute_error: 3847.6775\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 68536934400.0000 - mean_squared_error: 68536934400.0000 - mean_absolute_error: 3784.4258\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 66695823360.0000 - mean_squared_error: 66695823360.0000 - mean_absolute_error: 3720.0098\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 64822853632.0000 - mean_squared_error: 64822853632.0000 - mean_absolute_error: 3660.3054\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 964us/step - loss: 63027318784.0000 - mean_squared_error: 63027318784.0000 - mean_absolute_error: 3601.6914\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 61324673024.0000 - mean_squared_error: 61324673024.0000 - mean_absolute_error: 3546.2612\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 59754414080.0000 - mean_squared_error: 59754414080.0000 - mean_absolute_error: 3491.7769\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 58274443264.0000 - mean_squared_error: 58274443264.0000 - mean_absolute_error: 3438.3616\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 56689893376.0000 - mean_squared_error: 56689893376.0000 - mean_absolute_error: 3385.1045\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 55231741952.0000 - mean_squared_error: 55231741952.0000 - mean_absolute_error: 3333.0464\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 53929615360.0000 - mean_squared_error: 53929615360.0000 - mean_absolute_error: 3287.1943\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 52543221760.0000 - mean_squared_error: 52543221760.0000 - mean_absolute_error: 3241.7454\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 51217182720.0000 - mean_squared_error: 51217182720.0000 - mean_absolute_error: 3194.9197\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 50054393856.0000 - mean_squared_error: 50054393856.0000 - mean_absolute_error: 3154.4814\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 48840261632.0000 - mean_squared_error: 48840261632.0000 - mean_absolute_error: 3112.0603\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 47705878528.0000 - mean_squared_error: 47705878528.0000 - mean_absolute_error: 3071.0181\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 46528942080.0000 - mean_squared_error: 46528942080.0000 - mean_absolute_error: 3030.3911\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 45494079488.0000 - mean_squared_error: 45494079488.0000 - mean_absolute_error: 2991.8091\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 44420448256.0000 - mean_squared_error: 44420448256.0000 - mean_absolute_error: 2953.8672\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 43462307840.0000 - mean_squared_error: 43462307840.0000 - mean_absolute_error: 2916.0361\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 42472620032.0000 - mean_squared_error: 42472620032.0000 - mean_absolute_error: 2879.3906\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 41540468736.0000 - mean_squared_error: 41540468736.0000 - mean_absolute_error: 2843.9319\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 40553410560.0000 - mean_squared_error: 40553410560.0000 - mean_absolute_error: 2808.3145\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 39636262912.0000 - mean_squared_error: 39636262912.0000 - mean_absolute_error: 2772.8401\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 38853070848.0000 - mean_squared_error: 38853070848.0000 - mean_absolute_error: 2739.4954\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 38024187904.0000 - mean_squared_error: 38024187904.0000 - mean_absolute_error: 2708.1926\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 37201416192.0000 - mean_squared_error: 37201416192.0000 - mean_absolute_error: 2674.8054\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 36336791552.0000 - mean_squared_error: 36336791552.0000 - mean_absolute_error: 2643.0588\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 961us/step - loss: 35594530816.0000 - mean_squared_error: 35594530816.0000 - mean_absolute_error: 2611.4919\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 34837504000.0000 - mean_squared_error: 34837504000.0000 - mean_absolute_error: 2581.5994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 34106306560.0000 - mean_squared_error: 34106306560.0000 - mean_absolute_error: 2551.5205\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 33438400512.0000 - mean_squared_error: 33438400512.0000 - mean_absolute_error: 2523.0823\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 32718215168.0000 - mean_squared_error: 32718215168.0000 - mean_absolute_error: 2493.0715\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 32111892480.0000 - mean_squared_error: 32111892480.0000 - mean_absolute_error: 2465.4858\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 31438538752.0000 - mean_squared_error: 31438538752.0000 - mean_absolute_error: 2439.2253\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 30843330560.0000 - mean_squared_error: 30843330560.0000 - mean_absolute_error: 2411.6528\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 30238791680.0000 - mean_squared_error: 30238791680.0000 - mean_absolute_error: 2386.8721\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 29636495360.0000 - mean_squared_error: 29636495360.0000 - mean_absolute_error: 2360.3872\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 29027291136.0000 - mean_squared_error: 29027291136.0000 - mean_absolute_error: 2333.6863\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 28455407616.0000 - mean_squared_error: 28455407616.0000 - mean_absolute_error: 2307.7915\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 27899482112.0000 - mean_squared_error: 27899482112.0000 - mean_absolute_error: 2282.3901\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 27340146688.0000 - mean_squared_error: 27340146688.0000 - mean_absolute_error: 2256.4116\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 26806048768.0000 - mean_squared_error: 26806048768.0000 - mean_absolute_error: 2232.5200\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 26276016128.0000 - mean_squared_error: 26276016128.0000 - mean_absolute_error: 2207.9512\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 25769506816.0000 - mean_squared_error: 25769506816.0000 - mean_absolute_error: 2183.8955\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 25301571584.0000 - mean_squared_error: 25301571584.0000 - mean_absolute_error: 2161.2512\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 24844648448.0000 - mean_squared_error: 24844648448.0000 - mean_absolute_error: 2139.5127\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 24401340416.0000 - mean_squared_error: 24401340416.0000 - mean_absolute_error: 2117.2578\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 23917336576.0000 - mean_squared_error: 23917336576.0000 - mean_absolute_error: 2095.9111\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 23496982528.0000 - mean_squared_error: 23496982528.0000 - mean_absolute_error: 2074.2190\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 23044132864.0000 - mean_squared_error: 23044132864.0000 - mean_absolute_error: 2052.5295\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 22603257856.0000 - mean_squared_error: 22603257856.0000 - mean_absolute_error: 2030.4177\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 22203164672.0000 - mean_squared_error: 22203164672.0000 - mean_absolute_error: 2009.7526\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 964us/step - loss: 21775089664.0000 - mean_squared_error: 21775089664.0000 - mean_absolute_error: 1989.3479\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 21411747840.0000 - mean_squared_error: 21411747840.0000 - mean_absolute_error: 1968.4226\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 21025452032.0000 - mean_squared_error: 21025452032.0000 - mean_absolute_error: 1948.5850\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20607150080.0000 - mean_squared_error: 20607150080.0000 - mean_absolute_error: 1927.8057\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20243724288.0000 - mean_squared_error: 20243724288.0000 - mean_absolute_error: 1907.3069\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 19861151744.0000 - mean_squared_error: 19861151744.0000 - mean_absolute_error: 1887.7980\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 19496663040.0000 - mean_squared_error: 19496663040.0000 - mean_absolute_error: 1868.5973\n",
      "1172/1172 [==============================] - 1s 745us/step - loss: 19307171840.0000 - mean_squared_error: 19307171840.0000 - mean_absolute_error: 1857.9631\n",
      "--- Starting trial: run-8\n",
      "{'activation': 'elu', 'initial_learning_rate': 10.0, 'decay_step': 10, 'loss': 'mean_absolute_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2307.3752 - mean_absolute_error: 2307.3752\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 51.2920 - mean_absolute_error: 51.2920\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 39.7863 - mean_absolute_error: 39.7863\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 27.7615 - mean_absolute_error: 27.7615\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20.3832 - mean_absolute_error: 20.3832\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13.0589 - mean_absolute_error: 13.0589\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 11.0387 - mean_absolute_error: 11.0387\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9.0091 - mean_absolute_error: 9.0091\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8.5917 - mean_absolute_error: 8.5917\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 7.7840 - mean_absolute_error: 7.7840\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 7.3704 - mean_absolute_error: 7.3704\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6.9999 - mean_absolute_error: 6.9999\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 6.6759 - mean_absolute_error: 6.6759\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6.3789 - mean_absolute_error: 6.3789\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 6.1393 - mean_absolute_error: 6.1393\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.9373 - mean_absolute_error: 5.9373\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 988us/step - loss: 5.6375 - mean_absolute_error: 5.6375\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 4s 928us/step - loss: 5.5286 - mean_absolute_error: 5.5286\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 981us/step - loss: 5.3434 - mean_absolute_error: 5.3434\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.4190 - mean_absolute_error: 5.4190\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.0329 - mean_absolute_error: 5.0329\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.8884 - mean_absolute_error: 4.8884\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 4.8946 - mean_absolute_error: 4.8946\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 4.6592 - mean_absolute_error: 4.6592\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 988us/step - loss: 4.5510 - mean_absolute_error: 4.5510\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 4.5450 - mean_absolute_error: 4.5450\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 988us/step - loss: 4.3698 - mean_absolute_error: 4.3698\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 4.3048 - mean_absolute_error: 4.3048\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 4.2271 - mean_absolute_error: 4.2271\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2834 - mean_absolute_error: 4.2834\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 4.1416 - mean_absolute_error: 4.1416\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.0668 - mean_absolute_error: 4.0668\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 4.0171 - mean_absolute_error: 4.0171\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 3.9744 - mean_absolute_error: 3.9744\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 3.9048 - mean_absolute_error: 3.9048\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 3.8911 - mean_absolute_error: 3.8911\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 988us/step - loss: 3.9154 - mean_absolute_error: 3.9154\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 3.7960 - mean_absolute_error: 3.7960\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 3.7574 - mean_absolute_error: 3.7574\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 3.7154 - mean_absolute_error: 3.7154\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.7720 - mean_absolute_error: 3.7720\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.6484 - mean_absolute_error: 3.6484\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 4s 942us/step - loss: 3.6047 - mean_absolute_error: 3.6047\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 975us/step - loss: 3.5808 - mean_absolute_error: 3.5808\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 3.5476 - mean_absolute_error: 3.5476\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 3.5180 - mean_absolute_error: 3.5180\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 3.5321 - mean_absolute_error: 3.5321\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 3.4503 - mean_absolute_error: 3.4503\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 3.4144 - mean_absolute_error: 3.4144\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 3.4224 - mean_absolute_error: 3.4224\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 3.3656 - mean_absolute_error: 3.3656\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 3.3326 - mean_absolute_error: 3.3326\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.3015 - mean_absolute_error: 3.3015\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 990us/step - loss: 3.2779 - mean_absolute_error: 3.2779\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.2868 - mean_absolute_error: 3.2868\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.2121 - mean_absolute_error: 3.2121\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.1995 - mean_absolute_error: 3.1995\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 3.1834 - mean_absolute_error: 3.1834\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 3.1856 - mean_absolute_error: 3.1856\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 3.1322 - mean_absolute_error: 3.1322\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.1160 - mean_absolute_error: 3.1160\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 3.0811 - mean_absolute_error: 3.0811\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.0726 - mean_absolute_error: 3.0726\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.0517 - mean_absolute_error: 3.0517\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.0181 - mean_absolute_error: 3.0181\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.9989 - mean_absolute_error: 2.9989\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.9787 - mean_absolute_error: 2.9787\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 2.9669 - mean_absolute_error: 2.9669\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 983us/step - loss: 2.9464 - mean_absolute_error: 2.9464\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.9275 - mean_absolute_error: 2.9275\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.9143 - mean_absolute_error: 2.9143\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.8880 - mean_absolute_error: 2.8880\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.8655 - mean_absolute_error: 2.8655\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.8546 - mean_absolute_error: 2.8546\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.8404 - mean_absolute_error: 2.8404\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 2.8297 - mean_absolute_error: 2.8297\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 2.8122 - mean_absolute_error: 2.8122\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.7918 - mean_absolute_error: 2.7918\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.7800 - mean_absolute_error: 2.7800\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 2.7563 - mean_absolute_error: 2.7563\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.7360 - mean_absolute_error: 2.7360\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.7238 - mean_absolute_error: 2.7238\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.7142 - mean_absolute_error: 2.7142\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6997 - mean_absolute_error: 2.6997\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6804 - mean_absolute_error: 2.6804\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 2.6606 - mean_absolute_error: 2.6606\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.6504 - mean_absolute_error: 2.6504\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6400 - mean_absolute_error: 2.6400\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 2.6254 - mean_absolute_error: 2.6254\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.6103 - mean_absolute_error: 2.6103\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6020 - mean_absolute_error: 2.6020\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.5867 - mean_absolute_error: 2.5867\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 967us/step - loss: 2.5642 - mean_absolute_error: 2.5642\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.5719 - mean_absolute_error: 2.5719\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.5559 - mean_absolute_error: 2.5559\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 2.5374 - mean_absolute_error: 2.5374\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 2.5213 - mean_absolute_error: 2.5213\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 2.5174 - mean_absolute_error: 2.5174\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 2.5017 - mean_absolute_error: 2.5017\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.4899 - mean_absolute_error: 2.4899\n",
      "1172/1172 [==============================] - 1s 703us/step - loss: 2.4711 - mean_absolute_error: 2.4711\n",
      "--- Starting trial: run-9\n",
      "{'activation': 'elu', 'initial_learning_rate': 10.0, 'decay_step': 10, 'loss': 'mean_squared_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 235266530869248.0000 - mean_squared_error: 235266530869248.0000 - mean_absolute_error: 172544.6562\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6281527033856.0000 - mean_squared_error: 6281527033856.0000 - mean_absolute_error: 70234.4688\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 1562892566528.0000 - mean_squared_error: 1562892566528.0000 - mean_absolute_error: 35939.6133\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 405983657984.0000 - mean_squared_error: 405983657984.0000 - mean_absolute_error: 18047.3438\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 180185710592.0000 - mean_squared_error: 180185710592.0000 - mean_absolute_error: 11572.2031\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 92548374528.0000 - mean_squared_error: 92548374528.0000 - mean_absolute_error: 8211.1270\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 43731197952.0000 - mean_squared_error: 43731197952.0000 - mean_absolute_error: 6358.4761\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 16233442304.0000 - mean_squared_error: 16233442304.0000 - mean_absolute_error: 4837.8657\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3829399552.0000 - mean_squared_error: 3829399552.0000 - mean_absolute_error: 3943.8635\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 876553536.0000 - mean_squared_error: 876553536.0000 - mean_absolute_error: 3237.3894\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 569334464.0000 - mean_squared_error: 569334464.0000 - mean_absolute_error: 2837.8540\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 296677248.0000 - mean_squared_error: 296677248.0000 - mean_absolute_error: 2570.9636\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 173737888.0000 - mean_squared_error: 173737888.0000 - mean_absolute_error: 2388.1775\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 80234456.0000 - mean_squared_error: 80234456.0000 - mean_absolute_error: 2232.7922\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 61260668.0000 - mean_squared_error: 61260668.0000 - mean_absolute_error: 2109.2742\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 46309480.0000 - mean_squared_error: 46309480.0000 - mean_absolute_error: 2029.1351\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 42817108.0000 - mean_squared_error: 42817108.0000 - mean_absolute_error: 1943.8853\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 966us/step - loss: 38605264.0000 - mean_squared_error: 38605264.0000 - mean_absolute_error: 1896.7949\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 35070796.0000 - mean_squared_error: 35070796.0000 - mean_absolute_error: 1819.9270\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 32945664.0000 - mean_squared_error: 32945664.0000 - mean_absolute_error: 1781.4376\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 31088576.0000 - mean_squared_error: 31088576.0000 - mean_absolute_error: 1734.7107\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 29280700.0000 - mean_squared_error: 29280700.0000 - mean_absolute_error: 1688.8457\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 27819338.0000 - mean_squared_error: 27819338.0000 - mean_absolute_error: 1669.0156\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 26451388.0000 - mean_squared_error: 26451388.0000 - mean_absolute_error: 1625.8826\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 25270586.0000 - mean_squared_error: 25270586.0000 - mean_absolute_error: 1597.7629\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 24134124.0000 - mean_squared_error: 24134124.0000 - mean_absolute_error: 1565.9611\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 23166898.0000 - mean_squared_error: 23166898.0000 - mean_absolute_error: 1547.2679\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 22253482.0000 - mean_squared_error: 22253482.0000 - mean_absolute_error: 1519.2948\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 21398492.0000 - mean_squared_error: 21398492.0000 - mean_absolute_error: 1508.4343\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20712094.0000 - mean_squared_error: 20712094.0000 - mean_absolute_error: 1467.1335\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 20007946.0000 - mean_squared_error: 20007946.0000 - mean_absolute_error: 1450.2034\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 19367802.0000 - mean_squared_error: 19367802.0000 - mean_absolute_error: 1432.6499\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 18779762.0000 - mean_squared_error: 18779762.0000 - mean_absolute_error: 1413.4186\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 18232402.0000 - mean_squared_error: 18232402.0000 - mean_absolute_error: 1396.3275\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 17699324.0000 - mean_squared_error: 17699324.0000 - mean_absolute_error: 1382.8252\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 17267194.0000 - mean_squared_error: 17267194.0000 - mean_absolute_error: 1368.0406\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 16778894.0000 - mean_squared_error: 16778894.0000 - mean_absolute_error: 1352.6779\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 16335381.0000 - mean_squared_error: 16335381.0000 - mean_absolute_error: 1341.8387\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 15947719.0000 - mean_squared_error: 15947719.0000 - mean_absolute_error: 1324.6101\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 15559223.0000 - mean_squared_error: 15559223.0000 - mean_absolute_error: 1316.9891\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 968us/step - loss: 15251798.0000 - mean_squared_error: 15251798.0000 - mean_absolute_error: 1304.3005\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 14928229.0000 - mean_squared_error: 14928229.0000 - mean_absolute_error: 1288.8014\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 14619025.0000 - mean_squared_error: 14619025.0000 - mean_absolute_error: 1273.6182\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 14297254.0000 - mean_squared_error: 14297254.0000 - mean_absolute_error: 1270.2079\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 14038982.0000 - mean_squared_error: 14038982.0000 - mean_absolute_error: 1260.5267\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13787483.0000 - mean_squared_error: 13787483.0000 - mean_absolute_error: 1249.7181\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13536414.0000 - mean_squared_error: 13536414.0000 - mean_absolute_error: 1242.9291\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13311011.0000 - mean_squared_error: 13311011.0000 - mean_absolute_error: 1230.9540\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13074297.0000 - mean_squared_error: 13074297.0000 - mean_absolute_error: 1213.1774\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12863995.0000 - mean_squared_error: 12863995.0000 - mean_absolute_error: 1209.2318\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12667143.0000 - mean_squared_error: 12667143.0000 - mean_absolute_error: 1197.0757\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12472143.0000 - mean_squared_error: 12472143.0000 - mean_absolute_error: 1193.4058\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12290499.0000 - mean_squared_error: 12290499.0000 - mean_absolute_error: 1185.2498\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 12117697.0000 - mean_squared_error: 12117697.0000 - mean_absolute_error: 1177.1622\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11954652.0000 - mean_squared_error: 11954652.0000 - mean_absolute_error: 1170.1101\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11790507.0000 - mean_squared_error: 11790507.0000 - mean_absolute_error: 1161.9945\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 11638199.0000 - mean_squared_error: 11638199.0000 - mean_absolute_error: 1154.4420\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11498599.0000 - mean_squared_error: 11498599.0000 - mean_absolute_error: 1149.6818\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11362353.0000 - mean_squared_error: 11362353.0000 - mean_absolute_error: 1142.8402\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11222361.0000 - mean_squared_error: 11222361.0000 - mean_absolute_error: 1140.3783\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11105044.0000 - mean_squared_error: 11105044.0000 - mean_absolute_error: 1130.3159\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10962734.0000 - mean_squared_error: 10962734.0000 - mean_absolute_error: 1125.6765\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10857941.0000 - mean_squared_error: 10857941.0000 - mean_absolute_error: 1120.8350\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10743533.0000 - mean_squared_error: 10743533.0000 - mean_absolute_error: 1111.9908\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10631599.0000 - mean_squared_error: 10631599.0000 - mean_absolute_error: 1108.4053\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 987us/step - loss: 10522087.0000 - mean_squared_error: 10522087.0000 - mean_absolute_error: 1107.1266\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10425332.0000 - mean_squared_error: 10425332.0000 - mean_absolute_error: 1095.9835\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10331026.0000 - mean_squared_error: 10331026.0000 - mean_absolute_error: 1092.8275\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10238614.0000 - mean_squared_error: 10238614.0000 - mean_absolute_error: 1086.4764\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10154509.0000 - mean_squared_error: 10154509.0000 - mean_absolute_error: 1081.9720\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10063390.0000 - mean_squared_error: 10063390.0000 - mean_absolute_error: 1078.4562\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9989490.0000 - mean_squared_error: 9989490.0000 - mean_absolute_error: 1072.1895\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9899801.0000 - mean_squared_error: 9899801.0000 - mean_absolute_error: 1066.0376\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9821148.0000 - mean_squared_error: 9821148.0000 - mean_absolute_error: 1065.2406\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 9746806.0000 - mean_squared_error: 9746806.0000 - mean_absolute_error: 1058.2367\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9667698.0000 - mean_squared_error: 9667698.0000 - mean_absolute_error: 1054.2401\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9599254.0000 - mean_squared_error: 9599254.0000 - mean_absolute_error: 1049.3474\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9520877.0000 - mean_squared_error: 9520877.0000 - mean_absolute_error: 1048.3217\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9462311.0000 - mean_squared_error: 9462311.0000 - mean_absolute_error: 1042.5028\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9398673.0000 - mean_squared_error: 9398673.0000 - mean_absolute_error: 1039.4670\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9341480.0000 - mean_squared_error: 9341480.0000 - mean_absolute_error: 1031.6859\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9279926.0000 - mean_squared_error: 9279926.0000 - mean_absolute_error: 1033.3057\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9212280.0000 - mean_squared_error: 9212280.0000 - mean_absolute_error: 1026.1292\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9158226.0000 - mean_squared_error: 9158226.0000 - mean_absolute_error: 1023.5027\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9103105.0000 - mean_squared_error: 9103105.0000 - mean_absolute_error: 1021.9122\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9053541.0000 - mean_squared_error: 9053541.0000 - mean_absolute_error: 1018.8636\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9001608.0000 - mean_squared_error: 9001608.0000 - mean_absolute_error: 1015.4648\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8947984.0000 - mean_squared_error: 8947984.0000 - mean_absolute_error: 1011.7209\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8899231.0000 - mean_squared_error: 8899231.0000 - mean_absolute_error: 1006.8013\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 980us/step - loss: 8848438.0000 - mean_squared_error: 8848438.0000 - mean_absolute_error: 1004.6366\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8801270.0000 - mean_squared_error: 8801270.0000 - mean_absolute_error: 1001.7446\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8762088.0000 - mean_squared_error: 8762088.0000 - mean_absolute_error: 999.1197\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 8715796.0000 - mean_squared_error: 8715796.0000 - mean_absolute_error: 994.4955\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8671461.0000 - mean_squared_error: 8671461.0000 - mean_absolute_error: 991.8847\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8629607.0000 - mean_squared_error: 8629607.0000 - mean_absolute_error: 989.2043\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8581023.0000 - mean_squared_error: 8581023.0000 - mean_absolute_error: 986.0445\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8548991.0000 - mean_squared_error: 8548991.0000 - mean_absolute_error: 984.8096\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8509212.0000 - mean_squared_error: 8509212.0000 - mean_absolute_error: 981.2053\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8471999.0000 - mean_squared_error: 8471999.0000 - mean_absolute_error: 978.2964\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8430437.0000 - mean_squared_error: 8430437.0000 - mean_absolute_error: 979.0519\n",
      "1172/1172 [==============================] - 1s 747us/step - loss: 8403621.0000 - mean_squared_error: 8403621.0000 - mean_absolute_error: 967.8953\n",
      "--- Starting trial: run-10\n",
      "{'activation': 'elu', 'initial_learning_rate': 10.0, 'decay_step': 50, 'loss': 'mean_absolute_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 973us/step - loss: 71245.6016 - mean_absolute_error: 71245.6016\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 417.7121 - mean_absolute_error: 417.7121\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 169.6315 - mean_absolute_error: 169.6315\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 113.6403 - mean_absolute_error: 113.6403\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 93.3218 - mean_absolute_error: 93.3218\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 50.6105 - mean_absolute_error: 50.6105\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 42.7178 - mean_absolute_error: 42.7178\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 31.5152 - mean_absolute_error: 31.5152\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 27.1774 - mean_absolute_error: 27.1774\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 23.3528 - mean_absolute_error: 23.3528\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 20.7481 - mean_absolute_error: 20.7481\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 19.8417 - mean_absolute_error: 19.8417\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 16.9497 - mean_absolute_error: 16.9497\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 971us/step - loss: 15.7698 - mean_absolute_error: 15.7698\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 4s 931us/step - loss: 14.9656 - mean_absolute_error: 14.9656\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 977us/step - loss: 13.4618 - mean_absolute_error: 13.4618\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 12.8713 - mean_absolute_error: 12.8713\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 11.1578 - mean_absolute_error: 11.1578\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 11.0278 - mean_absolute_error: 11.0278\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 10.8562 - mean_absolute_error: 10.8562\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 10.2314 - mean_absolute_error: 10.2314\n",
      "Epoch 22/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9.4974 - mean_absolute_error: 9.4974\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 9.5098 - mean_absolute_error: 9.5098\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8.4434 - mean_absolute_error: 8.4434\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 8.8347 - mean_absolute_error: 8.8347\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 7.7395 - mean_absolute_error: 7.7395\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 7.8384 - mean_absolute_error: 7.8384\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 7.4097 - mean_absolute_error: 7.4097\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 7.8618 - mean_absolute_error: 7.8618\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 7.1408 - mean_absolute_error: 7.1408\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 6.4642 - mean_absolute_error: 6.4642\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 6.5318 - mean_absolute_error: 6.5318\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 6.4199 - mean_absolute_error: 6.4199\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 6.2731 - mean_absolute_error: 6.2731\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1000us/step - loss: 5.9021 - mean_absolute_error: 5.9021\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 5.9735 - mean_absolute_error: 5.9735\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.8656 - mean_absolute_error: 5.8656\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5.5831 - mean_absolute_error: 5.5831\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 981us/step - loss: 5.0105 - mean_absolute_error: 5.0105\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 4s 930us/step - loss: 5.3355 - mean_absolute_error: 5.3355\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 975us/step - loss: 5.2578 - mean_absolute_error: 5.2578\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 5.0088 - mean_absolute_error: 5.0088\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 4.5419 - mean_absolute_error: 4.5419\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.6353 - mean_absolute_error: 4.6353\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 4.4886 - mean_absolute_error: 4.4886\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 4.2019 - mean_absolute_error: 4.2019\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 4.3476 - mean_absolute_error: 4.3476\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 4.2433 - mean_absolute_error: 4.2433\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 4.4255 - mean_absolute_error: 4.4255\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4.2395 - mean_absolute_error: 4.2395\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.9159 - mean_absolute_error: 3.9159\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.7537 - mean_absolute_error: 3.7537\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.9168 - mean_absolute_error: 3.9168\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.7813 - mean_absolute_error: 3.7813\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.5916 - mean_absolute_error: 3.5916\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.8037 - mean_absolute_error: 3.8037\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.3692 - mean_absolute_error: 3.3692\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 3.4916 - mean_absolute_error: 3.4916\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 3.5661 - mean_absolute_error: 3.5661\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 3.3998 - mean_absolute_error: 3.3998\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.2645 - mean_absolute_error: 3.2645\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3.3908 - mean_absolute_error: 3.3908\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 990us/step - loss: 3.3178 - mean_absolute_error: 3.3178\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 4s 955us/step - loss: 3.3110 - mean_absolute_error: 3.3110\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 4s 937us/step - loss: 3.1237 - mean_absolute_error: 3.1237\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 980us/step - loss: 3.0179 - mean_absolute_error: 3.0179\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 2.8872 - mean_absolute_error: 2.8872\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 2.8791 - mean_absolute_error: 2.8791\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 3.2145 - mean_absolute_error: 3.2145\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 3.0492 - mean_absolute_error: 3.0492\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 2.9446 - mean_absolute_error: 2.9446\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 992us/step - loss: 2.9017 - mean_absolute_error: 2.9017\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 988us/step - loss: 2.8358 - mean_absolute_error: 2.8358\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 2.7903 - mean_absolute_error: 2.7903\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.7766 - mean_absolute_error: 2.7766\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 5s 989us/step - loss: 2.6953 - mean_absolute_error: 2.6953\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.6843 - mean_absolute_error: 2.6843\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 994us/step - loss: 2.4646 - mean_absolute_error: 2.4646\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 2.6512 - mean_absolute_error: 2.6512\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 990us/step - loss: 2.5163 - mean_absolute_error: 2.5163\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 995us/step - loss: 2.7303 - mean_absolute_error: 2.7303\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 2.5397 - mean_absolute_error: 2.5397\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.3940 - mean_absolute_error: 2.3940\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 989us/step - loss: 2.3975 - mean_absolute_error: 2.3975\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 989us/step - loss: 2.3749 - mean_absolute_error: 2.3749\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 2.2990 - mean_absolute_error: 2.2990\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.1241 - mean_absolute_error: 2.1241\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 2.4004 - mean_absolute_error: 2.4004\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 989us/step - loss: 2.2144 - mean_absolute_error: 2.2144\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 4s 936us/step - loss: 2.2332 - mean_absolute_error: 2.2332\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 980us/step - loss: 2.0177 - mean_absolute_error: 2.0177\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 987us/step - loss: 2.3649 - mean_absolute_error: 2.3649\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 2.1441 - mean_absolute_error: 2.1441\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 998us/step - loss: 2.1767 - mean_absolute_error: 2.1767\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 989us/step - loss: 2.1890 - mean_absolute_error: 2.1890\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 2.1525 - mean_absolute_error: 2.1525\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 991us/step - loss: 1.9150 - mean_absolute_error: 1.9150\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 2.0609 - mean_absolute_error: 2.0609\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 5s 993us/step - loss: 2.0868 - mean_absolute_error: 2.0868\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2.1476 - mean_absolute_error: 2.1476\n",
      "1172/1172 [==============================] - 1s 714us/step - loss: 1.9595 - mean_absolute_error: 1.9595\n",
      "--- Starting trial: run-11\n",
      "{'activation': 'elu', 'initial_learning_rate': 10.0, 'decay_step': 50, 'loss': 'mean_squared_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4955533475840.0000 - mean_squared_error: 4955533475840.0000 - mean_absolute_error: 64277.4648\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6931130368.0000 - mean_squared_error: 6931130368.0000 - mean_absolute_error: 28459.2051\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1435803776.0000 - mean_squared_error: 1435803776.0000 - mean_absolute_error: 13623.3477\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 297141984.0000 - mean_squared_error: 297141984.0000 - mean_absolute_error: 5198.6387\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 38698816.0000 - mean_squared_error: 38698816.0000 - mean_absolute_error: 1711.9197\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3601908.2500 - mean_squared_error: 3601908.2500 - mean_absolute_error: 545.0778\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 400883.2500 - mean_squared_error: 400883.2500 - mean_absolute_error: 226.5440\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 122232.1641 - mean_squared_error: 122232.1641 - mean_absolute_error: 156.2919\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 78083.8516 - mean_squared_error: 78083.8516 - mean_absolute_error: 140.0062\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 70592.3984 - mean_squared_error: 70592.3984 - mean_absolute_error: 134.5708\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 51896.1289 - mean_squared_error: 51896.1289 - mean_absolute_error: 128.0306\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 47042.9453 - mean_squared_error: 47042.9453 - mean_absolute_error: 123.8656\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 40947.0156 - mean_squared_error: 40947.0156 - mean_absolute_error: 115.8146\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 29918.5625 - mean_squared_error: 29918.5625 - mean_absolute_error: 93.7159\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 960us/step - loss: 20312.5547 - mean_squared_error: 20312.5547 - mean_absolute_error: 69.8257\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 16052.5566 - mean_squared_error: 16052.5566 - mean_absolute_error: 55.3881\n",
      "Epoch 17/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 14210.0986 - mean_squared_error: 14210.0986 - mean_absolute_error: 46.1045\n",
      "Epoch 18/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 11637.5107 - mean_squared_error: 11637.5107 - mean_absolute_error: 40.4603\n",
      "Epoch 19/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 10191.2861 - mean_squared_error: 10191.2861 - mean_absolute_error: 34.8618\n",
      "Epoch 20/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 9237.9805 - mean_squared_error: 9237.9805 - mean_absolute_error: 31.8922\n",
      "Epoch 21/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8192.2188 - mean_squared_error: 8192.2188 - mean_absolute_error: 29.6340\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 5s 1ms/step - loss: 8200.4365 - mean_squared_error: 8200.4365 - mean_absolute_error: 28.3640\n",
      "Epoch 23/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 7449.5762 - mean_squared_error: 7449.5762 - mean_absolute_error: 26.7300\n",
      "Epoch 24/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 7299.6089 - mean_squared_error: 7299.6089 - mean_absolute_error: 25.4844\n",
      "Epoch 25/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6474.6362 - mean_squared_error: 6474.6362 - mean_absolute_error: 23.3782\n",
      "Epoch 26/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5949.8022 - mean_squared_error: 5949.8022 - mean_absolute_error: 22.2480\n",
      "Epoch 27/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5908.7944 - mean_squared_error: 5908.7944 - mean_absolute_error: 21.7924\n",
      "Epoch 28/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 6171.0386 - mean_squared_error: 6171.0386 - mean_absolute_error: 21.3825\n",
      "Epoch 29/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5036.8164 - mean_squared_error: 5036.8164 - mean_absolute_error: 21.3285\n",
      "Epoch 30/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5374.7036 - mean_squared_error: 5374.7036 - mean_absolute_error: 20.3736\n",
      "Epoch 31/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4517.3643 - mean_squared_error: 4517.3643 - mean_absolute_error: 19.4792\n",
      "Epoch 32/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4730.1934 - mean_squared_error: 4730.1934 - mean_absolute_error: 18.9128\n",
      "Epoch 33/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 5868.4819 - mean_squared_error: 5868.4819 - mean_absolute_error: 19.3330\n",
      "Epoch 34/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 4184.8564 - mean_squared_error: 4184.8564 - mean_absolute_error: 18.4102\n",
      "Epoch 35/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 4080.4639 - mean_squared_error: 4080.4639 - mean_absolute_error: 18.1063\n",
      "Epoch 36/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3986.9265 - mean_squared_error: 3986.9265 - mean_absolute_error: 17.4568\n",
      "Epoch 37/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3451.6360 - mean_squared_error: 3451.6360 - mean_absolute_error: 16.9008\n",
      "Epoch 38/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3629.9673 - mean_squared_error: 3629.9673 - mean_absolute_error: 17.7728\n",
      "Epoch 39/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 3565.3220 - mean_squared_error: 3565.3220 - mean_absolute_error: 16.7159\n",
      "Epoch 40/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 6938408.5000 - mean_squared_error: 6938408.5000 - mean_absolute_error: 23.1976\n",
      "Epoch 41/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3244.0708 - mean_squared_error: 3244.0708 - mean_absolute_error: 16.0900\n",
      "Epoch 42/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3342.7007 - mean_squared_error: 3342.7007 - mean_absolute_error: 16.4254\n",
      "Epoch 43/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3023.2830 - mean_squared_error: 3023.2830 - mean_absolute_error: 15.5132\n",
      "Epoch 44/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3225.6885 - mean_squared_error: 3225.6885 - mean_absolute_error: 15.7665\n",
      "Epoch 45/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 3257.2200 - mean_squared_error: 3257.2200 - mean_absolute_error: 15.5068\n",
      "Epoch 46/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2924.6506 - mean_squared_error: 2924.6506 - mean_absolute_error: 14.5674\n",
      "Epoch 47/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2918.1677 - mean_squared_error: 2918.1677 - mean_absolute_error: 14.5521\n",
      "Epoch 48/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2826.0583 - mean_squared_error: 2826.0583 - mean_absolute_error: 14.6833\n",
      "Epoch 49/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2557.7473 - mean_squared_error: 2557.7473 - mean_absolute_error: 14.4176\n",
      "Epoch 50/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2648.1250 - mean_squared_error: 2648.1250 - mean_absolute_error: 14.7124\n",
      "Epoch 51/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 2440.5791 - mean_squared_error: 2440.5791 - mean_absolute_error: 13.7863\n",
      "Epoch 52/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2660.3198 - mean_squared_error: 2660.3198 - mean_absolute_error: 13.9968\n",
      "Epoch 53/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2487.7229 - mean_squared_error: 2487.7229 - mean_absolute_error: 13.8738\n",
      "Epoch 54/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2307.5771 - mean_squared_error: 2307.5771 - mean_absolute_error: 12.9885\n",
      "Epoch 55/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2256.4431 - mean_squared_error: 2256.4431 - mean_absolute_error: 13.3526\n",
      "Epoch 56/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2328.8750 - mean_squared_error: 2328.8750 - mean_absolute_error: 13.4749\n",
      "Epoch 57/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2359.0664 - mean_squared_error: 2359.0664 - mean_absolute_error: 13.4952\n",
      "Epoch 58/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2172.0151 - mean_squared_error: 2172.0151 - mean_absolute_error: 13.0041\n",
      "Epoch 59/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2157.2119 - mean_squared_error: 2157.2119 - mean_absolute_error: 13.1688\n",
      "Epoch 60/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2034.6334 - mean_squared_error: 2034.6334 - mean_absolute_error: 12.6653\n",
      "Epoch 61/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2127.8352 - mean_squared_error: 2127.8352 - mean_absolute_error: 12.7576\n",
      "Epoch 62/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 2009.8105 - mean_squared_error: 2009.8105 - mean_absolute_error: 12.2563\n",
      "Epoch 63/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1981.2869 - mean_squared_error: 1981.2869 - mean_absolute_error: 12.4117\n",
      "Epoch 64/100\n",
      "4688/4688 [==============================] - 5s 972us/step - loss: 1896.5464 - mean_squared_error: 1896.5464 - mean_absolute_error: 12.3565\n",
      "Epoch 65/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1980.5585 - mean_squared_error: 1980.5585 - mean_absolute_error: 12.2339\n",
      "Epoch 66/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1856.3580 - mean_squared_error: 1856.3580 - mean_absolute_error: 11.9224\n",
      "Epoch 67/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1764.4084 - mean_squared_error: 1764.4084 - mean_absolute_error: 11.6576\n",
      "Epoch 68/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 1700.5275 - mean_squared_error: 1700.5275 - mean_absolute_error: 11.7595\n",
      "Epoch 69/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1624.0443 - mean_squared_error: 1624.0443 - mean_absolute_error: 11.5601\n",
      "Epoch 70/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1739.8966 - mean_squared_error: 1739.8966 - mean_absolute_error: 11.8276\n",
      "Epoch 71/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1665.1737 - mean_squared_error: 1665.1737 - mean_absolute_error: 11.6982\n",
      "Epoch 72/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1618.8643 - mean_squared_error: 1618.8643 - mean_absolute_error: 11.2681\n",
      "Epoch 73/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1613.9142 - mean_squared_error: 1613.9142 - mean_absolute_error: 11.4136\n",
      "Epoch 74/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1622.2931 - mean_squared_error: 1622.2931 - mean_absolute_error: 11.1998\n",
      "Epoch 75/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1519.7953 - mean_squared_error: 1519.7953 - mean_absolute_error: 10.8100\n",
      "Epoch 76/100\n",
      "4688/4688 [==============================] - 10s 2ms/step - loss: 1663.1324 - mean_squared_error: 1663.1324 - mean_absolute_error: 11.2884\n",
      "Epoch 77/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1522.9722 - mean_squared_error: 1522.9722 - mean_absolute_error: 11.1005\n",
      "Epoch 78/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1425.4172 - mean_squared_error: 1425.4172 - mean_absolute_error: 10.9043\n",
      "Epoch 79/100\n",
      "4688/4688 [==============================] - 8s 2ms/step - loss: 1460.2424 - mean_squared_error: 1460.2424 - mean_absolute_error: 10.7804\n",
      "Epoch 80/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1415.4315 - mean_squared_error: 1415.4315 - mean_absolute_error: 10.8649\n",
      "Epoch 81/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1404.0211 - mean_squared_error: 1404.0211 - mean_absolute_error: 10.5928\n",
      "Epoch 82/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1326.5928 - mean_squared_error: 1326.5928 - mean_absolute_error: 10.5286\n",
      "Epoch 83/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1302.7267 - mean_squared_error: 1302.7267 - mean_absolute_error: 10.1644\n",
      "Epoch 84/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1350.2861 - mean_squared_error: 1350.2861 - mean_absolute_error: 10.5169\n",
      "Epoch 85/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1259.2452 - mean_squared_error: 1259.2452 - mean_absolute_error: 10.0938\n",
      "Epoch 86/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1264.0956 - mean_squared_error: 1264.0956 - mean_absolute_error: 10.4213\n",
      "Epoch 87/100\n",
      "4688/4688 [==============================] - 5s 985us/step - loss: 1284.1628 - mean_squared_error: 1284.1628 - mean_absolute_error: 10.1242\n",
      "Epoch 88/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1174.6414 - mean_squared_error: 1174.6414 - mean_absolute_error: 9.7275\n",
      "Epoch 89/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1226.0142 - mean_squared_error: 1226.0142 - mean_absolute_error: 10.1927\n",
      "Epoch 90/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1145.6561 - mean_squared_error: 1145.6561 - mean_absolute_error: 9.8735\n",
      "Epoch 91/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1195.5548 - mean_squared_error: 1195.5548 - mean_absolute_error: 9.7033\n",
      "Epoch 92/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1141.8146 - mean_squared_error: 1141.8146 - mean_absolute_error: 9.7587\n",
      "Epoch 93/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1126.6591 - mean_squared_error: 1126.6591 - mean_absolute_error: 9.5165\n",
      "Epoch 94/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1127.5107 - mean_squared_error: 1127.5107 - mean_absolute_error: 9.6142\n",
      "Epoch 95/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1089.4391 - mean_squared_error: 1089.4391 - mean_absolute_error: 9.3542\n",
      "Epoch 96/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1107.7262 - mean_squared_error: 1107.7262 - mean_absolute_error: 9.4818\n",
      "Epoch 97/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1010.6071 - mean_squared_error: 1010.6071 - mean_absolute_error: 9.2223\n",
      "Epoch 98/100\n",
      "4688/4688 [==============================] - 7s 1ms/step - loss: 1067.4657 - mean_squared_error: 1067.4657 - mean_absolute_error: 9.2789\n",
      "Epoch 99/100\n",
      "4688/4688 [==============================] - 7s 2ms/step - loss: 1070.0751 - mean_squared_error: 1070.0751 - mean_absolute_error: 9.4674\n",
      "Epoch 100/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 1044.6221 - mean_squared_error: 1044.6221 - mean_absolute_error: 9.0089\n",
      "1172/1172 [==============================] - 1s 773us/step - loss: 954.9729 - mean_squared_error: 954.9729 - mean_absolute_error: 10.8469\n",
      "--- Starting trial: run-12\n",
      "{'activation': 'linear', 'initial_learning_rate': 1.0, 'decay_step': 2, 'loss': 'mean_absolute_error'}\n",
      "Epoch 1/100\n",
      "4688/4688 [==============================] - 8s 1ms/step - loss: 285.8712 - mean_absolute_error: 285.8712\n",
      "Epoch 2/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 62.8902 - mean_absolute_error: 62.8902\n",
      "Epoch 3/100\n",
      "4688/4688 [==============================] - 5s 997us/step - loss: 36.2490 - mean_absolute_error: 36.2490\n",
      "Epoch 4/100\n",
      "4688/4688 [==============================] - 5s 981us/step - loss: 26.7955 - mean_absolute_error: 26.7955\n",
      "Epoch 5/100\n",
      "4688/4688 [==============================] - 5s 967us/step - loss: 22.8681 - mean_absolute_error: 22.8681\n",
      "Epoch 6/100\n",
      "4688/4688 [==============================] - 5s 999us/step - loss: 20.5705 - mean_absolute_error: 20.5705\n",
      "Epoch 7/100\n",
      "4688/4688 [==============================] - 40s 9ms/step - loss: 18.9795 - mean_absolute_error: 18.9795\n",
      "Epoch 8/100\n",
      "4688/4688 [==============================] - 5s 968us/step - loss: 17.8491 - mean_absolute_error: 17.8491\n",
      "Epoch 9/100\n",
      "4688/4688 [==============================] - 5s 985us/step - loss: 16.9511 - mean_absolute_error: 16.9511\n",
      "Epoch 10/100\n",
      "4688/4688 [==============================] - 5s 990us/step - loss: 16.1722 - mean_absolute_error: 16.1722\n",
      "Epoch 11/100\n",
      "4688/4688 [==============================] - 5s 977us/step - loss: 15.5109 - mean_absolute_error: 15.5109\n",
      "Epoch 12/100\n",
      "4688/4688 [==============================] - 6s 1ms/step - loss: 14.9123 - mean_absolute_error: 14.9123\n",
      "Epoch 13/100\n",
      "4688/4688 [==============================] - 16s 3ms/step - loss: 14.4460 - mean_absolute_error: 14.4460\n",
      "Epoch 14/100\n",
      "4688/4688 [==============================] - 13s 3ms/step - loss: 14.0421 - mean_absolute_error: 14.0421\n",
      "Epoch 15/100\n",
      "4688/4688 [==============================] - 5s 1ms/step - loss: 13.6609 - mean_absolute_error: 13.6609\n",
      "Epoch 16/100\n",
      "4688/4688 [==============================] - 5s 996us/step - loss: 13.3291 - mean_absolute_error: 13.3291\n",
      "Epoch 17/100\n",
      "3883/4688 [=======================>......] - ETA: 0s - loss: 13.1628 - mean_absolute_error: 13.1628"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for activation in HP_ACTIVATION.domain.values:\n",
    "    for initial_learning_rate in HP_INITIAL_LEARNING_RATE.domain.values:\n",
    "        for decay_step in HP_DECAY_STEP.domain.values:\n",
    "            for loss in HP_LOSS.domain.values:\n",
    "                hparams = {\n",
    "                    HP_ACTIVATION: activation,\n",
    "                    HP_INITIAL_LEARNING_RATE: initial_learning_rate,\n",
    "                    HP_DECAY_STEP: decay_step,\n",
    "                    HP_LOSS: loss,\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run('logs/hparam_tuning/' + run_name, hparams)\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc800495c40>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"376.240625pt\" height=\"262.518125pt\" viewBox=\"0 0 376.240625 262.518125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-11-30T23:00:53.074094</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 262.518125 \n",
       "L 376.240625 262.518125 \n",
       "L 376.240625 0 \n",
       "L 0 0 \n",
       "L 0 262.518125 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 34.240625 224.64 \n",
       "L 369.040625 224.64 \n",
       "L 369.040625 7.2 \n",
       "L 34.240625 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"md3a0d14038\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md3a0d14038\" x=\"110.94641\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- s0 -->\n",
       "      <g transform=\"translate(105.160473 239.238438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-73\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"52.099609\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_2\">\n",
       "     <!-- |s| -->\n",
       "     <g transform=\"translate(195.667188 252.960312)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-7c\" d=\"M 1344 4891 \n",
       "L 1344 -1509 \n",
       "L 813 -1509 \n",
       "L 813 4891 \n",
       "L 1344 4891 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-7c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"33.691406\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-7c\" x=\"85.791016\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m51038082a3\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m51038082a3\" x=\"34.240625\" y=\"214.756364\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(20.878125 218.555582)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m51038082a3\" x=\"34.240625\" y=\"17.083636\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(20.878125 20.882855)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_5\">\n",
       "     <!-- er -->\n",
       "     <g transform=\"translate(14.798437 121.052031)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"61.523438\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_4\">\n",
       "    <path d=\"M 49.458807 214.756364 \n",
       "L 52.533187 214.756364 \n",
       "L 55.607567 214.756364 \n",
       "L 58.681947 214.756364 \n",
       "L 61.756327 214.756364 \n",
       "L 64.830708 214.756364 \n",
       "L 67.905088 214.756364 \n",
       "L 70.979468 214.756364 \n",
       "L 74.053848 214.756364 \n",
       "L 77.128228 214.756364 \n",
       "L 80.202608 214.756364 \n",
       "L 83.276989 214.756364 \n",
       "L 86.351369 214.756364 \n",
       "L 89.425749 214.756364 \n",
       "L 92.500129 214.756364 \n",
       "L 95.574509 214.756364 \n",
       "L 98.648889 214.756364 \n",
       "L 101.72327 214.756364 \n",
       "L 104.79765 214.756364 \n",
       "L 107.87203 214.756364 \n",
       "L 110.94641 214.756364 \n",
       "L 114.02079 204.872727 \n",
       "L 117.09517 194.989091 \n",
       "L 120.169551 185.105455 \n",
       "L 123.243931 175.221818 \n",
       "L 126.318311 165.338182 \n",
       "L 129.392691 155.454545 \n",
       "L 132.467071 145.570909 \n",
       "L 135.541451 135.687273 \n",
       "L 138.615832 125.803636 \n",
       "L 141.690212 115.92 \n",
       "L 144.764592 106.036364 \n",
       "L 147.838972 96.152727 \n",
       "L 150.913352 86.269091 \n",
       "L 153.987732 76.385455 \n",
       "L 157.062113 66.501818 \n",
       "L 160.136493 56.618182 \n",
       "L 163.210873 46.734545 \n",
       "L 166.285253 36.850909 \n",
       "L 169.359633 26.967273 \n",
       "L 172.434013 17.083636 \n",
       "L 175.508394 17.083636 \n",
       "L 178.582774 17.083636 \n",
       "L 181.657154 17.083636 \n",
       "L 184.731534 17.083636 \n",
       "L 187.805914 17.083636 \n",
       "L 190.880294 17.083636 \n",
       "L 193.954675 17.083636 \n",
       "L 197.029055 17.083636 \n",
       "L 200.103435 17.083636 \n",
       "L 203.177815 17.083636 \n",
       "L 206.252195 17.083636 \n",
       "L 209.326575 17.083636 \n",
       "L 212.400956 17.083636 \n",
       "L 215.475336 17.083636 \n",
       "L 218.549716 17.083636 \n",
       "L 221.624096 17.083636 \n",
       "L 224.698476 17.083636 \n",
       "L 227.772856 17.083636 \n",
       "L 230.847237 17.083636 \n",
       "L 233.921617 17.083636 \n",
       "L 236.995997 17.083636 \n",
       "L 240.070377 17.083636 \n",
       "L 243.144757 17.083636 \n",
       "L 246.219137 17.083636 \n",
       "L 249.293518 17.083636 \n",
       "L 252.367898 17.083636 \n",
       "L 255.442278 17.083636 \n",
       "L 258.516658 17.083636 \n",
       "L 261.591038 17.083636 \n",
       "L 264.665418 17.083636 \n",
       "L 267.739799 17.083636 \n",
       "L 270.814179 17.083636 \n",
       "L 273.888559 17.083636 \n",
       "L 276.962939 17.083636 \n",
       "L 280.037319 17.083636 \n",
       "L 283.111699 17.083636 \n",
       "L 286.18608 17.083636 \n",
       "L 289.26046 17.083636 \n",
       "L 292.33484 17.083636 \n",
       "L 295.40922 17.083636 \n",
       "L 298.4836 17.083636 \n",
       "L 301.55798 17.083636 \n",
       "L 304.632361 17.083636 \n",
       "L 307.706741 17.083636 \n",
       "L 310.781121 17.083636 \n",
       "L 313.855501 17.083636 \n",
       "L 316.929881 17.083636 \n",
       "L 320.004261 17.083636 \n",
       "L 323.078642 17.083636 \n",
       "L 326.153022 17.083636 \n",
       "L 329.227402 17.083636 \n",
       "L 332.301782 17.083636 \n",
       "L 335.376162 17.083636 \n",
       "L 338.450542 17.083636 \n",
       "L 341.524923 17.083636 \n",
       "L 344.599303 17.083636 \n",
       "L 347.673683 17.083636 \n",
       "L 350.748063 17.083636 \n",
       "L 353.822443 17.083636 \n",
       "\" clip-path=\"url(#p7c23408a14)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 34.240625 224.64 \n",
       "L 34.240625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 369.040625 224.64 \n",
       "L 369.040625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 34.240625 224.64 \n",
       "L 369.040625 224.64 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 34.240625 7.2 \n",
       "L 369.040625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p7c23408a14\">\n",
       "   <rect x=\"34.240625\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s=np.arange(0,10,0.1)\n",
    "s0=2\n",
    "ones=np.ones(len(s))\n",
    "er=np.minimum(np.maximum(s/s0, ones)-ones,ones)\n",
    "plt.xlabel(\"|s|\")\n",
    "plt.ylabel(\"er\")\n",
    "plt.xticks([2], ['s0'])\n",
    "plt.yticks([0,1])\n",
    "plt.plot(s, er)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation functions review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 11s, sys: 43.4 s, total: 6min 55s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "histories['full_dnn_model_2'] = compile_and_fit(\n",
    "    full_dnn_model_2_linear,\n",
    "    max_epochs=100,\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_step=100,\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full_dnn_model_2_linear.evaluate(test_features, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "histories['TBNNModel2Concat'] = compile_and_fitTBNN(\n",
    "    TBNNModel2Concat,\n",
    "    max_epochs=100,\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_step=100,\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "histories['TBNNModel2Multiply'] = compile_and_fitTBNN(\n",
    "    TBNNModel2,\n",
    "    max_epochs=100,\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_step=100,\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"476.378125pt\" height=\"262.19625pt\" viewBox=\"0 0 476.378125 262.19625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-11-15T15:46:52.212764</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 262.19625 \n",
       "L 476.378125 262.19625 \n",
       "L 476.378125 0 \n",
       "L 0 0 \n",
       "L 0 262.19625 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 34.240625 224.64 \n",
       "L 369.040625 224.64 \n",
       "L 369.040625 7.2 \n",
       "L 34.240625 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 34.240625 224.64 \n",
       "L 34.240625 7.2 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m5ec73fdb58\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5ec73fdb58\" x=\"34.240625\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(31.059375 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 101.876989 224.64 \n",
       "L 101.876989 7.2 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5ec73fdb58\" x=\"101.876989\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(95.514489 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 169.513352 224.64 \n",
       "L 169.513352 7.2 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5ec73fdb58\" x=\"169.513352\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(163.150852 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 237.149716 224.64 \n",
       "L 237.149716 7.2 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5ec73fdb58\" x=\"237.149716\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(230.787216 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 304.78608 224.64 \n",
       "L 304.78608 7.2 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m5ec73fdb58\" x=\"304.78608\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(298.42358 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- Epochs -->\n",
       "     <g transform=\"translate(183.725 252.916562)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \n",
       "L 3578 4666 \n",
       "L 3578 4134 \n",
       "L 1259 4134 \n",
       "L 1259 2753 \n",
       "L 3481 2753 \n",
       "L 3481 2222 \n",
       "L 1259 2222 \n",
       "L 1259 531 \n",
       "L 3634 531 \n",
       "L 3634 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 34.240625 180.853512 \n",
       "L 369.040625 180.853512 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m12ca34ef31\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m12ca34ef31\" x=\"34.240625\" y=\"180.853512\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(20.878125 184.652731)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 34.240625 134.82126 \n",
       "L 369.040625 134.82126 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m12ca34ef31\" x=\"34.240625\" y=\"134.82126\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(20.878125 138.620479)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 34.240625 88.789008 \n",
       "L 369.040625 88.789008 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m12ca34ef31\" x=\"34.240625\" y=\"88.789008\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 3 -->\n",
       "      <g transform=\"translate(20.878125 92.588227)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 34.240625 42.756756 \n",
       "L 369.040625 42.756756 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m12ca34ef31\" x=\"34.240625\" y=\"42.756756\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(20.878125 46.555975)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_11\">\n",
       "     <!-- Mean Absolute Error -->\n",
       "     <g transform=\"translate(14.798438 166.759844)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4d\" d=\"M 628 4666 \n",
       "L 1569 4666 \n",
       "L 2759 1491 \n",
       "L 3956 4666 \n",
       "L 4897 4666 \n",
       "L 4897 0 \n",
       "L 4281 0 \n",
       "L 4281 4097 \n",
       "L 3078 897 \n",
       "L 2444 897 \n",
       "L 1241 4097 \n",
       "L 1241 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \n",
       "L 1331 1722 \n",
       "L 3047 1722 \n",
       "L 2188 4044 \n",
       "z\n",
       "M 1831 4666 \n",
       "L 2547 4666 \n",
       "L 4325 0 \n",
       "L 3669 0 \n",
       "L 3244 1197 \n",
       "L 1141 1197 \n",
       "L 716 0 \n",
       "L 50 0 \n",
       "L 1831 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "M 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2969 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4d\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"86.279297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"147.802734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"209.082031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"272.460938\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-41\" x=\"304.248047\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-62\" x=\"372.65625\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"436.132812\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"488.232422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"549.414062\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"577.197266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"640.576172\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"679.785156\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" x=\"741.308594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-45\" x=\"773.095703\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"836.279297\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"875.642578\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"914.505859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"975.6875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 37.573001 -1 \n",
       "L 37.622443 48.340895 \n",
       "L 41.004261 47.484323 \n",
       "L 44.38608 27.298679 \n",
       "L 47.767898 47.637138 \n",
       "L 51.149716 41.448631 \n",
       "L 54.531534 47.714007 \n",
       "L 57.913352 46.293092 \n",
       "L 61.29517 44.692758 \n",
       "L 64.676989 48.101894 \n",
       "L 68.058807 46.192912 \n",
       "L 71.440625 45.670768 \n",
       "L 74.822443 51.561438 \n",
       "L 78.204261 69.79622 \n",
       "L 81.58608 92.512642 \n",
       "L 84.967898 129.14098 \n",
       "L 88.349716 163.251869 \n",
       "L 91.731534 181.149344 \n",
       "L 95.113352 188.10826 \n",
       "L 98.49517 193.55805 \n",
       "L 101.876989 198.189111 \n",
       "L 105.258807 201.862642 \n",
       "L 108.640625 204.042124 \n",
       "L 112.022443 206.390133 \n",
       "L 115.404261 208.221136 \n",
       "L 118.78608 209.759263 \n",
       "L 122.167898 210.811238 \n",
       "L 125.549716 212.570863 \n",
       "L 128.931534 213.029411 \n",
       "L 132.313352 214.538277 \n",
       "L 135.69517 215.22704 \n",
       "L 139.076989 216.002649 \n",
       "L 142.458807 216.498339 \n",
       "L 145.840625 216.999009 \n",
       "L 149.222443 218.145133 \n",
       "L 152.604261 218.00571 \n",
       "L 155.98608 218.760513 \n",
       "L 159.367898 219.291118 \n",
       "L 162.749716 219.314794 \n",
       "L 166.131534 220.2479 \n",
       "L 169.513352 220.242439 \n",
       "L 172.89517 220.920615 \n",
       "L 176.276989 220.753989 \n",
       "L 179.658807 221.002767 \n",
       "L 183.040625 221.551761 \n",
       "L 186.422443 221.807616 \n",
       "L 189.804261 222.093467 \n",
       "L 193.18608 222.250483 \n",
       "L 196.567898 222.441264 \n",
       "L 199.949716 222.329683 \n",
       "L 203.331534 222.684966 \n",
       "L 206.713352 222.950118 \n",
       "L 210.09517 222.820991 \n",
       "L 213.476989 222.838048 \n",
       "L 216.858807 223.144261 \n",
       "L 220.240625 223.037198 \n",
       "L 223.622443 223.204285 \n",
       "L 227.004261 223.448819 \n",
       "L 230.38608 223.178567 \n",
       "L 233.767898 223.396535 \n",
       "L 237.149716 223.521748 \n",
       "L 240.531534 223.223195 \n",
       "L 243.913352 223.539081 \n",
       "L 247.29517 223.696048 \n",
       "L 250.676989 223.567226 \n",
       "L 254.058807 223.631012 \n",
       "L 257.440625 223.795107 \n",
       "L 260.822443 223.742651 \n",
       "L 264.204261 223.608165 \n",
       "L 267.58608 223.807191 \n",
       "L 270.967898 223.975613 \n",
       "L 274.349716 223.84446 \n",
       "L 277.731534 223.836704 \n",
       "L 281.113352 223.961139 \n",
       "L 284.49517 223.999105 \n",
       "L 287.876989 224.072156 \n",
       "L 291.258807 223.736447 \n",
       "L 294.640625 224.174199 \n",
       "L 298.022443 223.984663 \n",
       "L 301.404261 224.176647 \n",
       "L 304.78608 224.256896 \n",
       "L 308.167898 224.134197 \n",
       "L 311.549716 224.305807 \n",
       "L 314.931534 224.248858 \n",
       "L 318.313352 224.252147 \n",
       "L 321.69517 224.202817 \n",
       "L 325.076989 224.313359 \n",
       "L 328.458807 224.266227 \n",
       "L 331.840625 224.255902 \n",
       "L 335.222443 224.369816 \n",
       "L 338.604261 224.187641 \n",
       "L 341.98608 224.470803 \n",
       "L 345.367898 224.380472 \n",
       "L 348.749716 224.574135 \n",
       "L 352.131534 224.505645 \n",
       "L 355.513352 224.64 \n",
       "L 358.89517 224.570903 \n",
       "L 362.276989 224.587662 \n",
       "L 365.658807 224.600086 \n",
       "L 369.040625 224.465266 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_20\">\n",
       "    <path d=\"M 55.293526 -1 \n",
       "L 57.913352 7.728817 \n",
       "L 61.29517 11.014408 \n",
       "L 64.676989 19.090035 \n",
       "L 68.058807 23.734171 \n",
       "L 71.440625 24.539644 \n",
       "L 74.822443 24.722201 \n",
       "L 78.204261 24.847952 \n",
       "L 81.58608 25.833941 \n",
       "L 84.967898 26.00076 \n",
       "L 88.349716 26.195631 \n",
       "L 91.731534 26.56428 \n",
       "L 95.113352 26.684455 \n",
       "L 98.49517 26.852943 \n",
       "L 101.876989 27.096323 \n",
       "L 105.258807 27.184408 \n",
       "L 108.640625 27.280922 \n",
       "L 112.022443 27.504986 \n",
       "L 115.404261 27.59599 \n",
       "L 118.78608 27.587144 \n",
       "L 122.167898 27.632317 \n",
       "L 125.549716 27.650843 \n",
       "L 128.931534 27.693777 \n",
       "L 132.313352 27.698057 \n",
       "L 135.69517 27.719239 \n",
       "L 139.076989 27.732299 \n",
       "L 142.458807 27.861386 \n",
       "L 145.840625 28.038983 \n",
       "L 149.222443 28.140984 \n",
       "L 152.604261 28.182096 \n",
       "L 155.98608 28.221782 \n",
       "L 159.367898 28.238441 \n",
       "L 162.749716 28.234425 \n",
       "L 166.131534 28.231352 \n",
       "L 169.513352 28.255255 \n",
       "L 172.89517 28.326351 \n",
       "L 176.276989 28.409563 \n",
       "L 179.658807 28.441676 \n",
       "L 183.040625 28.527653 \n",
       "L 186.422443 28.580004 \n",
       "L 189.804261 28.587993 \n",
       "L 193.18608 28.603424 \n",
       "L 196.567898 28.610799 \n",
       "L 199.949716 28.615826 \n",
       "L 203.331534 28.647544 \n",
       "L 206.713352 28.69794 \n",
       "L 210.09517 28.701123 \n",
       "L 213.476989 28.704964 \n",
       "L 216.858807 28.707818 \n",
       "L 220.240625 28.718551 \n",
       "L 223.622443 28.717234 \n",
       "L 227.004261 28.72428 \n",
       "L 230.38608 28.728165 \n",
       "L 233.767898 28.758961 \n",
       "L 237.149716 28.788725 \n",
       "L 240.531534 28.828301 \n",
       "L 243.913352 28.848385 \n",
       "L 247.29517 28.911754 \n",
       "L 250.676989 28.936141 \n",
       "L 254.058807 28.953459 \n",
       "L 257.440625 28.951813 \n",
       "L 260.822443 28.957432 \n",
       "L 264.204261 28.96259 \n",
       "L 267.58608 28.965444 \n",
       "L 270.967898 28.974092 \n",
       "L 274.349716 28.965949 \n",
       "L 277.731534 28.97666 \n",
       "L 281.113352 28.974333 \n",
       "L 284.49517 28.986845 \n",
       "L 287.876989 28.984299 \n",
       "L 291.258807 28.985747 \n",
       "L 294.640625 28.983926 \n",
       "L 298.022443 28.989413 \n",
       "L 301.404261 28.990445 \n",
       "L 304.78608 28.988996 \n",
       "L 308.167898 28.992662 \n",
       "L 311.549716 28.999269 \n",
       "L 314.931534 28.99872 \n",
       "L 318.313352 29.002232 \n",
       "L 321.69517 29.009475 \n",
       "L 325.076989 29.013536 \n",
       "L 328.458807 29.006775 \n",
       "L 331.840625 29.015336 \n",
       "L 335.222443 29.013251 \n",
       "L 338.604261 29.010726 \n",
       "L 341.98608 29.016104 \n",
       "L 345.367898 29.021767 \n",
       "L 348.749716 29.01966 \n",
       "L 352.131534 29.025104 \n",
       "L 355.513352 29.020077 \n",
       "L 358.89517 29.033027 \n",
       "L 362.276989 29.026464 \n",
       "L 365.658807 29.023896 \n",
       "L 369.040625 29.025762 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #aec7e8; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 37.15646 -1 \n",
       "L 37.622443 48.432536 \n",
       "L 41.004261 48.433842 \n",
       "L 44.38608 48.434599 \n",
       "L 47.767898 48.435313 \n",
       "L 51.149716 48.435576 \n",
       "L 54.531534 48.435763 \n",
       "L 57.913352 48.436191 \n",
       "L 61.29517 48.439341 \n",
       "L 64.676989 48.447649 \n",
       "L 68.058807 48.450897 \n",
       "L 71.440625 48.45172 \n",
       "L 74.822443 48.452346 \n",
       "L 78.204261 48.452247 \n",
       "L 81.58608 48.452368 \n",
       "L 84.967898 48.452511 \n",
       "L 88.349716 48.452313 \n",
       "L 91.731534 48.452269 \n",
       "L 95.113352 48.452247 \n",
       "L 98.49517 48.452346 \n",
       "L 101.876989 48.452368 \n",
       "L 105.258807 48.452412 \n",
       "L 108.640625 48.452368 \n",
       "L 112.022443 48.452445 \n",
       "L 115.404261 48.452554 \n",
       "L 118.78608 48.452412 \n",
       "L 122.167898 48.452412 \n",
       "L 125.549716 48.452401 \n",
       "L 128.931534 48.452587 \n",
       "L 132.313352 48.452544 \n",
       "L 135.69517 48.452478 \n",
       "L 139.076989 48.452511 \n",
       "L 142.458807 48.452576 \n",
       "L 145.840625 48.452412 \n",
       "L 149.222443 48.452335 \n",
       "L 152.604261 48.452412 \n",
       "L 155.98608 48.452346 \n",
       "L 159.367898 48.452456 \n",
       "L 162.749716 48.452467 \n",
       "L 166.131534 48.452467 \n",
       "L 169.513352 48.452379 \n",
       "L 172.89517 48.452653 \n",
       "L 176.276989 48.452456 \n",
       "L 179.658807 48.452533 \n",
       "L 183.040625 48.4525 \n",
       "L 186.422443 48.452478 \n",
       "L 189.804261 48.4525 \n",
       "L 193.18608 48.452478 \n",
       "L 196.567898 48.452467 \n",
       "L 199.949716 48.452379 \n",
       "L 203.331534 48.452544 \n",
       "L 206.713352 48.452434 \n",
       "L 210.09517 48.452576 \n",
       "L 213.476989 48.452401 \n",
       "L 216.858807 48.452412 \n",
       "L 220.240625 48.452456 \n",
       "L 223.622443 48.452368 \n",
       "L 227.004261 48.4525 \n",
       "L 230.38608 48.452214 \n",
       "L 233.767898 48.452401 \n",
       "L 237.149716 48.452511 \n",
       "L 240.531534 48.452368 \n",
       "L 243.913352 48.452313 \n",
       "L 247.29517 48.452544 \n",
       "L 250.676989 48.452576 \n",
       "L 254.058807 48.452368 \n",
       "L 257.440625 48.452554 \n",
       "L 260.822443 48.452412 \n",
       "L 264.204261 48.452357 \n",
       "L 267.58608 48.452324 \n",
       "L 270.967898 48.452587 \n",
       "L 274.349716 48.452533 \n",
       "L 277.731534 48.4525 \n",
       "L 281.113352 48.452467 \n",
       "L 284.49517 48.452478 \n",
       "L 287.876989 48.452412 \n",
       "L 291.258807 48.452357 \n",
       "L 294.640625 48.452346 \n",
       "L 298.022443 48.452554 \n",
       "L 301.404261 48.452357 \n",
       "L 304.78608 48.452598 \n",
       "L 308.167898 48.452423 \n",
       "L 311.549716 48.452368 \n",
       "L 314.931534 48.452379 \n",
       "L 318.313352 48.452225 \n",
       "L 321.69517 48.4525 \n",
       "L 325.076989 48.452565 \n",
       "L 328.458807 48.452379 \n",
       "L 331.840625 48.452609 \n",
       "L 335.222443 48.452379 \n",
       "L 338.604261 48.452412 \n",
       "L 341.98608 48.452368 \n",
       "L 345.367898 48.452598 \n",
       "L 348.749716 48.452401 \n",
       "L 352.131534 48.452598 \n",
       "L 355.513352 48.452324 \n",
       "L 358.89517 48.452478 \n",
       "L 362.276989 48.452379 \n",
       "L 365.658807 48.452456 \n",
       "L 369.040625 48.452368 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\">\n",
       "    <path d=\"M 37.530034 -1 \n",
       "L 37.622443 30.687215 \n",
       "L 41.004261 30.483037 \n",
       "L 44.38608 30.581943 \n",
       "L 47.767898 31.107072 \n",
       "L 51.149716 31.760982 \n",
       "L 54.531534 32.551748 \n",
       "L 57.913352 33.553695 \n",
       "L 61.29517 33.964289 \n",
       "L 64.676989 34.1569 \n",
       "L 68.058807 34.31979 \n",
       "L 71.440625 34.632861 \n",
       "L 74.822443 34.749349 \n",
       "L 78.204261 34.806814 \n",
       "L 81.58608 34.894526 \n",
       "L 84.967898 35.226079 \n",
       "L 88.349716 35.394873 \n",
       "L 91.731534 35.6865 \n",
       "L 95.113352 35.868025 \n",
       "L 98.49517 36.063555 \n",
       "L 101.876989 36.150608 \n",
       "L 105.258807 36.343065 \n",
       "L 108.640625 36.386569 \n",
       "L 112.022443 36.395964 \n",
       "L 115.404261 36.516644 \n",
       "L 118.78608 36.627557 \n",
       "L 122.167898 36.692529 \n",
       "L 125.549716 36.762022 \n",
       "L 128.931534 36.890539 \n",
       "L 132.313352 37.06008 \n",
       "L 135.69517 37.139692 \n",
       "L 139.076989 37.271238 \n",
       "L 142.458807 37.303306 \n",
       "L 145.840625 37.377431 \n",
       "L 149.222443 37.456187 \n",
       "L 152.604261 37.529105 \n",
       "L 155.98608 37.626957 \n",
       "L 159.367898 37.689888 \n",
       "L 162.749716 37.743314 \n",
       "L 166.131534 37.753959 \n",
       "L 169.513352 37.750513 \n",
       "L 172.89517 37.761005 \n",
       "L 176.276989 37.758349 \n",
       "L 179.658807 37.761796 \n",
       "L 183.040625 37.764232 \n",
       "L 186.422443 37.774022 \n",
       "L 189.804261 37.781594 \n",
       "L 193.18608 37.773275 \n",
       "L 196.567898 37.774066 \n",
       "L 199.949716 37.77738 \n",
       "L 203.331534 37.791055 \n",
       "L 206.713352 37.780541 \n",
       "L 210.09517 37.790528 \n",
       "L 213.476989 37.790089 \n",
       "L 216.858807 37.791889 \n",
       "L 220.240625 37.794106 \n",
       "L 223.622443 37.793711 \n",
       "L 227.004261 37.797815 \n",
       "L 230.38608 37.803544 \n",
       "L 233.767898 37.80091 \n",
       "L 237.149716 37.799286 \n",
       "L 240.531534 37.802315 \n",
       "L 243.913352 37.806859 \n",
       "L 247.29517 37.809866 \n",
       "L 250.676989 37.811271 \n",
       "L 254.058807 37.812368 \n",
       "L 257.440625 37.814585 \n",
       "L 260.822443 37.8179 \n",
       "L 264.204261 37.81599 \n",
       "L 267.58608 37.814629 \n",
       "L 270.967898 37.812961 \n",
       "L 274.349716 37.820643 \n",
       "L 277.731534 37.818997 \n",
       "L 281.113352 37.820292 \n",
       "L 284.49517 37.824002 \n",
       "L 287.876989 37.822202 \n",
       "L 291.258807 37.822158 \n",
       "L 294.640625 37.822882 \n",
       "L 298.022443 37.827996 \n",
       "L 301.404261 37.82387 \n",
       "L 304.78608 37.827184 \n",
       "L 308.167898 37.830279 \n",
       "L 311.549716 37.827711 \n",
       "L 314.931534 37.830916 \n",
       "L 318.313352 37.827316 \n",
       "L 321.69517 37.831267 \n",
       "L 325.076989 37.832167 \n",
       "L 328.458807 37.834647 \n",
       "L 331.840625 37.833418 \n",
       "L 335.222443 37.837457 \n",
       "L 338.604261 37.834779 \n",
       "L 341.98608 37.837676 \n",
       "L 345.367898 37.83434 \n",
       "L 348.749716 37.832891 \n",
       "L 352.131534 37.837501 \n",
       "L 355.513352 37.837764 \n",
       "L 358.89517 37.839893 \n",
       "L 362.276989 37.839784 \n",
       "L 365.658807 37.839893 \n",
       "L 369.040625 37.84222 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #ffbb78; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_23\">\n",
       "    <path d=\"M 34.240625 8.575227 \n",
       "L 37.622443 8.575227 \n",
       "L 41.004261 8.574941 \n",
       "L 44.38608 8.575227 \n",
       "L 47.767898 8.575051 \n",
       "L 51.149716 8.575139 \n",
       "L 54.531534 8.575402 \n",
       "L 57.913352 8.575095 \n",
       "L 61.29517 8.575337 \n",
       "L 64.676989 8.575205 \n",
       "L 68.058807 8.575161 \n",
       "L 71.440625 8.575029 \n",
       "L 74.822443 8.575073 \n",
       "L 78.204261 8.575227 \n",
       "L 81.58608 8.575051 \n",
       "L 84.967898 8.575029 \n",
       "L 88.349716 8.575293 \n",
       "L 91.731534 8.575095 \n",
       "L 95.113352 8.575007 \n",
       "L 98.49517 8.575073 \n",
       "L 101.876989 8.575293 \n",
       "L 105.258807 8.575029 \n",
       "L 108.640625 8.575073 \n",
       "L 112.022443 8.574941 \n",
       "L 115.404261 8.574963 \n",
       "L 118.78608 8.574854 \n",
       "L 122.167898 8.575315 \n",
       "L 125.549716 8.575139 \n",
       "L 128.931534 8.575029 \n",
       "L 132.313352 8.575227 \n",
       "L 135.69517 8.574985 \n",
       "L 139.076989 8.575161 \n",
       "L 142.458807 8.575139 \n",
       "L 145.840625 8.575161 \n",
       "L 149.222443 8.575139 \n",
       "L 152.604261 8.575161 \n",
       "L 155.98608 8.575007 \n",
       "L 159.367898 8.575271 \n",
       "L 162.749716 8.574766 \n",
       "L 166.131534 8.575073 \n",
       "L 169.513352 8.575051 \n",
       "L 172.89517 8.575227 \n",
       "L 176.276989 8.57481 \n",
       "L 179.658807 8.575227 \n",
       "L 183.040625 8.575117 \n",
       "L 186.422443 8.575358 \n",
       "L 189.804261 8.575205 \n",
       "L 193.18608 8.575073 \n",
       "L 196.567898 8.575227 \n",
       "L 199.949716 8.575051 \n",
       "L 203.331534 8.574898 \n",
       "L 206.713352 8.575161 \n",
       "L 210.09517 8.575117 \n",
       "L 213.476989 8.575073 \n",
       "L 216.858807 8.575271 \n",
       "L 220.240625 8.575117 \n",
       "L 223.622443 8.575227 \n",
       "L 227.004261 8.575358 \n",
       "L 230.38608 8.575007 \n",
       "L 233.767898 8.575029 \n",
       "L 237.149716 8.575073 \n",
       "L 240.531534 8.575161 \n",
       "L 243.913352 8.575095 \n",
       "L 247.29517 8.575007 \n",
       "L 250.676989 8.575095 \n",
       "L 254.058807 8.575073 \n",
       "L 257.440625 8.575139 \n",
       "L 260.822443 8.575227 \n",
       "L 264.204261 8.575117 \n",
       "L 267.58608 8.575117 \n",
       "L 270.967898 8.575446 \n",
       "L 274.349716 8.574832 \n",
       "L 277.731534 8.575139 \n",
       "L 281.113352 8.575161 \n",
       "L 284.49517 8.575205 \n",
       "L 287.876989 8.575205 \n",
       "L 291.258807 8.575051 \n",
       "L 294.640625 8.575073 \n",
       "L 298.022443 8.574985 \n",
       "L 301.404261 8.575095 \n",
       "L 304.78608 8.575161 \n",
       "L 308.167898 8.575073 \n",
       "L 311.549716 8.575293 \n",
       "L 314.931534 8.575249 \n",
       "L 318.313352 8.575161 \n",
       "L 321.69517 8.575205 \n",
       "L 325.076989 8.575315 \n",
       "L 328.458807 8.575117 \n",
       "L 331.840625 8.575293 \n",
       "L 335.222443 8.574985 \n",
       "L 338.604261 8.574941 \n",
       "L 341.98608 8.575139 \n",
       "L 345.367898 8.574985 \n",
       "L 348.749716 8.575293 \n",
       "L 352.131534 8.574941 \n",
       "L 355.513352 8.575161 \n",
       "L 358.89517 8.575051 \n",
       "L 362.276989 8.575249 \n",
       "L 365.658807 8.575315 \n",
       "L 369.040625 8.575095 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_24\">\n",
       "    <path clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #98df8a; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path d=\"M 37.138139 -1 \n",
       "L 37.622443 48.412222 \n",
       "L 41.004261 48.411958 \n",
       "L 44.38608 48.411903 \n",
       "L 47.767898 48.411881 \n",
       "L 51.149716 48.412145 \n",
       "L 54.531534 48.411728 \n",
       "L 57.913352 48.411826 \n",
       "L 61.29517 48.41209 \n",
       "L 64.676989 48.412101 \n",
       "L 68.058807 48.411947 \n",
       "L 71.440625 48.411936 \n",
       "L 74.822443 48.411958 \n",
       "L 78.204261 48.412024 \n",
       "L 81.58608 48.411892 \n",
       "L 84.967898 48.411881 \n",
       "L 88.349716 48.411958 \n",
       "L 91.731534 48.412156 \n",
       "L 95.113352 48.412013 \n",
       "L 98.49517 48.411969 \n",
       "L 101.876989 48.411892 \n",
       "L 105.258807 48.411892 \n",
       "L 108.640625 48.412057 \n",
       "L 112.022443 48.412068 \n",
       "L 115.404261 48.412013 \n",
       "L 118.78608 48.411914 \n",
       "L 122.167898 48.411805 \n",
       "L 125.549716 48.411859 \n",
       "L 128.931534 48.412068 \n",
       "L 132.313352 48.411936 \n",
       "L 135.69517 48.411958 \n",
       "L 139.076989 48.411936 \n",
       "L 142.458807 48.411947 \n",
       "L 145.840625 48.411881 \n",
       "L 149.222443 48.411958 \n",
       "L 152.604261 48.411903 \n",
       "L 155.98608 48.411739 \n",
       "L 159.367898 48.412046 \n",
       "L 162.749716 48.41187 \n",
       "L 166.131534 48.412035 \n",
       "L 169.513352 48.411947 \n",
       "L 172.89517 48.412211 \n",
       "L 176.276989 48.411936 \n",
       "L 179.658807 48.412068 \n",
       "L 183.040625 48.411892 \n",
       "L 186.422443 48.412002 \n",
       "L 189.804261 48.412046 \n",
       "L 193.18608 48.412046 \n",
       "L 196.567898 48.411925 \n",
       "L 199.949716 48.411837 \n",
       "L 203.331534 48.411969 \n",
       "L 206.713352 48.411914 \n",
       "L 210.09517 48.411969 \n",
       "L 213.476989 48.412035 \n",
       "L 216.858807 48.412002 \n",
       "L 220.240625 48.411903 \n",
       "L 223.622443 48.411991 \n",
       "L 227.004261 48.411925 \n",
       "L 230.38608 48.412013 \n",
       "L 233.767898 48.412013 \n",
       "L 237.149716 48.411881 \n",
       "L 240.531534 48.411772 \n",
       "L 243.913352 48.411805 \n",
       "L 247.29517 48.411859 \n",
       "L 250.676989 48.412035 \n",
       "L 254.058807 48.411826 \n",
       "L 257.440625 48.411761 \n",
       "L 260.822443 48.412002 \n",
       "L 264.204261 48.411903 \n",
       "L 267.58608 48.411826 \n",
       "L 270.967898 48.411958 \n",
       "L 274.349716 48.411837 \n",
       "L 277.731534 48.411969 \n",
       "L 281.113352 48.411914 \n",
       "L 284.49517 48.412002 \n",
       "L 287.876989 48.411903 \n",
       "L 291.258807 48.412156 \n",
       "L 294.640625 48.412024 \n",
       "L 298.022443 48.411826 \n",
       "L 301.404261 48.411958 \n",
       "L 304.78608 48.411826 \n",
       "L 308.167898 48.412068 \n",
       "L 311.549716 48.411859 \n",
       "L 314.931534 48.411826 \n",
       "L 318.313352 48.411881 \n",
       "L 321.69517 48.412035 \n",
       "L 325.076989 48.411991 \n",
       "L 328.458807 48.411783 \n",
       "L 331.840625 48.412024 \n",
       "L 335.222443 48.411958 \n",
       "L 338.604261 48.411925 \n",
       "L 341.98608 48.411826 \n",
       "L 345.367898 48.411881 \n",
       "L 348.749716 48.411991 \n",
       "L 352.131534 48.41209 \n",
       "L 355.513352 48.41187 \n",
       "L 358.89517 48.412101 \n",
       "L 362.276989 48.412024 \n",
       "L 365.658807 48.411925 \n",
       "L 369.040625 48.411805 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_26\">\n",
       "    <path d=\"M 37.033981 -1 \n",
       "L 37.622443 47.411943 \n",
       "L 41.004261 47.480745 \n",
       "L 44.38608 47.74849 \n",
       "L 47.767898 47.94965 \n",
       "L 51.149716 48.014621 \n",
       "L 54.531534 48.123646 \n",
       "L 57.913352 48.103705 \n",
       "L 61.29517 48.211128 \n",
       "L 64.676989 48.302253 \n",
       "L 68.058807 48.391347 \n",
       "L 71.440625 48.398283 \n",
       "L 74.822443 48.407404 \n",
       "L 78.204261 48.406229 \n",
       "L 81.58608 48.409423 \n",
       "L 84.967898 48.410334 \n",
       "L 88.349716 48.411387 \n",
       "L 91.731534 48.411837 \n",
       "L 95.113352 48.411563 \n",
       "L 98.49517 48.411969 \n",
       "L 101.876989 48.41187 \n",
       "L 105.258807 48.412002 \n",
       "L 108.640625 48.411958 \n",
       "L 112.022443 48.411936 \n",
       "L 115.404261 48.412002 \n",
       "L 118.78608 48.412178 \n",
       "L 122.167898 48.412046 \n",
       "L 125.549716 48.411925 \n",
       "L 128.931534 48.411947 \n",
       "L 132.313352 48.412013 \n",
       "L 135.69517 48.411991 \n",
       "L 139.076989 48.412123 \n",
       "L 142.458807 48.411991 \n",
       "L 145.840625 48.412035 \n",
       "L 149.222443 48.411969 \n",
       "L 152.604261 48.41187 \n",
       "L 155.98608 48.411925 \n",
       "L 159.367898 48.411837 \n",
       "L 162.749716 48.411892 \n",
       "L 166.131534 48.411761 \n",
       "L 169.513352 48.412068 \n",
       "L 172.89517 48.412068 \n",
       "L 176.276989 48.411892 \n",
       "L 179.658807 48.411826 \n",
       "L 183.040625 48.411969 \n",
       "L 186.422443 48.411859 \n",
       "L 189.804261 48.411914 \n",
       "L 193.18608 48.411881 \n",
       "L 196.567898 48.411925 \n",
       "L 199.949716 48.411859 \n",
       "L 203.331534 48.412035 \n",
       "L 206.713352 48.412002 \n",
       "L 210.09517 48.412013 \n",
       "L 213.476989 48.411969 \n",
       "L 216.858807 48.412101 \n",
       "L 220.240625 48.411947 \n",
       "L 223.622443 48.411815 \n",
       "L 227.004261 48.412002 \n",
       "L 230.38608 48.41209 \n",
       "L 233.767898 48.412035 \n",
       "L 237.149716 48.411947 \n",
       "L 240.531534 48.411837 \n",
       "L 243.913352 48.411837 \n",
       "L 247.29517 48.411695 \n",
       "L 250.676989 48.411925 \n",
       "L 254.058807 48.412123 \n",
       "L 257.440625 48.412068 \n",
       "L 260.822443 48.411881 \n",
       "L 264.204261 48.412013 \n",
       "L 267.58608 48.411969 \n",
       "L 270.967898 48.411859 \n",
       "L 274.349716 48.412079 \n",
       "L 277.731534 48.411947 \n",
       "L 281.113352 48.411881 \n",
       "L 284.49517 48.412013 \n",
       "L 287.876989 48.411925 \n",
       "L 291.258807 48.411892 \n",
       "L 294.640625 48.411914 \n",
       "L 298.022443 48.411892 \n",
       "L 301.404261 48.412024 \n",
       "L 304.78608 48.411815 \n",
       "L 308.167898 48.411947 \n",
       "L 311.549716 48.41187 \n",
       "L 314.931534 48.411925 \n",
       "L 318.313352 48.411761 \n",
       "L 321.69517 48.412013 \n",
       "L 325.076989 48.412035 \n",
       "L 328.458807 48.411903 \n",
       "L 331.840625 48.411925 \n",
       "L 335.222443 48.412156 \n",
       "L 338.604261 48.412035 \n",
       "L 341.98608 48.411936 \n",
       "L 345.367898 48.411958 \n",
       "L 348.749716 48.411991 \n",
       "L 352.131534 48.412013 \n",
       "L 355.513352 48.411914 \n",
       "L 358.89517 48.412013 \n",
       "L 362.276989 48.411892 \n",
       "L 365.658807 48.412035 \n",
       "L 369.040625 48.412013 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #ff9896; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_27\">\n",
       "    <path d=\"M 34.240625 45.376409 \n",
       "L 37.622443 45.379812 \n",
       "L 41.004261 45.380251 \n",
       "L 44.38608 45.379845 \n",
       "L 47.767898 45.379954 \n",
       "L 51.149716 45.379779 \n",
       "L 54.531534 45.379976 \n",
       "L 57.913352 45.379812 \n",
       "L 61.29517 45.379735 \n",
       "L 64.676989 45.379812 \n",
       "L 68.058807 45.37979 \n",
       "L 71.440625 45.380009 \n",
       "L 74.822443 45.379943 \n",
       "L 78.204261 45.379866 \n",
       "L 81.58608 45.379932 \n",
       "L 84.967898 45.379932 \n",
       "L 88.349716 45.379943 \n",
       "L 91.731534 45.379823 \n",
       "L 95.113352 45.379823 \n",
       "L 98.49517 45.379768 \n",
       "L 101.876989 45.380031 \n",
       "L 105.258807 45.379998 \n",
       "L 108.640625 45.379877 \n",
       "L 112.022443 45.379932 \n",
       "L 115.404261 45.379845 \n",
       "L 118.78608 45.379845 \n",
       "L 122.167898 45.379877 \n",
       "L 125.549716 45.379943 \n",
       "L 128.931534 45.379954 \n",
       "L 132.313352 45.379877 \n",
       "L 135.69517 45.379921 \n",
       "L 139.076989 45.379998 \n",
       "L 142.458807 45.379888 \n",
       "L 145.840625 45.379899 \n",
       "L 149.222443 45.380042 \n",
       "L 152.604261 45.379658 \n",
       "L 155.98608 45.37991 \n",
       "L 159.367898 45.379877 \n",
       "L 162.749716 45.379954 \n",
       "L 166.131534 45.379943 \n",
       "L 169.513352 45.379724 \n",
       "L 172.89517 45.380031 \n",
       "L 176.276989 45.379768 \n",
       "L 179.658807 45.379866 \n",
       "L 183.040625 45.379998 \n",
       "L 186.422443 45.379779 \n",
       "L 189.804261 45.379845 \n",
       "L 193.18608 45.37991 \n",
       "L 196.567898 45.380031 \n",
       "L 199.949716 45.37991 \n",
       "L 203.331534 45.379921 \n",
       "L 206.713352 45.37979 \n",
       "L 210.09517 45.379943 \n",
       "L 213.476989 45.379801 \n",
       "L 216.858807 45.380053 \n",
       "L 220.240625 45.379987 \n",
       "L 223.622443 45.37991 \n",
       "L 227.004261 45.379888 \n",
       "L 230.38608 45.380152 \n",
       "L 233.767898 45.380042 \n",
       "L 237.149716 45.379976 \n",
       "L 240.531534 45.379932 \n",
       "L 243.913352 45.379888 \n",
       "L 247.29517 45.379943 \n",
       "L 250.676989 45.379845 \n",
       "L 254.058807 45.379921 \n",
       "L 257.440625 45.379823 \n",
       "L 260.822443 45.379845 \n",
       "L 264.204261 45.379504 \n",
       "L 267.58608 45.380009 \n",
       "L 270.967898 45.380042 \n",
       "L 274.349716 45.379888 \n",
       "L 277.731534 45.379921 \n",
       "L 281.113352 45.37979 \n",
       "L 284.49517 45.379943 \n",
       "L 287.876989 45.379779 \n",
       "L 291.258807 45.379976 \n",
       "L 294.640625 45.379899 \n",
       "L 298.022443 45.38002 \n",
       "L 301.404261 45.380119 \n",
       "L 304.78608 45.379987 \n",
       "L 308.167898 45.379735 \n",
       "L 311.549716 45.37991 \n",
       "L 314.931534 45.380075 \n",
       "L 318.313352 45.379943 \n",
       "L 321.69517 45.37991 \n",
       "L 325.076989 45.379757 \n",
       "L 328.458807 45.379812 \n",
       "L 331.840625 45.37991 \n",
       "L 335.222443 45.379855 \n",
       "L 338.604261 45.379954 \n",
       "L 341.98608 45.379823 \n",
       "L 345.367898 45.379998 \n",
       "L 348.749716 45.379855 \n",
       "L 352.131534 45.379899 \n",
       "L 355.513352 45.379998 \n",
       "L 358.89517 45.379899 \n",
       "L 362.276989 45.379746 \n",
       "L 365.658807 45.379888 \n",
       "L 369.040625 45.379888 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_28\">\n",
       "    <path d=\"M 34.240625 7.969673 \n",
       "L 37.622443 19.142144 \n",
       "L 41.004261 44.324933 \n",
       "L 44.38608 48.378079 \n",
       "L 47.767898 48.668596 \n",
       "L 51.149716 48.899213 \n",
       "L 54.531534 49.03044 \n",
       "L 57.913352 49.169778 \n",
       "L 61.29517 49.296418 \n",
       "L 64.676989 49.369423 \n",
       "L 68.058807 49.46304 \n",
       "L 71.440625 49.524422 \n",
       "L 74.822443 49.593608 \n",
       "L 78.204261 49.639242 \n",
       "L 81.58608 49.669423 \n",
       "L 84.967898 49.711721 \n",
       "L 88.349716 49.757805 \n",
       "L 91.731534 49.773466 \n",
       "L 95.113352 49.793495 \n",
       "L 98.49517 49.825377 \n",
       "L 101.876989 49.850675 \n",
       "L 105.258807 49.850203 \n",
       "L 108.640625 49.885015 \n",
       "L 112.022443 49.890097 \n",
       "L 115.404261 49.916886 \n",
       "L 118.78608 49.92751 \n",
       "L 122.167898 49.928224 \n",
       "L 125.549716 49.951447 \n",
       "L 128.931534 49.951117 \n",
       "L 132.313352 49.970323 \n",
       "L 135.69517 49.987269 \n",
       "L 139.076989 50.002743 \n",
       "L 142.458807 50.025264 \n",
       "L 145.840625 50.041935 \n",
       "L 149.222443 50.066058 \n",
       "L 152.604261 50.079447 \n",
       "L 155.98608 50.096711 \n",
       "L 159.367898 50.106083 \n",
       "L 162.749716 50.114611 \n",
       "L 166.131534 50.134146 \n",
       "L 169.513352 50.138482 \n",
       "L 172.89517 50.154022 \n",
       "L 176.276989 50.165513 \n",
       "L 179.658807 50.168059 \n",
       "L 183.040625 50.172965 \n",
       "L 186.422443 50.182217 \n",
       "L 189.804261 50.188911 \n",
       "L 193.18608 50.195452 \n",
       "L 196.567898 50.201434 \n",
       "L 199.949716 50.214187 \n",
       "L 203.331534 50.217512 \n",
       "L 206.713352 50.225535 \n",
       "L 210.09517 50.22953 \n",
       "L 213.476989 50.233228 \n",
       "L 216.858807 50.239144 \n",
       "L 220.240625 50.239199 \n",
       "L 223.622443 50.245871 \n",
       "L 227.004261 50.250722 \n",
       "L 230.38608 50.252928 \n",
       "L 233.767898 50.250953 \n",
       "L 237.149716 50.261203 \n",
       "L 240.531534 50.26094 \n",
       "L 243.913352 50.26522 \n",
       "L 247.29517 50.267777 \n",
       "L 250.676989 50.266724 \n",
       "L 254.058807 50.271531 \n",
       "L 257.440625 50.276579 \n",
       "L 260.822443 50.279082 \n",
       "L 264.204261 50.280706 \n",
       "L 267.58608 50.281694 \n",
       "L 270.967898 50.283351 \n",
       "L 274.349716 50.288015 \n",
       "L 277.731534 50.28818 \n",
       "L 281.113352 50.289398 \n",
       "L 284.49517 50.294721 \n",
       "L 287.876989 50.295972 \n",
       "L 291.258807 50.299714 \n",
       "L 294.640625 50.303632 \n",
       "L 298.022443 50.306234 \n",
       "L 301.404261 50.306486 \n",
       "L 304.78608 50.30664 \n",
       "L 308.167898 50.312379 \n",
       "L 311.549716 50.310854 \n",
       "L 314.931534 50.312786 \n",
       "L 318.313352 50.315727 \n",
       "L 321.69517 50.318427 \n",
       "L 325.076989 50.323025 \n",
       "L 328.458807 50.321006 \n",
       "L 331.840625 50.322729 \n",
       "L 335.222443 50.325725 \n",
       "L 338.604261 50.32533 \n",
       "L 341.98608 50.325604 \n",
       "L 345.367898 50.330367 \n",
       "L 348.749716 50.331948 \n",
       "L 352.131534 50.334132 \n",
       "L 355.513352 50.330049 \n",
       "L 358.89517 50.332716 \n",
       "L 362.276989 50.334384 \n",
       "L 365.658807 50.337995 \n",
       "L 369.040625 50.338324 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #c5b0d5; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_29\">\n",
       "    <path d=\"M 37.027919 -1 \n",
       "L 37.622443 45.379899 \n",
       "L 41.004261 45.711079 \n",
       "L 44.38608 46.181004 \n",
       "L 47.767898 46.871811 \n",
       "L 51.149716 46.738367 \n",
       "L 54.531534 47.522944 \n",
       "L 57.913352 47.466642 \n",
       "L 61.29517 48.131263 \n",
       "L 64.676989 48.394848 \n",
       "L 68.058807 48.398163 \n",
       "L 71.440625 48.409566 \n",
       "L 74.822443 48.406109 \n",
       "L 78.204261 48.4104 \n",
       "L 81.58608 48.406921 \n",
       "L 84.967898 48.403903 \n",
       "L 88.349716 48.406361 \n",
       "L 91.731534 48.411113 \n",
       "L 95.113352 48.409873 \n",
       "L 98.49517 48.411278 \n",
       "L 101.876989 48.408556 \n",
       "L 105.258807 48.408128 \n",
       "L 108.640625 48.411508 \n",
       "L 112.022443 48.407963 \n",
       "L 115.404261 48.410927 \n",
       "L 118.78608 48.409214 \n",
       "L 122.167898 48.410652 \n",
       "L 125.549716 48.409456 \n",
       "L 128.931534 48.407008 \n",
       "L 132.313352 48.408545 \n",
       "L 135.69517 48.408589 \n",
       "L 139.076989 48.406833 \n",
       "L 142.458807 48.408007 \n",
       "L 145.840625 48.409214 \n",
       "L 149.222443 48.407766 \n",
       "L 152.604261 48.408325 \n",
       "L 155.98608 48.408852 \n",
       "L 159.367898 48.40804 \n",
       "L 162.749716 48.409302 \n",
       "L 166.131534 48.409401 \n",
       "L 169.513352 48.409796 \n",
       "L 172.89517 48.407788 \n",
       "L 176.276989 48.408358 \n",
       "L 179.658807 48.408666 \n",
       "L 183.040625 48.409214 \n",
       "L 186.422443 48.409467 \n",
       "L 189.804261 48.408699 \n",
       "L 193.18608 48.409467 \n",
       "L 196.567898 48.409346 \n",
       "L 199.949716 48.410455 \n",
       "L 203.331534 48.410378 \n",
       "L 206.713352 48.410992 \n",
       "L 210.09517 48.412331 \n",
       "L 213.476989 48.411805 \n",
       "L 216.858807 48.413506 \n",
       "L 220.240625 48.409851 \n",
       "L 223.622443 48.409182 \n",
       "L 227.004261 48.410564 \n",
       "L 230.38608 48.409192 \n",
       "L 233.767898 48.412463 \n",
       "L 237.149716 48.414274 \n",
       "L 240.531534 48.410202 \n",
       "L 243.913352 48.407008 \n",
       "L 247.29517 48.414976 \n",
       "L 250.676989 48.421572 \n",
       "L 254.058807 48.410883 \n",
       "L 257.440625 48.409434 \n",
       "L 260.822443 48.419399 \n",
       "L 264.204261 48.413561 \n",
       "L 267.58608 48.402564 \n",
       "L 270.967898 48.413067 \n",
       "L 274.349716 48.41457 \n",
       "L 277.731534 48.409621 \n",
       "L 281.113352 48.410674 \n",
       "L 284.49517 48.41322 \n",
       "L 287.876989 48.412792 \n",
       "L 291.258807 48.408984 \n",
       "L 294.640625 48.412507 \n",
       "L 298.022443 48.409225 \n",
       "L 301.404261 48.414065 \n",
       "L 304.78608 48.412935 \n",
       "L 308.167898 48.407799 \n",
       "L 311.549716 48.417424 \n",
       "L 314.931534 48.402201 \n",
       "L 318.313352 48.403815 \n",
       "L 321.69517 48.413067 \n",
       "L 325.076989 48.417731 \n",
       "L 328.458807 48.410564 \n",
       "L 331.840625 48.406032 \n",
       "L 335.222443 48.418796 \n",
       "L 338.604261 48.422736 \n",
       "L 341.98608 48.420288 \n",
       "L 345.367898 48.420705 \n",
       "L 348.749716 48.418247 \n",
       "L 352.131534 48.420903 \n",
       "L 355.513352 48.427905 \n",
       "L 358.89517 48.42267 \n",
       "L 362.276989 48.416425 \n",
       "L 365.658807 48.419213 \n",
       "L 369.040625 48.425589 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_30\">\n",
       "    <path d=\"M 34.240625 7.232003 \n",
       "L 37.622443 7.199518 \n",
       "L 41.004261 7.2 \n",
       "L 44.38608 7.199649 \n",
       "L 47.767898 7.199671 \n",
       "L 51.149716 7.199781 \n",
       "L 54.531534 7.199891 \n",
       "L 57.913352 7.199913 \n",
       "L 61.29517 7.199452 \n",
       "L 64.676989 7.19943 \n",
       "L 68.058807 7.199869 \n",
       "L 71.440625 7.199518 \n",
       "L 74.822443 7.199781 \n",
       "L 78.204261 7.199496 \n",
       "L 81.58608 7.199474 \n",
       "L 84.967898 7.199605 \n",
       "L 88.349716 7.199781 \n",
       "L 91.731534 7.199583 \n",
       "L 95.113352 7.199781 \n",
       "L 98.49517 7.199825 \n",
       "L 101.876989 7.199891 \n",
       "L 105.258807 7.19943 \n",
       "L 108.640625 7.19943 \n",
       "L 112.022443 7.199715 \n",
       "L 115.404261 7.199869 \n",
       "L 118.78608 7.199825 \n",
       "L 122.167898 7.199693 \n",
       "L 125.549716 7.199649 \n",
       "L 128.931534 7.199649 \n",
       "L 132.313352 7.199671 \n",
       "L 135.69517 7.199737 \n",
       "L 139.076989 7.199627 \n",
       "L 142.458807 7.199825 \n",
       "L 145.840625 7.199847 \n",
       "L 149.222443 7.199605 \n",
       "L 152.604261 7.199452 \n",
       "L 155.98608 7.199693 \n",
       "L 159.367898 7.199935 \n",
       "L 162.749716 7.2 \n",
       "L 166.131534 7.199627 \n",
       "L 169.513352 7.199715 \n",
       "L 172.89517 7.199825 \n",
       "L 176.276989 7.199561 \n",
       "L 179.658807 7.199693 \n",
       "L 183.040625 7.199561 \n",
       "L 186.422443 7.199847 \n",
       "L 189.804261 7.199649 \n",
       "L 193.18608 7.199627 \n",
       "L 196.567898 7.199605 \n",
       "L 199.949716 7.199671 \n",
       "L 203.331534 7.199869 \n",
       "L 206.713352 7.2 \n",
       "L 210.09517 7.199715 \n",
       "L 213.476989 7.199847 \n",
       "L 216.858807 7.199978 \n",
       "L 220.240625 7.199496 \n",
       "L 223.622443 7.199276 \n",
       "L 227.004261 7.199561 \n",
       "L 230.38608 7.199715 \n",
       "L 233.767898 7.199737 \n",
       "L 237.149716 7.199386 \n",
       "L 240.531534 7.199978 \n",
       "L 243.913352 7.199561 \n",
       "L 247.29517 7.199715 \n",
       "L 250.676989 7.199605 \n",
       "L 254.058807 7.199649 \n",
       "L 257.440625 7.19943 \n",
       "L 260.822443 7.199715 \n",
       "L 264.204261 7.199737 \n",
       "L 267.58608 7.19932 \n",
       "L 270.967898 7.199408 \n",
       "L 274.349716 7.199693 \n",
       "L 277.731534 7.199825 \n",
       "L 281.113352 7.200022 \n",
       "L 284.49517 7.199737 \n",
       "L 287.876989 7.199781 \n",
       "L 291.258807 7.199605 \n",
       "L 294.640625 7.199671 \n",
       "L 298.022443 7.199561 \n",
       "L 301.404261 7.199386 \n",
       "L 304.78608 7.199935 \n",
       "L 308.167898 7.199715 \n",
       "L 311.549716 7.199561 \n",
       "L 314.931534 7.199869 \n",
       "L 318.313352 7.19943 \n",
       "L 321.69517 7.199605 \n",
       "L 325.076989 7.199627 \n",
       "L 328.458807 7.199715 \n",
       "L 331.840625 7.199627 \n",
       "L 335.222443 7.199737 \n",
       "L 338.604261 7.199649 \n",
       "L 341.98608 7.199737 \n",
       "L 345.367898 7.199496 \n",
       "L 348.749716 7.199605 \n",
       "L 352.131534 7.199496 \n",
       "L 355.513352 7.199715 \n",
       "L 358.89517 7.199605 \n",
       "L 362.276989 7.199781 \n",
       "L 365.658807 7.199737 \n",
       "L 369.040625 7.19943 \n",
       "\" clip-path=\"url(#p56529ad6ac)\" style=\"fill: none; stroke: #c49c94; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 34.240625 224.64 \n",
       "L 34.240625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 369.040625 224.64 \n",
       "L 369.040625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 34.240625 224.64 \n",
       "L 369.040625 224.64 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 34.240625 7.2 \n",
       "L 369.040625 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 376.040625 191.3375 \n",
       "L 467.178125 191.3375 \n",
       "Q 469.178125 191.3375 469.178125 189.3375 \n",
       "L 469.178125 14.2 \n",
       "Q 469.178125 12.2 467.178125 12.2 \n",
       "L 376.040625 12.2 \n",
       "Q 374.040625 12.2 374.040625 14.2 \n",
       "L 374.040625 189.3375 \n",
       "Q 374.040625 191.3375 376.040625 191.3375 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_31\">\n",
       "     <path d=\"M 378.040625 20.298437 \n",
       "L 388.040625 20.298437 \n",
       "L 398.040625 20.298437 \n",
       "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- Linear -->\n",
       "     <g transform=\"translate(406.040625 23.798437)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"55.712891\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"83.496094\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"146.875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"208.398438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"269.677734\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_32\">\n",
       "     <path d=\"M 378.040625 34.976562 \n",
       "L 388.040625 34.976562 \n",
       "L 398.040625 34.976562 \n",
       "\" style=\"fill: none; stroke: #aec7e8; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- Selu -->\n",
       "     <g transform=\"translate(406.040625 38.476562)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
       "L 3425 3897 \n",
       "Q 3066 4069 2747 4153 \n",
       "Q 2428 4238 2131 4238 \n",
       "Q 1616 4238 1336 4038 \n",
       "Q 1056 3838 1056 3469 \n",
       "Q 1056 3159 1242 3001 \n",
       "Q 1428 2844 1947 2747 \n",
       "L 2328 2669 \n",
       "Q 3034 2534 3370 2195 \n",
       "Q 3706 1856 3706 1288 \n",
       "Q 3706 609 3251 259 \n",
       "Q 2797 -91 1919 -91 \n",
       "Q 1588 -91 1214 -16 \n",
       "Q 841 59 441 206 \n",
       "L 441 856 \n",
       "Q 825 641 1194 531 \n",
       "Q 1563 422 1919 422 \n",
       "Q 2459 422 2753 634 \n",
       "Q 3047 847 3047 1241 \n",
       "Q 3047 1584 2836 1778 \n",
       "Q 2625 1972 2144 2069 \n",
       "L 1759 2144 \n",
       "Q 1053 2284 737 2584 \n",
       "Q 422 2884 422 3419 \n",
       "Q 422 4038 858 4394 \n",
       "Q 1294 4750 2059 4750 \n",
       "Q 2388 4750 2728 4690 \n",
       "Q 3069 4631 3425 4513 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"152.783203\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_33\">\n",
       "     <path d=\"M 378.040625 49.654687 \n",
       "L 388.040625 49.654687 \n",
       "L 398.040625 49.654687 \n",
       "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- Softplus -->\n",
       "     <g transform=\"translate(406.040625 53.154687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \n",
       "L 2375 4384 \n",
       "L 1825 4384 \n",
       "Q 1516 4384 1395 4259 \n",
       "Q 1275 4134 1275 3809 \n",
       "L 1275 3500 \n",
       "L 2222 3500 \n",
       "L 2222 3053 \n",
       "L 1275 3053 \n",
       "L 1275 0 \n",
       "L 697 0 \n",
       "L 697 3053 \n",
       "L 147 3053 \n",
       "L 147 3500 \n",
       "L 697 3500 \n",
       "L 697 3744 \n",
       "Q 697 4328 969 4595 \n",
       "Q 1241 4863 1831 4863 \n",
       "L 2375 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-66\" x=\"124.658203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.113281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"197.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"260.798828\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"288.582031\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"351.960938\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_34\">\n",
       "     <path d=\"M 378.040625 64.332812 \n",
       "L 388.040625 64.332812 \n",
       "L 398.040625 64.332812 \n",
       "\" style=\"fill: none; stroke: #ffbb78; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- Elu -->\n",
       "     <g transform=\"translate(406.040625 67.832812)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"63.183594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"90.966797\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_35\">\n",
       "     <path d=\"M 378.040625 79.010937 \n",
       "L 388.040625 79.010937 \n",
       "L 398.040625 79.010937 \n",
       "\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- Sigmoid -->\n",
       "     <g transform=\"translate(406.040625 82.510937)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" x=\"91.259766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\" x=\"154.736328\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"252.148438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"313.330078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-64\" x=\"341.113281\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_36\">\n",
       "     <path d=\"M 378.040625 93.689062 \n",
       "L 388.040625 93.689062 \n",
       "L 398.040625 93.689062 \n",
       "\" style=\"fill: none; stroke: #98df8a; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- Exponential -->\n",
       "     <g transform=\"translate(406.040625 97.189062)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-45\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"63.183594\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"122.363281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"185.839844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"247.021484\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"310.400391\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"371.923828\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"435.302734\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"474.511719\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"502.294922\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"563.574219\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_37\">\n",
       "     <path d=\"M 378.040625 108.367187 \n",
       "L 388.040625 108.367187 \n",
       "L 398.040625 108.367187 \n",
       "\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- Relu -->\n",
       "     <g transform=\"translate(406.040625 111.867187)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-52\" d=\"M 2841 2188 \n",
       "Q 3044 2119 3236 1894 \n",
       "Q 3428 1669 3622 1275 \n",
       "L 4263 0 \n",
       "L 3584 0 \n",
       "L 2988 1197 \n",
       "Q 2756 1666 2539 1819 \n",
       "Q 2322 1972 1947 1972 \n",
       "L 1259 1972 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "L 2053 4666 \n",
       "Q 2853 4666 3247 4331 \n",
       "Q 3641 3997 3641 3322 \n",
       "Q 3641 2881 3436 2590 \n",
       "Q 3231 2300 2841 2188 \n",
       "z\n",
       "M 1259 4147 \n",
       "L 1259 2491 \n",
       "L 2053 2491 \n",
       "Q 2509 2491 2742 2702 \n",
       "Q 2975 2913 2975 3322 \n",
       "Q 2975 3731 2742 3939 \n",
       "Q 2509 4147 2053 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"64.982422\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"126.505859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"154.289062\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_38\">\n",
       "     <path d=\"M 378.040625 123.045312 \n",
       "L 388.040625 123.045312 \n",
       "L 398.040625 123.045312 \n",
       "\" style=\"fill: none; stroke: #ff9896; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- Gelu -->\n",
       "     <g transform=\"translate(406.040625 126.545312)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-47\" d=\"M 3809 666 \n",
       "L 3809 1919 \n",
       "L 2778 1919 \n",
       "L 2778 2438 \n",
       "L 4434 2438 \n",
       "L 4434 434 \n",
       "Q 4069 175 3628 42 \n",
       "Q 3188 -91 2688 -91 \n",
       "Q 1594 -91 976 548 \n",
       "Q 359 1188 359 2328 \n",
       "Q 359 3472 976 4111 \n",
       "Q 1594 4750 2688 4750 \n",
       "Q 3144 4750 3555 4637 \n",
       "Q 3966 4525 4313 4306 \n",
       "L 4313 3634 \n",
       "Q 3963 3931 3569 4081 \n",
       "Q 3175 4231 2741 4231 \n",
       "Q 1884 4231 1454 3753 \n",
       "Q 1025 3275 1025 2328 \n",
       "Q 1025 1384 1454 906 \n",
       "Q 1884 428 2741 428 \n",
       "Q 3075 428 3337 486 \n",
       "Q 3600 544 3809 666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-47\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"77.490234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\" x=\"139.013672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"166.796875\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_39\">\n",
       "     <path d=\"M 378.040625 137.723437 \n",
       "L 388.040625 137.723437 \n",
       "L 398.040625 137.723437 \n",
       "\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_20\">\n",
       "     <!-- Softmax -->\n",
       "     <g transform=\"translate(406.040625 141.223437)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-66\" x=\"124.658203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.113281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6d\" x=\"197.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"294.734375\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-78\" x=\"356.013672\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_40\">\n",
       "     <path d=\"M 378.040625 152.401562 \n",
       "L 388.040625 152.401562 \n",
       "L 398.040625 152.401562 \n",
       "\" style=\"fill: none; stroke: #c5b0d5; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_21\">\n",
       "     <!-- Softsign -->\n",
       "     <g transform=\"translate(406.040625 155.901562)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-66\" x=\"124.658203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.113281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"197.322266\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"249.421875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" x=\"277.205078\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"340.681641\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_41\">\n",
       "     <path d=\"M 378.040625 167.079687 \n",
       "L 388.040625 167.079687 \n",
       "L 398.040625 167.079687 \n",
       "\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_22\">\n",
       "     <!-- Swish -->\n",
       "     <g transform=\"translate(406.040625 170.579687)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-77\" d=\"M 269 3500 \n",
       "L 844 3500 \n",
       "L 1563 769 \n",
       "L 2278 3500 \n",
       "L 2956 3500 \n",
       "L 3675 769 \n",
       "L 4391 3500 \n",
       "L 4966 3500 \n",
       "L 4050 0 \n",
       "L 3372 0 \n",
       "L 2619 2869 \n",
       "L 1863 0 \n",
       "L 1184 0 \n",
       "L 269 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-77\" x=\"63.476562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"145.263672\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"173.046875\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"225.146484\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_42\">\n",
       "     <path d=\"M 378.040625 181.757812 \n",
       "L 388.040625 181.757812 \n",
       "L 398.040625 181.757812 \n",
       "\" style=\"fill: none; stroke: #c49c94; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "    <g id=\"text_23\">\n",
       "     <!-- Tanh -->\n",
       "     <g transform=\"translate(406.040625 185.257812)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \n",
       "L 3928 4666 \n",
       "L 3928 4134 \n",
       "L 2272 4134 \n",
       "L 2272 0 \n",
       "L 1638 0 \n",
       "L 1638 4134 \n",
       "L -19 4134 \n",
       "L -19 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" x=\"44.583984\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"105.863281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"169.242188\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p56529ad6ac\">\n",
       "   <rect x=\"34.240625\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot0 = HistoryPlotter(metric='mean_absolute_error')\n",
    "plot0.plot(histories)\n",
    "#plot0.plot(histories, yMax=10)\n",
    "#plot0.plot(histories, yMax=3, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://1a439a72-f960-4623-8a74-8a842fd3d90e/assets\n",
      "INFO:tensorflow:Assets written to: ram://0743e33c-da22-44ca-a6f6-3708c77c24a0/assets\n",
      "INFO:tensorflow:Assets written to: ram://b7de2f41-fc41-4057-86e6-5f7fa7cdacf1/assets\n",
      "INFO:tensorflow:Assets written to: ram://e8c2b7c2-12d7-4bca-bf9d-e78b7fa8d558/assets\n",
      "INFO:tensorflow:Assets written to: ram://dd0614ce-e4ca-4a28-9cc4-42d6b27f76ee/assets\n",
      "INFO:tensorflow:Assets written to: ram://f73ee62d-25e1-4928-a9ed-3bac77aa56a2/assets\n",
      "INFO:tensorflow:Assets written to: ram://0da4db56-acbb-45ed-b292-0585012f357c/assets\n",
      "INFO:tensorflow:Assets written to: ram://1a709218-cf56-4f03-8c3a-4f6190a058da/assets\n",
      "INFO:tensorflow:Assets written to: ram://8ca2ae6a-87bc-4ce5-bfd4-adf82aaf7d21/assets\n",
      "INFO:tensorflow:Assets written to: ram://2d5e7d8d-721c-4250-b4f9-303068bac29a/assets\n",
      "INFO:tensorflow:Assets written to: ram://2b13a427-7030-4b4c-8f4a-efa211addd07/assets\n"
     ]
    }
   ],
   "source": [
    "with open('./histories_activationFunctions1Dict', 'wb') as file_pi:\n",
    "    pickle.dump(histories_activationFunctions1, file_pi)\n",
    "#with open('./histories_activationFunctionsDict', \"rb\") as file_pi:\n",
    "#    histories_activationFunctionsNew = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(TBNNModel2Concat, \"TBNNModel2Concat.png\", show_layer_names=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(TBNNModel2, \"TBNNModel2Multiply.png\", show_layer_names=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 838us/step\n",
      "CPU times: user 1.67 s, sys: 115 ms, total: 1.79 s\n",
      "Wall time: 1.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TBNNModel_prediction = pd.DataFrame(\n",
    "    data=TBNNModel2Concat.predict([test_features_long, test_features_short]),\n",
    "    columns=test_target.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBNNModel_prediction_prepared = preparePrediction(TBNNModel_prediction, testCenterData)\n",
    "writePredictionOld(TBNNModel_prediction_prepared[['dU0', 'dU1', 'dU2']],\n",
    "                   'vector',\n",
    "                   TSL[testCenterData_ind][0],\n",
    "                   MLturbRANSfolder,\n",
    "                   'dU')\n",
    "writePredictionOld(TBNNModel_prediction_prepared[['dp']],\n",
    "                   'scalar',\n",
    "                   TSL[testCenterData_ind][0],\n",
    "                   MLturbRANSfolder,\n",
    "                   'dp')\n",
    "writePredictionOld(TBNNModel_prediction_prepared[['dAW']],\n",
    "                   'scalar',\n",
    "                   TSL[testCenterData_ind][0],\n",
    "                   MLturbRANSfolder,\n",
    "                   'dAW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 800us/step - loss: 3.2634 - mean_absolute_error: 3.2634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.263425827026367, 3.263425827026367]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TBNNModel2.evaluate([test_features_long, test_features_short],\n",
    "        test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 846us/step - loss: 1.0820 - mean_absolute_error: 1.0820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.082020878791809, 1.082020878791809]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TBNNModel2Concat.evaluate([test_features_long, test_features_short],\n",
    "        test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Tensor_input_layer (InputLayer  [(None, 97)]        0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 97)           195         ['Tensor_input_layer[0][0]']     \n",
      "                                                                                                  \n",
      " First_hidden_layer (Dense)     (None, 64)           6272        ['normalization[0][0]']          \n",
      "                                                                                                  \n",
      " Flow_parameters_input_layer (I  [(None, 9)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " Second_hidden_layer (Dense)    (None, 64)           4160        ['First_hidden_layer[0][0]']     \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 9)           19          ['Flow_parameters_input_layer[0][\n",
      " )                                                               0]']                             \n",
      "                                                                                                  \n",
      " Parameters_concatenation (Conc  (None, 73)          0           ['Second_hidden_layer[0][0]',    \n",
      " atenate)                                                         'normalization_1[0][0]']        \n",
      "                                                                                                  \n",
      " Last_hidden_layer (Dense)      (None, 5)            370         ['Parameters_concatenation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,016\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 214\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 5s 66ms/step - loss: 0.8323 - mean_absolute_error: 0.8323 - val_loss: 0.1108 - val_mean_absolute_error: 0.1108\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.6351 - mean_absolute_error: 0.6351 - val_loss: 0.1009 - val_mean_absolute_error: 0.1009\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.6055 - mean_absolute_error: 0.6055 - val_loss: 0.0994 - val_mean_absolute_error: 0.0994\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.5927 - mean_absolute_error: 0.5927 - val_loss: 0.0983 - val_mean_absolute_error: 0.0983\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.5851 - mean_absolute_error: 0.5851 - val_loss: 0.0947 - val_mean_absolute_error: 0.0947\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.5796 - mean_absolute_error: 0.5796 - val_loss: 0.0957 - val_mean_absolute_error: 0.0957\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.5727 - mean_absolute_error: 0.5727 - val_loss: 0.0948 - val_mean_absolute_error: 0.0948\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.5672 - mean_absolute_error: 0.5672 - val_loss: 0.0943 - val_mean_absolute_error: 0.0943\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.5589 - mean_absolute_error: 0.5589 - val_loss: 0.0931 - val_mean_absolute_error: 0.0931\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.5477 - mean_absolute_error: 0.5477 - val_loss: 0.0899 - val_mean_absolute_error: 0.0899\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 65ms/step - loss: 0.5331 - mean_absolute_error: 0.5331 - val_loss: 0.0845 - val_mean_absolute_error: 0.0845\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.5104 - mean_absolute_error: 0.5104 - val_loss: 0.0834 - val_mean_absolute_error: 0.0834\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.4822 - mean_absolute_error: 0.4822 - val_loss: 0.0772 - val_mean_absolute_error: 0.0772\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.4380 - mean_absolute_error: 0.4380 - val_loss: 0.0683 - val_mean_absolute_error: 0.0683\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 60ms/step - loss: 0.3766 - mean_absolute_error: 0.3766 - val_loss: 0.0518 - val_mean_absolute_error: 0.0518\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 3s 59ms/step - loss: 0.3104 - mean_absolute_error: 0.3104 - val_loss: 0.0639 - val_mean_absolute_error: 0.0639\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 63ms/step - loss: 0.2492 - mean_absolute_error: 0.2492 - val_loss: 0.0559 - val_mean_absolute_error: 0.0559\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.1578 - mean_absolute_error: 0.1578 - val_loss: 0.0806 - val_mean_absolute_error: 0.0806\n",
      "Epoch 1/2\n",
      "60/60 [==============================] - 4s 61ms/step - loss: 0.0991 - mean_absolute_error: 0.0991 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 2/2\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.0274 - val_mean_absolute_error: 0.0274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Flow_parameters_input_layer, Tensor_input_layer with unsupported characters which will be renamed to flow_parameters_input_layer, tensor_input_layer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/nargiza/repo_2/tbnnTurbulenceTraining/constantAngleSlopeDNS_U4e-1_A5_H1e-2_RANSsets/saved_model/TBNNModel_batch_train_1/TBNNModel_batch_train_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/nargiza/repo_2/tbnnTurbulenceTraining/constantAngleSlopeDNS_U4e-1_A5_H1e-2_RANSsets/saved_model/TBNNModel_batch_train_1/TBNNModel_batch_train_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 4s, sys: 35.1 s, total: 13min 39s\n",
      "Wall time: 12min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TBNNModel_batch_train = keras.Model(\n",
    "    inputs=[inputs_long_, inputs_short_],\n",
    "    outputs=outputs,\n",
    ")\n",
    "name = \"TBNNModel_batch_train\"\n",
    "version = \"_1\"\n",
    "model = TBNNModel_batch_train\n",
    "saved_models_dir = \"/home/nargiza/repo_2/tbnnTurbulenceTraining/\" + \\\n",
    "    \"constantAngleSlopeDNS_U4e-1_A5_H1e-2_RANSsets/saved_model\"\n",
    "model_dir = os.path.join(saved_models_dir, name + version)\n",
    "if (not os.path.exists(model_dir)):\n",
    "    os.mkdir(model_dir)\n",
    "filepath = os.path.join(model_dir, \"{epoch:03d}-{val_loss:.4f}.h5\")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = filepath,\n",
    "                                 monitor='val_loss',\n",
    "                                 save_best_only=True,\n",
    "                                 save_weights_only = True)\n",
    "batch_size = 5000\n",
    "steps_per_epoch = len(trainData) // batch_size\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.001,\n",
    "    decay_steps=steps_per_epoch*10,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "\n",
    "\n",
    "def get_optimizer(lr_schedule=lr_schedule):\n",
    "    return tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)# lr_schedule)\n",
    "\n",
    "optimizer = get_optimizer()\n",
    "model.compile(optimizer=optimizer,\n",
    "                 loss='mean_absolute_error',\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError(\n",
    "                 name='mean_absolute_error')])\n",
    "\n",
    "model.summary()\n",
    "TSL = timeStepsList()\n",
    "TSL = TSL[:3]\n",
    "batches_num = len(TSL)\n",
    "epochs_num = 10\n",
    "for i in range(epochs_num):\n",
    "    real_i = epochs_num % batches_num\n",
    "    trainData = formDataset([TSL[real_i]], 1, MLturbRANSfolder, FsScalars, FsVectors,\\\n",
    "                                FsTensors, FsSymmTensors, FsSkewSymmTensors, size)\n",
    "    steps_per_epoch = len(trainData) // batch_size\n",
    "    trainData.sample(frac=1)\n",
    "    train_target = trainData.loc[:, target_labels]\n",
    "    train_features_short = trainData.loc[:, short_input_labels]\n",
    "    train_features_long = trainData.loc[:, long_input_labels]\n",
    "        \n",
    "    model.fit(\n",
    "        [train_features_long, train_features_short],\n",
    "        train_target,\n",
    "        steps_per_epoch = steps_per_epoch,\n",
    "        epochs = 2,\n",
    "        validation_split = 0.2,\n",
    "        verbose = 1,\n",
    "        callbacks = [checkpoint],\n",
    "        use_multiprocessing = True)\n",
    "model.save(os.path.join(model_dir, name + \"_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f717b791c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/romanovadi/anaconda3/lib/python3.9/weakref.py\", line 370, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:103\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:487\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    484\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    488\u001b[0m     element,\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for               res/I0        res/I1        res/I2        res/I3        res/I4  \\\n0       1.016385e+06 -1.004044e+06  1.777893e+07 -5.867744e+06 -5.102294e+11   \n1       1.039447e+06 -1.025998e+06  2.400745e+07 -7.918464e+06 -5.332120e+11   \n2       1.047083e+06 -1.036225e+06  1.728662e+07 -5.707071e+06 -5.424902e+11   \n3       1.050067e+06 -1.041998e+06  1.043520e+07 -3.452749e+06 -5.470768e+11   \n4       1.042686e+06 -1.038927e+06  7.497395e+06 -2.490698e+06 -5.416315e+11   \n...              ...           ...           ...           ...           ...   \n593995  2.653137e+04 -2.624351e+04 -2.503822e+05  8.383157e+04 -3.460971e+08   \n593996  2.444572e+04 -2.417258e+04 -2.223790e+05  7.444258e+04 -2.935271e+08   \n593997  2.195004e+04 -2.165447e+04 -2.168103e+05  7.231410e+04 -2.360115e+08   \n593998  1.960535e+04 -1.939911e+04 -1.896459e+05  6.341344e+04 -1.887550e+08   \n593999  1.756172e+04 -1.754579e+04 -1.340087e+05  4.478832e+04 -1.528923e+08   \n\n        res/magGradP  res/magGradAW  res/inv1GradU  res/inv2GradU    res/T00  \\\n0       2.626330e+06         2500.0       7.680430  -12282.640625  12.665646   \n1       2.566374e+06         2500.0      11.189335  -13323.824219   9.821540   \n2       2.431804e+06         2500.0       7.342609  -10804.134766   0.698047   \n3       2.243592e+06         2500.0       4.580991   -8047.972168  -7.315175   \n4       2.011188e+06         2500.0       3.096846   -3749.621094 -11.807054   \n...              ...            ...            ...            ...        ...   \n593995  7.324587e+02            0.0       0.123536    -287.846771  -0.260891   \n593996  7.356863e+02            0.0       1.233790    -271.618073   0.717300   \n593997  7.373934e+02            0.0      -0.075367    -295.565765  -0.730074   \n593998  7.388403e+02            0.0      -0.239526    -206.181015  -1.075927   \n593999  7.403318e+02            0.0      -0.144396     -15.917440  -0.665729   \n\n        ...   init/U0       init/U1   init/U2    res/U0    res/U1    res/U2  \\\n0       ...  0.402563 -5.260185e-07  0.004219  0.402158  0.000477  0.000403   \n1       ...  0.409254  6.302119e-06  0.007113  0.407975  0.000572  0.003388   \n2       ...  0.412084  7.055768e-06  0.008075  0.410015  0.001343  0.004802   \n3       ...  0.410981  1.231414e-05  0.008590  0.408533  0.002282  0.005908   \n4       ...  0.406744  9.424059e-06  0.008508  0.404163  0.002766  0.006451   \n...     ...       ...           ...       ...       ...       ...       ...   \n593995  ...  0.025487  9.301916e-06  0.086420  0.025486  0.000055  0.088039   \n593996  ...  0.026324  1.008303e-05  0.082404  0.026316 -0.000003  0.084020   \n593997  ...  0.026062  6.829668e-06  0.077506  0.026060  0.000007  0.079129   \n593998  ...  0.025724  3.670253e-06  0.072838  0.025732 -0.000024  0.074482   \n593999  ...  0.025190 -3.261019e-08  0.068541  0.025199 -0.000040  0.070213   \n\n        init/alpha.water  init/p_rgh    res/p_rgh  res/alpha.water  \n0                    1.0   59.718414 -1029.856079              1.0  \n1                    1.0   58.489220 -1003.050903              1.0  \n2                    1.0   57.480843  -933.301697              1.0  \n3                    1.0   56.311970  -839.547852              1.0  \n4                    1.0   55.272839  -737.649414              1.0  \n...                  ...         ...          ...              ...  \n593995               0.0   -0.069890     0.286862              0.0  \n593996               0.0   -0.076538     0.286994              0.0  \n593997               0.0   -0.080880     0.287874              0.0  \n593998               0.0   -0.085399     0.287659              0.0  \n593999               0.0   -0.091049     0.287715              0.0  \n\n[594000 rows x 106 columns] with type DataFrame",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36mcompile_and_fit\u001b[0;34m(model, max_epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile_and_fit\u001b[39m(model, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      4\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m      5\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMeanAbsoluteError(\n\u001b[1;32m      7\u001b[0m                  name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[0;32m----> 9\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Suppress logging.\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Calculate validation results on 1% of the training data.\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1501\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1492\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcoordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1493\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1494\u001b[0m         )\n\u001b[1;32m   1495\u001b[0m     )\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1499\u001b[0m ):\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1501\u001b[0m     data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1261\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:349\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    347\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 349\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:382\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_inputs\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices_dataset, inputs):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124;03m\"\"\"Slice inputs into a Dataset of batches.\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    Given a Dataset of batch indices and the unsliced inputs,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m      A Dataset of input batches matching the batch indices.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip(\n\u001b[0;32m--> 382\u001b[0m         (indices_dataset, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrepeat())\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m d: tf\u001b[38;5;241m.\u001b[39mgather(d, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), data\n\u001b[1;32m    388\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:734\u001b[0m, in \u001b[0;36mDatasetV2.from_tensors\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensors\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    699\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` with a single element, comprising the given tensors.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \n\u001b[1;32m    701\u001b[0m \u001b[38;5;124;03m  `from_tensors` produces a dataset containing only a single element. To slice\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4688\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, element, name)\u001b[0m\n\u001b[1;32m   4686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4687\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensors()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4688\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4689\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m   4690\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure, element)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py:108\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    103\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    106\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 108\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensorSpec):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1629\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1631\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1641\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "histories['full_dnn_model_4'] = compile_and_fit(\n",
    "    full_dnn_model_4,\n",
    "    max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pandas/core/frame.py:7134: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return concat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 23s, sys: 5.18 s, total: 2min 28s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TSL = timeStepsList()\n",
    "testTSL = TSL[-2:]\n",
    "testData = formDataset(testTSL, len(testTSL), MLturbRANSfolder, FsScalars, FsVectors, FsTensors, \n",
    "                        FsSymmTensors, FsSkewSymmTensors, size)\n",
    "\n",
    "test_target = testData.loc[:, target_labels]\n",
    "test_features_short = testData.loc[:, short_input_labels]\n",
    "test_features_long = testData.loc[:, long_input_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1</th>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.066554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0         1\n",
       "TBNNModel_batch_train_1  0.066554  0.066554"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models = {}\n",
    "all_models[name + version] = model.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)\n",
    "pd.DataFrame(all_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(os.path.join(model_dir, name + \"_model\"))\n",
    "loaded_model.compile(optimizer=optimizer,\n",
    "                 loss='mean_absolute_error',\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError(\n",
    "                 name='mean_absolute_error')])\n",
    "#TODO: load weights from the last modified file with weights ('cause last = best when we use\n",
    "# save_best_only = True)\n",
    "loaded_model.load_weights(os.path.join(model_dir,'001-0.0201.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1</th>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.066554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1_loaded</th>\n",
       "      <td>0.067113</td>\n",
       "      <td>0.067113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1_loaded_from_best_epoch</th>\n",
       "      <td>0.067113</td>\n",
       "      <td>0.067113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0         1\n",
       "TBNNModel_batch_train_1                         0.066554  0.066554\n",
       "TBNNModel_batch_train_1_loaded                  0.067113  0.067113\n",
       "TBNNModel_batch_train_1_loaded_from_best_epoch  0.067113  0.067113"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models[name + version + '_loaded_from_best_epoch'] = loaded_model.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)\n",
    "pd.DataFrame(all_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(model_dir, 'last_epoch.h5'))\n",
    "\n",
    "loaded_model = keras.models.load_model(os.path.join(model_dir, name + \"_model\"))\n",
    "loaded_model.compile(optimizer=optimizer,\n",
    "                 loss='mean_absolute_error',\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError(\n",
    "                 name='mean_absolute_error')])\n",
    "loaded_model.load_weights(os.path.join(model_dir,'last_epoch.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1</th>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.066554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1_loaded</th>\n",
       "      <td>0.067113</td>\n",
       "      <td>0.067113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1_loaded_from_best_epoch</th>\n",
       "      <td>0.067113</td>\n",
       "      <td>0.067113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_batch_train_1_loaded_from_last_epoch</th>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.066554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0         1\n",
       "TBNNModel_batch_train_1                         0.066554  0.066554\n",
       "TBNNModel_batch_train_1_loaded                  0.067113  0.067113\n",
       "TBNNModel_batch_train_1_loaded_from_best_epoch  0.067113  0.067113\n",
       "TBNNModel_batch_train_1_loaded_from_last_epoch  0.066554  0.066554"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models[name + version + '_loaded_from_last_epoch'] = loaded_model.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)\n",
    "pd.DataFrame(all_models).T\n",
    "#so we save best weights during training, and we can also save the weights after all epochs\n",
    "# .evaluate method uses weights from last epoch even if they are not the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAACFCAYAAADrVkFtAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3de1hU1foH8O9wU0EwBUQQ1FDRRI8ZIUOAxxI5ZuIlAS3EzLyhcgyzTInUh9TsYuTRsLTUDtkB9DGP6Sk1TUNAicIb2gXPUQEVQbwAisPw/v7wYf8cURhxhgH5fp6HJ2ftPXu9s/fau3ln77WWSkQERERERERE9DBLMTN1BERERERERGR8TP6IiIiIiIiaASZ/REREREREzQCTPyIiIiIiombA4s6C9PR0LF++3BSxkB58fX0xe/ZsU4dRL8uXL0d6erqpwyATasrt90HwuqqflJQUU4fQLISGhpo6hEZv9uzZ8PX1NXUYREQGV+PO39mzZ7Fp0yZTxEJ1yMjIaNLJU3p6OjIyMkwdBplIU2+/D4LX1drl5eVx/zSgTZs2IS8vz9RhNFqbNm3C2bNnTR0GEZFR1LjzV42/wDY+D8OvtWq1mm2rmXoY2u+DYtu/u+TkZIwZM8bUYTQr0dHRCAsLM3UYjZJKpTJ1CERERsM+f0RERERERM0Akz8iIiIiIqJmgMkfERERERFRM8Dkj4iIiIiIqBlg8kdERERERNQMMPkjIiIiIiJqBpj8ERERERERNQNM/oiIiIiIiJoBJn9ERERERETNAJM/IiIiIiKiZoDJHxERERERUTPA5I+IiIiIiKgZYPJHRERERETUDDD5IyIiIiIiagYeOPnbvXs3Jk2aBJVKBZVKhSFDhmDjxo2GiO2BbN68GWq1WokrOjoa2dnZpg6L7sO//vUveHp6QqVSISAgAJWVlTrLS0pKEBcXBzs7O9jY2CA2NhbFxcUmirZulZWVSE9Px4IFC7Bz506lfM+ePVCr1fjf//5n1Pobqh4ynB07duC5555TrmNPPfUU/P390a9fP6jVasydOxe5ubmmDpOaAbZFIqKHg8WDbiAwMBCBgYHYunUrioqKsGbNGri5uRkitvt27tw5ODs7AwBGjx4NJycnBAQEoE+fPvjoo49MEhPV39ixYzFo0CC4uLggNTUVMTExWLZsmbK8bdu2iI2NxaVLl6DRaBAXF2fCaOuWmZmJNWvWYN26dVi7dq1SXlJSgrNnz6KsrMyg9d1+PhizHjKeoUOHok+fPujUqRM6d+6MtLQ0ZVlmZibefvtt9OjRA3PnzkVcXBzMzPgwBxkH2yIR0cPBYFfnNm3aALj1hdwUrl69ioiICJ0yBwcHAEC7du1MEdJDa8eOHThw4ABExOh1OTo6wsnJCW3atMH777+Pb7/9tsY6Xbp0gbu7u9FjeVC+vr6IioqqUT569Gjk5+fD09PTYHXd7XwwRj3NTXl5OVavXt2gd5htbW0BAK1atdIp9/b2xvbt2zF27FgsWbIE7777boPFRI3D/v37sWvXLmi12gapj22RiKjpM1jyp1KpdP7bkMrKyhAaGlrjkRNTxvQw++677+Dv7w9XV1fMmzcPR44cMWp9jo6O2LBhAwDgpZdewpkzZ3SWt2zZEi1atDBqDIZiZWVl9DrudT7Qg6uoqEBkZCScnJzw7LPP4quvvkJpaalR66zt+mVmZoZVq1ahffv2WLx4MU6fPm3UWKhxycjIQFBQEJycnDBr1ixkZGQY9Uc5tkUioqbPaM9lZGdn4/XXX4e7uztKSkowYcIEODg4oH///jh16hQAICcnBzExMejVqxfy8/MxYsQItGvXDv3790dGRgYAICkpCba2tsqjpFevXkV8fDxatmwJX19fAMCWLVtw4sQJFBUVYfLkyfjggw/uO94LFy5gypQpiIuLw+TJkzFq1Cjl1/2tW7fC1tYWKpUK8fHxuHnzJgAgPT0dzs7OWLJkCQBARLB69WpERkbCx8cHQUFB+OOPPwAA+fn5ePfdd9G7d2+cP38eQUFB6Ny5c6Puo1YbCwsLFBQU4MMPP0Tfvn3h4eGBxYsXK8fW0EaMGIF58+bh0qVLCAsLg0ajqXX9TZs2ISoqCnPmzMGQIUMQExODiooKALUfi+PHj2P+/Pno0aMHzpw5g/nz56NTp07w9PTE3r17cePGDURHR6Nr165wc3PDd999p1Nvbe3oXi5evIiVK1fi4MGDStkjjzyCl19+GdHR0YiOjoaHhwdUKhW++uqrOuu51/lwt3rq2lf6nMfNkVarxc6dOxEREQEHBweMGTMG//73v5VrQ0Nq06YNwsLCUF5ejqSkJKW8tuuRvsf18OHDmDBhAt577z1ER0dj+vTpem2fGo6lpSWKi4uRkJAAX19fuLm54a233sLx48cbPBa2RSKiJkDukJSUJHcprlO3bt0EgJSWloqIyLlz5yQwMFAAyNSpU+X48eOya9cusbOzk7Fjx4qIyP79+6VXr15ibm4u0dHRsnfvXtm8ebPY29uLtbW1FBQUiIhIUFCQuLq66tT35JNPilqtVl4PGzZMunTporPOyZMnBYAMHDiwzvgHDhwoY8aMUV737dtXxo0bp7x+8803BYBkZmYqZRUVFeLj46O8Xrp0qaxfv15ERCorK0WtVkuHDh2krKxM/vOf/0jPnj3F3NxcFi1aJJ9//rn0799f8vPz64ytWkhIiISEhOi9vrFERUWJlZWVAND5s7CwEADi4eEh7777rnL8qtU3/scff1xERLRardKmoqOjleWrV6+WlStXKq+XL18ufn5+cvPmTRERKSoqku7du8uAAQOkqqqq1mNRWFgoERERAkBeeeUVycrKkqtXr4q/v7+4u7vLzJkzJScnR65duyZPP/20uLu768RaVzs6duyYAJC1a9eKiEhqaqoEBAQIANm0aZOyXlxcnPLv3Nxcadmypfj7+0tVVZVe9dx5Ptyrnrr2lT7nsb4aS/t9EJcuXarR7gGIpaWlqFQqsbGxkXHjxsm///1v0Wg0yvvqe10VEbl8+bIAkJ49e95zncTERAEgEyZMUMpqux7pe1x79uwpqampInLrehccHKzX9u/Xg+yf5mzZsmXSokWLGu2x+vrcrVs3WbBggfzxxx867wMgSUlJ911fc2iLIvXfP0RETUCy0e78dejQAd7e3gCAxYsXo1evXggMDERAQACysrIAAAEBAfDx8YFKpcKyZcswcOBAPP/88/jkk0+UvjUAYG1tXWP7FhYPPFZNDX379lX+3bt3b53HGWfMmAELCwt8+umnStmuXbswbNgwAEBBQQHi4+OVflbm5uYICQnB+fPnsW3bNgwZMgR+fn7QarUIDw/HxIkTcfDgQbi4uBj8c5hK9Wicf/zxB2JiYtCxY0eo1Wp8/PHHKCoqeuDtm5mZ4euvv4abmxs++ugjbNmypcY6hYWFiI2NxbRp02BpaQkAsLe3x/z587F//34kJibWeiwcHR2hVqsBALNmzcITTzwBW1tbPP/88zh16hReeeUVPPbYY2jdujWGDx+OU6dO4eLFizox1NaO7uTn54fY2FidMhHBSy+9pLyOiopCZWUlEhISdB67etB69NlX+pzHBGg0GogIysrKkJycjOHDh8PZ2RmzZs1Camqq0fvHOjo6AgDOnj0LoO7rkT7HVaPR4OTJk/j1118B3HpkeeLEiXptn0yr+g70n3/+iSVLlqB79+7o27cvPv74Y5w/f96odbMtEhE1bobPoG5jbm5+q5LbEjVbW1tcu3ZNZx0LCwvlyycAjBo1ClZWVjh69Kgxw9Oxd+9eALf6SyUmJiIzMxNVVVXKcldXV4SGhiIxMRFLly6Fg4MDkpOTsWDBAgBAWloaNBoNpk6dqrPdSZMmKZ3jLS0tYWFhga5du9Y7zlOnTiEsLKze7zeE6v+p34uIKAMQZGZmIjMzE6+//jocHBzQuXNnXL9+vcaAAfpycHDA5s2bERAQgIkTJ+Lxxx/XWZ6RkYGysrIaI85WJ+k//vgjIiIiaj0W1e329tHqqgc6uL2dtm7dGgBQVFSkfOGpqx3dzZ0/bqhUKiX+LVu2YMeOHXjjjTfQu3dvZR1D1KPvvtLnPNZXbm6uydvvg9Dnsc7qdYqKipCQkIAVK1Yo7ePkyZPo2bOnweO6cuUKAMDDwwOAftejuo6rpaUlBg8ejFmzZiEnJwdLlizByJEj9d5+fTTltmEKd/Z/vpvqR+SPHj2K1157DbNnzwZwa7CYIUOGwM7OzqAxPSxtkYjoYWXU5K++LC0t4eLiUmNeN2PSarVYtmwZcnNzMXv2bKSmpir9DqtFR0fj66+/xmeffYY5c+agqKhIGWXyxIkTsLGxwZo1axos5ubK29sbK1aswNSpUxEaGoqIiAjlS0P1IAOXLl3SeY+DgwOsra1RUFBQrzrvNtBBddntSZc+7UhfZWVlePXVV9GpUye8/fbbOssMUY+x9hU1vJMnTwL4/7vBhroeJSUlYezYsUhISMDmzZuRkpKCAQMG8HpH98S2SETUuDXK5A+49et5jx49jF7PiRMn4ObmhtGjR8Pe3r7WCeq9vb3h5+eHVatWoWfPnggODlaWWVtbIy8vD3l5eXB1ddV5X1FRkTLtxINyd3dHcnKyQbZVX3//+9/xyy+/3HO5SqWCmZkZqqqq4O3tjRdeeAHh4eGIjIwEUHOY8PqYMmUK0tPTsX79ehQUFCAmJgYA8OijjwLAPQcjMWabqqqqwtChQ+tsR/qKi4vDmTNn8M0338DGxsbg9ZhiX3Xt2tXk7fdBlJSU1Dl1jJWVFW7evAkHBwe8+OKLCA0NRX5+PsaOHWuUu34igpSUFNjZ2Sl3bQ11PbKxscH333+PxMREvPbaawgKCkJ2drbRrndNuW2YwnvvvYfs7Oxa17G0tIRGo0GfPn0wceJEjBkzBs7OzhgwYIDB7/o9TG2RiOhhZbA+f9V9WgzRt6WwsBDnz59HSEgIgFuPgpSWlurMZVRaWqpzx8XMzKzGCJD6xDJv3jwcPXoUO3fuxKBBg5Ty6j48d3rjjTdQUFCA1157DaGhoUp5nz59ICKYO3dujc+ybt26OuN4GFTffevevTsWL16M/Px8ZGRkYNasWfX+H7CI3PPxwoSEBPTr1w/nzp1TytRqNWxtbfHNN9/orJufn4/y8nIMHz68XnHo49ChQ3q3o7rk5ORg+fLlCA4OxogRI5TynTt36lXP3c6HO5lyXz1sLC0toVKpYGNjg7CwMPz73//GuXPn8PHHH8Pf3/+Bppupq/18+OGHOHr0KD744AN07NgRgGGuRxUVFUhISAAAjBs3DhkZGaiqqsKePXt4vWvkqqeU6datG+bPn48//vgDhw8fxqxZs9ChQ4d6b5dtkYio6TPYnb+rV68CuPXLeHVfqOq+L7c/vllWVobr169DRJQvRBUVFTh69Cj69OkD4Fan73HjxsHHxwfArf95bNq0CUuXLkVYWBiSk5NRUVGBvLw8/PLLL3jiiSfg4uKC7du3Izs7G1euXIG3t7fyOFt1H4TbXblyBXPnzkXLli2Vvl0bNmxA//79kZWVhZycHFy4cAFHjhyBk5MTnJycAADBwcHw9PREt27dYG9vr2xv8ODB8Pb2xsaNG3Hjxg2MHDkSf/75J9LS0vD1118DuPUFXavVQqPR6PQda4qqE+/qX5W7d++Ol156CS+88IJBJ1w/e/YsCgoKcOPGDbRs2VJnWcuWLbF582Z4eXkpZQ4ODli6dCmioqLwww8/KAnSihUrEBERgWeeeQZA7cfibu22euqD69evK2XVyVX1sur2XFs7qm6Lt2+7eps3btxQymbMmAFLS0usWLFCp76dO3cqPzrUVs/dzoc769F3X+l7Hjc3ZmZmEBFYWVlhxIgRCA8Px5AhQww+l2N1mykvL9cpP336ND788EOsXLkSs2bNwuTJk5Vl+lyP6jquAPD5559j5syZMDc3h6urK9q0aYN+/fpBrVbXuX1qGHdeizt27IgJEybghRdegKenp0HrYlskInoI3Dn+5/0Oub13716JjIxUhpgeOnSoJCUlyZ49e6R79+4CQKZPny6FhYWSmJgodnZ2AkAWLlwolZWVMmnSJLG0tJSXX35ZQkJC5JVXXpFFixaJVqtV6rhy5YoEBwdL69atRa1WS2ZmpkycOFEmTJgg27dvFxGRw4cPi5ubm3h4eEhKSops3bpV/P39lbh8fHzkb3/7mwQFBUm/fv2kVatWAkA+++wzERGZNm2a2Nrailqtlt27d8v27dvFwcFBQkJClOkrqkVFRUlKSkqNfVFcXCzh4eHSvn17cXR0lPHjxytTOWzcuFGcnZ0FgLz66qty/PhxvfdxtcYyVH5UVJQAEBcXF3nzzTfl8OHDer3vfuPfsmWLPP300wJARo0aJT/99NNd19u+fbusWrWqxnuDgoJk5syZEhsbK++//74yTUJtx+LgwYOiVqsFgISHh8uff/4phw4dEl9fXwEgL7zwgvz222+SlZWltK/w8HDJzc0VkdrbUWpqqowcOVIASEBAgPz4449y8OBBCQ4OVqYkSUtLU87Bxx57TObMmSNz5syRyMhI6du3r8yYMaPOekpLS2ucD3erR599pe95rI/G0n4fRPVUD+bm5jJkyBBJTEyUa9eu1fm++k5l8P3338tzzz2nXMf8/f1l0KBBMnToUHn22WclOjpasrOz7/re2q5H+hzXsrIy8fb2lueee07ee+89mTJliqxZs0av7d8vTvVQP8uWLRMAYm9vL3//+98lPT1dOXdrg3pMZdBc2mJ99w8RURORrBLRfY4jOTkZY8aMMfrQ5NUmT56MxMREnTsqjd3gwYOxbdu2GneijK36jk9KSkqD1nunHTt2oE2bNnjqqafu665PY4mfTONhOP7l5eX48ssvERoaqnPnvy4NfV1tarh/6mf//v2oqKjAM888o4yYqQ+VSoWkpCSOrnoP3D9E9BBLabQDvjRW+/btg5eXV4Mnfo3J0KFDTR0CkUlYW1tj2rRppg6DCAAwYMAAU4dARERNjMmTv4qKCmWwisbad+inn37CtGnT0Lt3bxw7dgz79u0zdUhERERkJAkJCbh06RL8/Pzg6empM+8rEVFTZtKr2TvvvIOtW7dCq9Xi9ddfx6FDh0wZzj3Z29vjxo0b+Pnnn5GQkMCho4mIiB5ily5dwhtvvIG//OUvaNu2Lf72t79h0aJF2LlzpzLAHRFRU2TSO39vvfUW3nrrLVOGoJdevXohNzfX1GEQERFRA4iJicHo0aNx8uRJZGVl4cCBA0hOTsaiRYtgZmaGHj16wMvLC/7+/vDz80OvXr0a7dNLRES3M/ljn0RERESNjbm5OTw9PeHp6Ynx48cDAC5cuIBDhw4pCeGrr76K69evw8nJCd7e3joJYatWrUz8CYiIamLyR0RERKQHJycnBAcHIzg4GMCtuQkPHz6M1NRUZGVlYf369Vi0aBEsLCzQt29f+Pn5wcvLCwMGDECXLl1MGzwREZj8EREREdWLhYUFvLy84OXlpZQVFBTgwIEDSkK4evVq3Lx5E87OzspdQS8vL/Tv3x9WVlYmjN4wkpOTTR0CPYCmOqVJXl4e0tLSTB1Go3e348vkj4iIiMhAXFxcEBoaqsxtWlZWhl9//VVJCOPi4lBcXAwbGxs8/vjjSkL41FNP3df8oY3FmDFjTB0CPYCmmvylpaWx7enhbseXYxcTERERGYmNjQ38/f0xd+5cbNu2DUVFRcjNzcUnn3wCT09PbNu2DSNGjICDgwO6du2K8ePH47PPPsPx48chIqYOXy9JSUkQEf41ob+kpCRTNxuDMPV+bKx/tR1f3vkjIiIiakDu7u5wd3dXBpK5evUqDh06hNTUVBw4cADR0dEoLy+HnZ0d+vfvDz8/P/j7++Opp56CtbW1iaMnoqaMyR8RERGRCdnZ2SEwMBCBgYEAbg0k89tvvymPin755ZfKQDIeHh7Ko6L+/v5wd3c3WBwlJSXIzc3Fk08+abBtElHjwuSPiIiIqBGxsLBQppmYMmUKgFsDyVRPMZGamooNGzagoqICzs7OOlNMeHt7o0WLFvWqNzU1FSNHjsSMGTOwePFi2NraGvJjEVEjwOSPiIiIqJFzcXGBi4uLMs1EeXk5fvnlFyUh/OCDD/Dmm2/C2toa/fr1UxLCgQMHwtHRUa860tPToVKpkJCQgOTkZKxevRojR4405sciogbG5I+IiIioibG2toa/vz/8/f0xa9YsAMCpU6eUKSYOHDiAlStXoqqqCu7u7soUE/7+/ujXrx/MzGqO+ffjjz9Cq9UCAC5evIhRo0bh2WefxerVq9GpU6cG/XxEZBxM/oiIiIgeArUNJJOVlYWFCxfi8uXLsLW1hY+Pj5IQBgQEwMbGBr/88ouyraqqKgDA7t274eHhgUWLFmHOnDkwNzc3yWcjIsNg8kdERET0ELrbQDKHDx9GWloa0tPTsW7dOmUgma5du6KioqLGNjQaDQBg/vz5SExMxBdffAFvb+8G/RxEZDic54+IiIioGbCwsICXlxeioqKwceNGnD59Gnl5edi4cSM6dOgAC4t73xOoqqrCyZMn4ePjgylTpuDatWsNGDkRGco9z/LQ0NCGjIP0kJGRAbVabeowHkhGRgbbVjP1MLTfB8W2f3d5eXmmDqHZ+eijj5CSkmLqMKgR6NixI0JDQ5GcnAyR2ieVr6ysBACsX78eW7duxSeffNIQIRKRAdVI/tzc3BASEmKKWKgOarUavr6+pg6j3ppy7PTgmnr7fRC8rtbO1dWV+6cBcV/XLiQkBG5ubqYOo8H99NNPymAvddFoNCgsLFTaUklJiTFDIyIDqpH8+fr68tdAMorZs2ebOgQik+B1lRoTtkW609mzZ3HhwoW7LrOwsIBKpYJWq1UGgVGpVGjbti3c3Nxw+PBh7N69G+PHj0erVq0aMmwiqgcO+EJERETUjKWlpem8trW1hYuLC7p27YouXbrA1dUVrq6u6Ny5s/JvKysrALcSwdDQUCZ+RE0Ekz8iIiKiZqxXr174/vvv4ebmhs6dO8Pa2trUIRGRkTD5IyIiImrG+vTpgz59+pg6DCJqAEz+iIiIiKhBXblyBe+//z7279+PkpISdOnSBRYWFnjssccAAC4uLpg5c6aJo6SHzY4dO7Bq1Srs2LEDwK0++WZmZigrK0OLFi3w17/+FVOmTEHXrl1NHKnxcJ4/IiIiImowO3bsQM+ePbFv3z58+eWXOHr0KLZt24YvvvgCBQUFWLp0KcrLy00dZg3nzp1rVvU+jIYOHYrVq1cDADp37oy0tDSkpqbi119/xT/+8Q8cOXIEPXr0QExMjDLA0cOGyR8RERERNYj//ve/GDt2LDp37ow9e/agS5cuyrK2bdti/fr1ePHFF1FWVma6IO/i6tWriIiIaDb1NqSCgoIGrc/W1hYAagxS5O3tje3bt2Ps2LFYsmQJ3n333QaNq6Ew+SMiIiKiBjF+/Hhcu3YNcXFxsLS0vOs6ixYtalR3/srKyhAaGorc3NxmUW9DGz16NB577DEsXboU//vf/4xen0qluucyMzMzrFq1Cu3bt8fixYtx+vRpo8fT0Jj8EREREZHRHT16FKmpqXjkkUcwePDge67XrVs3REVFKa83bdqEqKgozJkzB0OGDEFMTAwqKioAANnZ2Xj99dfh7u6OkpISTJgwAQ4ODujfvz9OnTqls90dO3Zg+vTpmDVrFnx9fbFmzRpl2YULFzBlyhTExcVh8uTJGDVqFIqLiwEAW7ZswYkTJ1BUVITJkyfjgw8+AACICFavXo3IyEj4+PggKCgIf/zxx33FZeh6m6LKykqcPHkSb7/9Ntzd3dG/f3/84x//uOfck8bWpk0bhIWFoby8HElJSUq5IY734cOHMWHCBLz33nuIjo7G9OnT9dq+QQkRERERUT0AkKSkJL3WXbt2rQAQLy8vvbe/fPly8fPzk5s3b4qISFFRkXTv3l0GDBggVVVVcu7cOQkMDBQAMnXqVDl+/Ljs2rVL7OzsZOzYscp2vvzyS3nhhRdEq9WKiMjixYsFgPzwww8iIjJw4EAZM2aMsn7fvn1l3Lhxyuthw4ZJly5ddGJbunSprF+/XkREKisrRa1WS4cOHaSsrEzvuAxdr76SkpKksaQBTz75pABQ/lQqlZibm4tKpRK1Wi3x8fFy8eJFnfc8SPyXL18WANKzZ897rpOYmCgAZMKECUqZIY53z549JTU1VUREKioqJDg4WK/t369a9k8y7/wRERERkdGVlJQAAOzt7fVav7CwELGxsZg2bZryiKi9vT3mz5+P/fv3IzExER06dIC3tzcAYPHixejVqxcCAwMREBCArKwsAMDFixcRFRWFxYsXw8zs1lffyZMn4/nnn4ezs7NSX9++fZV/9+7dG0eOHLlnbAUFBYiPj1f645mbmyMkJATnz5/Htm3b9IrLGPU+DEQEWq0WIoLMzEy89tprcHZ2xtChQ/Hll182SH9QR0dHAMDZs2cBGOZ4azQanDx5Er/++isAwMrKChMnTtRr+4bEqR6IiIiIyOg6d+4M4NagL/rIyMhAWVkZ3NzcdMqHDRsGAPjxxx8REREBc3NzAICFxf9/rbW1tcW1a9cAAKmpqaiqqsKjjz6qLHd0dMTmzZuV13v37gVwq59dYmIiMjMzax3tMS0tDRqNBlOnTtUpnzRpkjKQSF1xGave+5GSknLf7zG00tLSey7TarXKv3ft2oXvvvsOkZGRePLJJwHcemT09v1rKFeuXAEAeHh4ADDM8ba0tMTgwYMxa9Ys5OTkYMmSJRg5cqTe2zcUJn9EREREZHSenp4AbiV/+nxprx5s49KlSzrlDg4OsLa21nuUyGPHjkGj0UBE7jnYh1arxbJly5Cbm4vZs2cjNTUVGRkZ99zmiRMnYGNjo9NvsD5MVW+1sLAwg2znQbRt21av9SorKwEA5eXl2L9/PwDgnXfeQUxMzD0HD6qvkydPAvj/u7KG2u9JSUkYO3YsEhISsHnzZqSkpGDAgAEGP6614WOfRERERGR0PXr0QI8ePVBZWYmffvqpzvWr79TdOXDL7dvTh52dHU5wcisAABaYSURBVG7cuIGcnJway27evImqqioMHToUx44dw+eff64kqbWxtrZGXl4e8vLyaiwrKirSKy5T1Xs7ETH5nz4Tqpubm8PMzAxWVlZ47rnnEB0dDQBYuHChwRM/EUFKSgrs7OyUu8yG2u82Njb4/vvv8c9//hMAEBQUhJMnTxr8uNaGyR8RERERGZ25uTk+/fRTAMC8efNw8+bNu6539epVfPXVV1Cr1bC1tcU333yjszw/Px/l5eUYPny4XvVWPyIYGxur80jln3/+ieTkZBw6dAg7d+7EoEGDlGXVdwqrmZmZQaPRKK/79OkDEcHcuXN16iosLMS6dev0istU9TYV5ubmStI3YMAArFu3DsXFxfj222+hVqvrvd3b9+/dfPjhhzh69Cg++OADdOzYEYBh9ntFRQUSEhIAAOPGjUNGRgaqqqqwZ8+eBj2ufOyTiIiIiBrEX//6V3zyySeYM2cOBg4ciI8//lgZKOPy5cvYs2cPNm7ciBUrVsDBwQFLly5FVFQUfvjhByVJWrFiBSIiIvDMM88AgJJEVj8WCNzqQ3f9+nWICPz8/PDss89iy5YtGDRoEEaPHo0zZ87g999/x6ZNm5QBOTZs2ID+/fsjKysLOTk5uHDhAo4cOQInJye4uLhg+/btyM7OxpUrV+Dn5wdvb29s3LgRN27cwMiRI/Hnn38iLS0NX3/9tV5xVT+Cauh6mzKVSgULCwtUVlbCy8sLL774Il588UVlABZDqO7Pd+dckqdPn8aHH36IlStXYtasWZg8ebKybPDgwQ98vAHg888/x8yZM2Fubg5XV1e0adMG/fr1g1qtbrjjet9jhxIRERERyf1N9XC73NxcmTZtmqjVanFxcRFvb28ZOHCgJCQkiEaj0Vl3y5YtEhQUJDNnzpTY2Fh5//33paqqSkRE9uzZI927dxcAMn36dCksLJTExESxs7MTALJw4UKprKyU8vJymT59unTs2FGcnJwkMjJSLl++rNQxbdo0sbW1FbVaLbt375bt27eLg4ODhISESGlpqRw+fFjc3NzEw8NDUlJSRESkuLhYwsPDpX379uLo6Cjjx4+X/Pz8+4rL0PXqq7FO9fD444/L8uXL6/w89Y3/+++/l+eee06pz9/fXwYNGiRDhw6VZ599VqKjoyU7O/uu733Q411WVibe3t7y3HPPyXvvvSdTpkyRNWvW6LX9+1XbVA8qkTrufRIRERER3YVKpUJSUlKjGDiE9JecnIwxY8bU+QhkQ5g4cSK6dOmCF198Ed26ddPrPY0p/saolv2Twsc+iYiIiIjIJL744gtTh9CscMAXIiIiIiKiZoDJHxERERERUTPA5I+IiIioGfvvf/+Lc+fOmToMImoA7PNHRERE1IytXbsWS5YsgaWlJVxcXODu7g53d3d07twZXbp0QZcuXdCpUyd07NgRFhb86kjUlPEMJiLSQ3p6Os6ePWvqMOgennrqKbi6upo6jHpJTk42dQhkYqZuv9UTZms0Gpw+fRqnT5/Gvn37YG5uDq1Wq0yMbm5uDgcHB3Tu3BkeHh549NFHAQDHjh1DSEgIzMz4QBlRY8fkj4hID8uXL8emTZtMHQbdQ1Mean7MmDGmDoFMzNTt18fHp0ZZVVWVkvRV02q1uHDhAi5cuIBDhw4p5S1atGDiR9RE8EwlItJTSEgIRIR/jezvYZCUlGTy/ci/5tt+27dvf193Hi0tLdGiRQssWLAAANC9e3djhUZEBsbkj4iIiKiZunHjBtLS0tC+ffs6+/NV390LDAzE77//joULFzZAhERkSHzsk4iIiKiZyM3NRUZGBg4ePIiDBw/i119/hUajQevWrWt9n6WlJZycnPDpp59i6NChDRQtERkakz8iIiKih1BpaSmys7ORlZWFAwcOYN++fSgsLISFhQU8PDzg7++PGTNmwMvLC6WlpcrAL7ezsLCAiCAyMhKLFy+uM0kkosaNyR8RERHRQ+DUqVNITU1FVlYWsrKycOjQIWg0Gjg7O8PLywuRkZHw9/eHn58fWrVqpfNejUYDKysr3Lx5UylTqVR48sknsXbtWnh6ejb0xyEiI2DyR0RERNTEXL16FYcOHVKSvfT0dBQXF8PS0hJ/+ctf4OfnhylTpiAgIECZkqE21e/7+eefYWlpCRsbG8THx2P8+PFQqVQN8ImIqCEw+SMiIiJqxCorK/Hbb78pj2+mpqbixIkTEBE4OzvD398fsbGx8PLygre3N1q0aFGvegICApCVlYXx48fjvffeQ7t27Qz8SYjI1Jj8ERERETUi586dw88//6wke2lpaSgvL4etrS3+8pe/IDAwEAsXLsTAgQPh6OhosHqff/55hIaGwtfX12DbJKLGhckfERERkQmdOnUKH3/8sdJXLycnB+bm5ujRowe8vLywZMkS+Pv7o1+/fkadTN3f399o2yaixoHJHxEREZEJzZs3D23atIG3tzdCQ0Ph5eUFf39/tG3b1tShEdFDhskfERERkQmtWLECUVFRpg6j3tLT000dAt2nh+WYJScnmzqERqm248vkj4iIiMiEnJycTB3CA4mPj0d8fLypw6BmaMyYMaYOoclh8kdERERE9SIipg6BmqGwsDCEhYWZOowmyXi9homIiIiIiKjRYPJHRERERETUDDD5IyIygt27d2PSpElQqVRQqVQYMmQINm7caOqwsHnzZqjVaiWu6OhoZGdnmzos0tO//vUveHp6QqVSISAgAJWVlTrLS0pKEBcXBzs7O9jY2CA2NhbFxcUmirZulZWVSE9Px4IFC7Bz506lfM+ePVCr1fjf//5n1Pobqh4iosaCff6IiIwgMDAQgYGB2Lp1K4qKirBmzRq4ubmZJJZz587B2dkZADB69Gg4OTkhICAAffr0wUcffWSSmKh+xo4di0GDBsHFxQWpqamIiYnBsmXLlOVt27ZFbGwsLl26BI1Gg7i4OBNGW7fMzEysWbMG69atw9q1a5XykpISnD17FmVlZQat7/ZzwZj1EBE1VrzzR0RkRG3atAEAk83XdfXqVUREROiUOTg4AADatWtnipAeWgUFBQ1Sj6OjI5ycnNCmTRu8//77+Pbbb2us06VLF7i7uzdIPA/C19f3rlMcjB49Gvn5+fD09DRYXXc7F4xRDxFRY8bkj4jIiFQqlc5/G1JZWRlCQ0ORm5vbaGJ6mD3xxBPw9vbGP/7xD1y4cMGodTk6OmLDhg0AgJdeeglnzpzRWd6yZUu0aNHCqDEYipWVldHruNe5QETU3DD5IyJqQNnZ2Xj99dfh7u6OkpISTJgwAQ4ODujfvz9OnToFAMjJyUFMTAx69eqF/Px8jBgxAu3atUP//v2RkZEBAEhKSoKtra3yKOnVq1cRHx+Pli1bwtfXFwCwZcsWnDhxAkVFRZg8eTI++OCD+473woULmDJlCuLi4jB58mSMGjVK6UO2detW2NraQqVSIT4+Hjdv3gRwa3JZZ2dnLFmyBMCtoeBXr16NyMhI+Pj4ICgoCH/88QcAID8/H++++y569+6N8+fPIygoCJ07d27U/dTuRaPR4Oeff0Z0dDRcXFzwzDPPYP369bhy5YpR6hsxYgTmzZuHS5cuISwsDBqNptb1N23ahKioKMyZMwdDhgxBTEwMKioqANR+HI4fP4758+ejR48eOHPmDObPn49OnTrB09MTe/fuxY0bNxAdHY2uXbvCzc0N3333nU69tbWhe7l48SJWrlyJgwcPKmWPPPIIXn75ZURHRyM6OhoeHh5QqVT46quv6qznXufC3eqpa1/pcw4TETVaQkREdQoJCZGQkJD7fl+3bt0EgJSWloqIyLlz5yQwMFAAyNSpU+X48eOya9cusbOzk7Fjx4qIyP79+6VXr15ibm4u0dHRsnfvXtm8ebPY29uLtbW1FBQUiIhIUFCQuLq66tT35JNPilqtVl4PGzZMunTporPOyZMnBYAMHDiwzvgHDhwoY8aMUV737dtXxo0bp7x+8803BYBkZmYqZRUVFeLj46O8Xrp0qaxfv15ERCorK0WtVkuHDh2krKxM/vOf/0jPnj3F3NxcFi1aJJ9//rn0799f8vPz64ytGgBJSkrSe31jadeunQBQ/szNzcXc3FwsLCzk2WeflQ0bNijt4Hb1if/xxx8XERGtVqu0p+joaGX56tWrZeXKlcrr5cuXi5+fn9y8eVNERIqKiqR79+4yYMAAqaqqqvU4FBYWSkREhACQV155RbKysuTq1avi7+8v7u7uMnPmTMnJyZFr167J008/Le7u7jqx1tWGjh07JgBk7dq1IiKSmpoqAQEBAkA2bdqkrBcXF6f8Ozc3V1q2bCn+/v5SVVWlVz13ngv3qqeufaXPOXw/Gkv7JaJmIZl3/oiIGlCHDh3g7e0NAFi8eDF69eqFwMBABAQEICsrCwAQEBAAHx8fqFQqLFu2DAMHDsTzzz+PTz75BOXl5Vi9ejUAwNrausb2LSwMP45X3759lX/37t0bR44cUV7PmDEDFhYW+PTTT5WyXbt2YdiwYQBu9YOLj49X+lqZm5sjJCQE58+fx7Zt2zBkyBD4+flBq9UiPDwcEydOxMGDB+Hi4mLwz9HQtFottFotKisrsWvXLrz88sto164dQkJCsG3btjrv1OnDzMwMX3/9Ndzc3PDRRx9hy5YtNdYpLCxEbGwspk2bBktLSwCAvb095s+fj/379yMxMbHW4+Do6Ai1Wg0AmDVrFp544gnY2tri+eefx6lTp/DKK6/gscceQ+vWrTF8+HCcOnUKFy9e1ImhtjZ0Jz8/P8TGxuqUiQheeukl5XVUVBQqKyuRkJCg8/jyg9ajz77S5xwmImqsONonEVEDMzc3B6CbqNna2uLatWs661hYWChfQAFg1KhRsLKywtGjRxss1r179wK41WcqMTERmZmZqKqqUpa7uroiNDQUiYmJWLp0KRwcHJCcnIwFCxYAANLS0qDRaDB16lSd7U6aNAmtWrUCAFhaWsLCwgJdu3atd5yZmZkm78N4+365U/WUDDdv3sTWrVuxefNmPPLIIwgPDwdwK7mpLwcHB2zevBkBAQGYOHEiHn/8cZ3lGRkZKCsrqzHabHWC/uOPPyIiIqLW41DdZs3M/v83Y1tbWwDQaaOtW7cGABQVFcHR0RFA3W3obu78YUOlUinxb9myBTt27MAbb7yB3r17K+sYoh5995U+5zARUWPE5I+IqImwtLSEi4tLjbndjEmr1WLZsmXIzc3F7NmzkZqaqvQ7rBYdHY2vv/4an332GebMmYOioiJlpMkTJ07AxsYGa9asMWqcCQkJ9erTaEg2NjZ6rVd9/C5fvoxVq1YBAL7//nuEhYXVO4H19vbGihUrMHXqVISGhiIiIkJJTE6fPg0AuHTpks57HBwcYG1tXe9RSu8Wa3XZ7UmXPm1IX2VlZXj11VfRqVMnvP322zrLDFGPsfYVEVFjweSPiKgJuXnzJnr06GH0ek6cOAE3NzeMHj0a9vb2tU5Q7+3tDT8/P6xatQo9e/ZEcHCwssza2hp5eXnIy8uDq6urzvuKioqUaSce1BdffIGwsDCDbKu+7O3t65wvztLSEhqNBq1bt8bIkSMRFhaG4cOHY8iQIQ9853LKlClIT0/H+vXrUVBQgJiYGADAo48+CgD3HIzEmO2pqqoKQ4cOrbMN6SsuLg5nzpzBN998o5NsG6oeU+4rIqKGwD5/RERGVP0434M81letsLAQ58+fR0hICIBbj5yVlpZCq9Uq65SWlurcdTEzM6vRt0yfWObNm4ejR49i586dGDRokFKu0Wju+v433ngDBQUFeO211xAaGqqU9+nTByKCuXPn1vgs69atqzOOh4G5uTnMzMxgZWWFwYMHIzk5GcXFxfjnP/+pkyjrS0Tu+XhhQkIC+vXrh3PnzillarUatra2+Oabb3TWzc/PR3l5OYYPH37fMejr0KFDerehuuTk5GD58uUIDg7GiBEjlPKdO3fqVc/dzoU7mXJfERE1BCZ/RERGdPXqVQBASUmJUlY9JcLtj2+WlZXh+vXrOl9WKyoqdPr3LV68GOPGjYOPjw+AW4nV5cuXsXTpUvz+++945513UFFRgd9//x2//PILAMDFxQXnz59HdnY29u3bh/LycuWRtrtNQXDlyhVMmzYNLVu2VPp3bdiwAUePHsX69euRk5ODCxcu4MiRIzpz2QUHB8PT0xN9+/aFvb29Uj548GB4e3tj48aNGD16NP75z39iwYIFCA8Px8svvwzg1pd0rVZrkAFQGovqPptmZmYYMGAA1q1bh+LiYmzfvh2hoaEPNLfd2bNnUVBQgBs3btRY1rJlS2zevBlt27ZVyhwcHLB06VIcOHAAP/zwg1K+YsUKRERE4JlnngFQ+3G4W5utnvrg+vXrSln1e6uXVd/NrK0NVbfD27ddvc3bP+OMGTNgaWmJFStW6NS3c+dOveq527lwZz367it9z2EiokbHNKOMEhE1Lfc71cPevXslMjJSGfZ/6NChkpSUJHv27JHu3bsLAJk+fboUFhZKYmKi2NnZCQBZuHChVFZWyqRJk8TS0lJefvllCQkJkVdeeUUWLVokWq1WqePKlSsSHBwsrVu3FrVaLZmZmTJx4kSZMGGCbN++XUREDh8+LG5ubuLh4SEpKSmydetW8ff3V+Ly8fGRv/3tbxIUFCT9+vWTVq1aCQD57LPPRERk2rRpYmtrK2q1Wnbv3i3bt28XBwcHCQkJqTFtQVRUlKSkpNTYF8XFxRIeHi7t27cXR0dHGT9+vDKVw8aNG8XZ2VkAyKuvvirHjx+/72ODRjJUvr29vQAQlUolAQEB8tlnn0lxcXGd77uf+Lds2SJPP/20AJBRo0bJTz/9dNf1tm/fLqtWrarx3qCgIJk5c6bExsbK+++/r0yTUNtxOHjwoKjVagEg4eHh8ueff8qhQ4fE19dXAMgLL7wgv/32m2RlZSltKzw8XHJzc0Wk9jaUmpoqI0eOFAASEBAgP/74oxw8eFCCg4OV6UjS0tIkKSlJAMhjjz0mc+bMkTlz5khkZKT07dtXZsyYUWc9paWlNc6Fu9Wjz77S9xzWV2Npv0TULCSrRPgTFRFRXaofZUxJSWmQ+iZPnozExESduyqN3eDBg7Ft2za0bNmyQetVqVRISkoyeZ+/YcOGYdCgQQgLC0PHjh31fl9jiZ9Mg8efiBpQCgd8ISKiB7Zv3z54eXk1eOLXmHz77bemDoGIiKhWTP6IiBqhiooKZcAKU89fdy8//fQTpk2bht69e+PYsWPYt2+fqUMiIiKiWnDAFyKiRuadd97B1q1bodVq8frrr+PQoUOmDumu7O3tcePGDfz8889ISEgw2LQNREREZBy880dE1Mi89dZbeOutt0wdRp169eqF3NxcU4dBREREeuKdPyIiIiIiomaAyR8REREREVEzwOSPiIiIiIioGWDyR0RERERE1Aww+SMiIiIiImoGmPwRERERERE1A0z+iIiIiIiImgEmf0RERERERM0Akz8iIiIiIqJmgMkfERERERFRM8Dkj4iIiIiIqBlg8kdERERERNQMMPkjIiIiIiJqBixMHQARUVORl5eH5ORkU4dBD6H09HRTh0BERM0Akz8iIj1lZGRgzJgxpg6DHkLx8fGIj483dRhERPSQU4mImDoIIiIiIiIiMqoU9vkjIiIiIiJqBpj8ERERERERNQNM/oiIiIiIiJoBJn9ERERERETNwP8BdjgobpgqfFoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(TBNNModel_changed_branches, \"multi_input_and_output_model.png\", show_layer_names=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training (old results, no batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Flow_parameters_input_layer (I  [(None, 30)]        0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 30)          61          ['Flow_parameters_input_layer[0][\n",
      " )                                                               0]']                             \n",
      "                                                                                                  \n",
      " First_hidden_layer (Dense)     (None, 64)           1984        ['normalization_2[0][0]']        \n",
      "                                                                                                  \n",
      " Tensor_input_layer (InputLayer  [(None, 63)]        0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Second_hidden_layer (Dense)    (None, 64)           4160        ['First_hidden_layer[0][0]']     \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 63)          127         ['Tensor_input_layer[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Parameters_concatenation (Conc  (None, 127)         0           ['Second_hidden_layer[0][0]',    \n",
      " atenate)                                                         'normalization_1[0][0]']        \n",
      "                                                                                                  \n",
      " Last_hidden_layer (Dense)      (None, 5)            640         ['Parameters_concatenation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,972\n",
      "Trainable params: 6,784\n",
      "Non-trainable params: 188\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.7067 - mean_absolute_error: 0.7067 - val_loss: 0.2011 - val_mean_absolute_error: 0.2011\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.5679 - mean_absolute_error: 0.5679 - val_loss: 0.1959 - val_mean_absolute_error: 0.1959\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.5511 - mean_absolute_error: 0.5511 - val_loss: 0.1918 - val_mean_absolute_error: 0.1918\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.5350 - mean_absolute_error: 0.5350 - val_loss: 0.1846 - val_mean_absolute_error: 0.1846\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.5055 - mean_absolute_error: 0.5055 - val_loss: 0.1704 - val_mean_absolute_error: 0.1704\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.4351 - mean_absolute_error: 0.4351 - val_loss: 0.1304 - val_mean_absolute_error: 0.1304\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.2850 - mean_absolute_error: 0.2850 - val_loss: 0.0599 - val_mean_absolute_error: 0.0599\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.1032 - mean_absolute_error: 0.1032 - val_loss: 0.0421 - val_mean_absolute_error: 0.0421\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0578 - mean_absolute_error: 0.0578 - val_loss: 0.0252 - val_mean_absolute_error: 0.0252\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0445 - mean_absolute_error: 0.0445 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0405 - mean_absolute_error: 0.0405 - val_loss: 0.0246 - val_mean_absolute_error: 0.0246\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0361 - mean_absolute_error: 0.0361 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0229 - val_mean_absolute_error: 0.0229\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0338 - mean_absolute_error: 0.0338 - val_loss: 0.0270 - val_mean_absolute_error: 0.0270\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0300 - mean_absolute_error: 0.0300 - val_loss: 0.0425 - val_mean_absolute_error: 0.0425\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0267 - val_mean_absolute_error: 0.0267\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0283 - mean_absolute_error: 0.0283 - val_loss: 0.0189 - val_mean_absolute_error: 0.0189\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0184 - val_mean_absolute_error: 0.0184\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0269 - mean_absolute_error: 0.0269 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0280 - mean_absolute_error: 0.0280 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0283 - mean_absolute_error: 0.0283 - val_loss: 0.0278 - val_mean_absolute_error: 0.0278\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0270 - mean_absolute_error: 0.0270 - val_loss: 0.0103 - val_mean_absolute_error: 0.0103\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0261 - mean_absolute_error: 0.0261 - val_loss: 0.0088 - val_mean_absolute_error: 0.0088\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0235 - mean_absolute_error: 0.0235 - val_loss: 0.0099 - val_mean_absolute_error: 0.0099\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0257 - mean_absolute_error: 0.0257 - val_loss: 0.0194 - val_mean_absolute_error: 0.0194\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0279 - mean_absolute_error: 0.0279 - val_loss: 0.0180 - val_mean_absolute_error: 0.0180\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0270 - mean_absolute_error: 0.0270 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.0255 - mean_absolute_error: 0.0255 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0230 - mean_absolute_error: 0.0230 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0267 - mean_absolute_error: 0.0267 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0267 - mean_absolute_error: 0.0267 - val_loss: 0.0089 - val_mean_absolute_error: 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0238 - mean_absolute_error: 0.0238 - val_loss: 0.0126 - val_mean_absolute_error: 0.0126\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0234 - mean_absolute_error: 0.0234 - val_loss: 0.0085 - val_mean_absolute_error: 0.0085\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0242 - mean_absolute_error: 0.0242 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0249 - mean_absolute_error: 0.0249 - val_loss: 0.0105 - val_mean_absolute_error: 0.0105\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0264 - mean_absolute_error: 0.0264 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0262 - mean_absolute_error: 0.0262 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0248 - mean_absolute_error: 0.0248 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0230 - mean_absolute_error: 0.0230 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0263 - mean_absolute_error: 0.0263 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0257 - mean_absolute_error: 0.0257 - val_loss: 0.0120 - val_mean_absolute_error: 0.0120\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0235 - mean_absolute_error: 0.0235 - val_loss: 0.0086 - val_mean_absolute_error: 0.0086\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 0.0222 - mean_absolute_error: 0.0222 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0260 - mean_absolute_error: 0.0260 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0255 - mean_absolute_error: 0.0255 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 0.0257 - mean_absolute_error: 0.0257 - val_loss: 0.0234 - val_mean_absolute_error: 0.0234\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 0.0235 - mean_absolute_error: 0.0235 - val_loss: 0.0191 - val_mean_absolute_error: 0.0191\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 0.0255 - mean_absolute_error: 0.0255 - val_loss: 0.0148 - val_mean_absolute_error: 0.0148\n",
      "CPU times: user 2min 55s, sys: 14.4 s, total: 3min 9s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "histories['TBNNModel'] = compile_and_fitTBNN(\n",
    "#histories['TBNNModel'] = compile_and_fit(\n",
    "    TBNNModel,\n",
    "    'TBNNModel',\n",
    "#    [inputs_long, inputs_short],\n",
    "#    train_target,\n",
    "    max_epochs=50)#,\n",
    "    #callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Flow_parameters_input_layer (I  [(None, 9)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 9)           19          ['Flow_parameters_input_layer[0][\n",
      " )                                                               0]']                             \n",
      "                                                                                                  \n",
      " First_hidden_layer (Dense)     (None, 64)           640         ['normalization_2[1][0]']        \n",
      "                                                                                                  \n",
      " Tensor_input_layer (InputLayer  [(None, 97)]        0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Second_hidden_layer (Dense)    (None, 64)           4160        ['First_hidden_layer[0][0]']     \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 97)          195         ['Tensor_input_layer[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Parameters_concatenation (Conc  (None, 161)         0           ['Second_hidden_layer[0][0]',    \n",
      " atenate)                                                         'normalization_1[1][0]']        \n",
      "                                                                                                  \n",
      " Last_hidden_layer (Dense)      (None, 5)            810         ['Parameters_concatenation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,824\n",
      "Trainable params: 5,610\n",
      "Non-trainable params: 214\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 8s 62ms/step - loss: 0.7969 - mean_absolute_error: 0.7969 - val_loss: 0.2723 - val_mean_absolute_error: 0.2723\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5961 - mean_absolute_error: 0.5961 - val_loss: 0.2269 - val_mean_absolute_error: 0.2269\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5744 - mean_absolute_error: 0.5744 - val_loss: 0.2099 - val_mean_absolute_error: 0.2099\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5676 - mean_absolute_error: 0.5676 - val_loss: 0.2036 - val_mean_absolute_error: 0.2036\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5640 - mean_absolute_error: 0.5640 - val_loss: 0.2010 - val_mean_absolute_error: 0.2010\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5619 - mean_absolute_error: 0.5619 - val_loss: 0.1993 - val_mean_absolute_error: 0.1993\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5602 - mean_absolute_error: 0.5602 - val_loss: 0.1979 - val_mean_absolute_error: 0.1979\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5586 - mean_absolute_error: 0.5586 - val_loss: 0.1969 - val_mean_absolute_error: 0.1969\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5580 - mean_absolute_error: 0.5580 - val_loss: 0.1974 - val_mean_absolute_error: 0.1974\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5575 - mean_absolute_error: 0.5575 - val_loss: 0.1962 - val_mean_absolute_error: 0.1962\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5563 - mean_absolute_error: 0.5563 - val_loss: 0.1963 - val_mean_absolute_error: 0.1963\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5558 - mean_absolute_error: 0.5558 - val_loss: 0.1948 - val_mean_absolute_error: 0.1948\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5548 - mean_absolute_error: 0.5548 - val_loss: 0.1952 - val_mean_absolute_error: 0.1952\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5538 - mean_absolute_error: 0.5538 - val_loss: 0.1948 - val_mean_absolute_error: 0.1948\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5532 - mean_absolute_error: 0.5532 - val_loss: 0.1939 - val_mean_absolute_error: 0.1939\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5524 - mean_absolute_error: 0.5524 - val_loss: 0.1937 - val_mean_absolute_error: 0.1937\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 120603s 1013s/step - loss: 0.5518 - mean_absolute_error: 0.5518 - val_loss: 0.1941 - val_mean_absolute_error: 0.1941\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5511 - mean_absolute_error: 0.5511 - val_loss: 0.1939 - val_mean_absolute_error: 0.1939\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.5503 - mean_absolute_error: 0.5503 - val_loss: 0.1933 - val_mean_absolute_error: 0.1933\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 0.5497 - mean_absolute_error: 0.5497 - val_loss: 0.1927 - val_mean_absolute_error: 0.1927\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5487 - mean_absolute_error: 0.5487 - val_loss: 0.1930 - val_mean_absolute_error: 0.1930\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.5480 - mean_absolute_error: 0.5480 - val_loss: 0.1930 - val_mean_absolute_error: 0.1930\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5473 - mean_absolute_error: 0.5473 - val_loss: 0.1933 - val_mean_absolute_error: 0.1933\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5464 - mean_absolute_error: 0.5464 - val_loss: 0.1918 - val_mean_absolute_error: 0.1918\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5458 - mean_absolute_error: 0.5458 - val_loss: 0.1923 - val_mean_absolute_error: 0.1923\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5449 - mean_absolute_error: 0.5449 - val_loss: 0.1919 - val_mean_absolute_error: 0.1919\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5450 - mean_absolute_error: 0.5450 - val_loss: 0.1911 - val_mean_absolute_error: 0.1911\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5436 - mean_absolute_error: 0.5436 - val_loss: 0.1903 - val_mean_absolute_error: 0.1903\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5424 - mean_absolute_error: 0.5424 - val_loss: 0.1911 - val_mean_absolute_error: 0.1911\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5424 - mean_absolute_error: 0.5424 - val_loss: 0.1910 - val_mean_absolute_error: 0.1910\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5418 - mean_absolute_error: 0.5418 - val_loss: 0.1902 - val_mean_absolute_error: 0.1902\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5402 - mean_absolute_error: 0.5402 - val_loss: 0.1894 - val_mean_absolute_error: 0.1894\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5397 - mean_absolute_error: 0.5397 - val_loss: 0.1902 - val_mean_absolute_error: 0.1902\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5390 - mean_absolute_error: 0.5390 - val_loss: 0.1891 - val_mean_absolute_error: 0.1891\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5381 - mean_absolute_error: 0.5381 - val_loss: 0.1890 - val_mean_absolute_error: 0.1890\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5374 - mean_absolute_error: 0.5374 - val_loss: 0.1885 - val_mean_absolute_error: 0.1885\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5367 - mean_absolute_error: 0.5367 - val_loss: 0.1873 - val_mean_absolute_error: 0.1873\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5359 - mean_absolute_error: 0.5359 - val_loss: 0.1881 - val_mean_absolute_error: 0.1881\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5350 - mean_absolute_error: 0.5350 - val_loss: 0.1883 - val_mean_absolute_error: 0.1883\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5341 - mean_absolute_error: 0.5341 - val_loss: 0.1875 - val_mean_absolute_error: 0.1875\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5336 - mean_absolute_error: 0.5336 - val_loss: 0.1882 - val_mean_absolute_error: 0.1882\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5327 - mean_absolute_error: 0.5327 - val_loss: 0.1867 - val_mean_absolute_error: 0.1867\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5321 - mean_absolute_error: 0.5321 - val_loss: 0.1868 - val_mean_absolute_error: 0.1868\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5312 - mean_absolute_error: 0.5312 - val_loss: 0.1869 - val_mean_absolute_error: 0.1869\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5303 - mean_absolute_error: 0.5303 - val_loss: 0.1856 - val_mean_absolute_error: 0.1856\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5298 - mean_absolute_error: 0.5298 - val_loss: 0.1856 - val_mean_absolute_error: 0.1856\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5292 - mean_absolute_error: 0.5292 - val_loss: 0.1856 - val_mean_absolute_error: 0.1856\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5282 - mean_absolute_error: 0.5282 - val_loss: 0.1846 - val_mean_absolute_error: 0.1846\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5274 - mean_absolute_error: 0.5274 - val_loss: 0.1854 - val_mean_absolute_error: 0.1854\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5269 - mean_absolute_error: 0.5269 - val_loss: 0.1854 - val_mean_absolute_error: 0.1854\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5264 - mean_absolute_error: 0.5264 - val_loss: 0.1848 - val_mean_absolute_error: 0.1848\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5253 - mean_absolute_error: 0.5253 - val_loss: 0.1843 - val_mean_absolute_error: 0.1843\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5246 - mean_absolute_error: 0.5246 - val_loss: 0.1836 - val_mean_absolute_error: 0.1836\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5239 - mean_absolute_error: 0.5239 - val_loss: 0.1837 - val_mean_absolute_error: 0.1837\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5231 - mean_absolute_error: 0.5231 - val_loss: 0.1839 - val_mean_absolute_error: 0.1839\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5221 - mean_absolute_error: 0.5221 - val_loss: 0.1831 - val_mean_absolute_error: 0.1831\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5215 - mean_absolute_error: 0.5215 - val_loss: 0.1826 - val_mean_absolute_error: 0.1826\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5208 - mean_absolute_error: 0.5208 - val_loss: 0.1827 - val_mean_absolute_error: 0.1827\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5199 - mean_absolute_error: 0.5199 - val_loss: 0.1822 - val_mean_absolute_error: 0.1822\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5192 - mean_absolute_error: 0.5192 - val_loss: 0.1813 - val_mean_absolute_error: 0.1813\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5184 - mean_absolute_error: 0.5184 - val_loss: 0.1812 - val_mean_absolute_error: 0.1812\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.5179 - mean_absolute_error: 0.5179 - val_loss: 0.1815 - val_mean_absolute_error: 0.1815\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5170 - mean_absolute_error: 0.5170 - val_loss: 0.1818 - val_mean_absolute_error: 0.1818\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5164 - mean_absolute_error: 0.5164 - val_loss: 0.1819 - val_mean_absolute_error: 0.1819\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5155 - mean_absolute_error: 0.5155 - val_loss: 0.1808 - val_mean_absolute_error: 0.1808\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5147 - mean_absolute_error: 0.5147 - val_loss: 0.1797 - val_mean_absolute_error: 0.1797\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5142 - mean_absolute_error: 0.5142 - val_loss: 0.1800 - val_mean_absolute_error: 0.1800\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5132 - mean_absolute_error: 0.5132 - val_loss: 0.1805 - val_mean_absolute_error: 0.1805\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5126 - mean_absolute_error: 0.5126 - val_loss: 0.1795 - val_mean_absolute_error: 0.1795\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5121 - mean_absolute_error: 0.5121 - val_loss: 0.1795 - val_mean_absolute_error: 0.1795\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.5111 - mean_absolute_error: 0.5111 - val_loss: 0.1789 - val_mean_absolute_error: 0.1789\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5104 - mean_absolute_error: 0.5104 - val_loss: 0.1790 - val_mean_absolute_error: 0.1790\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5098 - mean_absolute_error: 0.5098 - val_loss: 0.1790 - val_mean_absolute_error: 0.1790\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5092 - mean_absolute_error: 0.5092 - val_loss: 0.1786 - val_mean_absolute_error: 0.1786\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5081 - mean_absolute_error: 0.5081 - val_loss: 0.1786 - val_mean_absolute_error: 0.1786\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.5073 - mean_absolute_error: 0.5073 - val_loss: 0.1775 - val_mean_absolute_error: 0.1775\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5067 - mean_absolute_error: 0.5067 - val_loss: 0.1778 - val_mean_absolute_error: 0.1778\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5058 - mean_absolute_error: 0.5058 - val_loss: 0.1770 - val_mean_absolute_error: 0.1770\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5051 - mean_absolute_error: 0.5051 - val_loss: 0.1773 - val_mean_absolute_error: 0.1773\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5043 - mean_absolute_error: 0.5043 - val_loss: 0.1773 - val_mean_absolute_error: 0.1773\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.5036 - mean_absolute_error: 0.5036 - val_loss: 0.1766 - val_mean_absolute_error: 0.1766\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5030 - mean_absolute_error: 0.5030 - val_loss: 0.1764 - val_mean_absolute_error: 0.1764\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5023 - mean_absolute_error: 0.5023 - val_loss: 0.1759 - val_mean_absolute_error: 0.1759\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5014 - mean_absolute_error: 0.5014 - val_loss: 0.1758 - val_mean_absolute_error: 0.1758\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5007 - mean_absolute_error: 0.5007 - val_loss: 0.1756 - val_mean_absolute_error: 0.1756\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5000 - mean_absolute_error: 0.5000 - val_loss: 0.1748 - val_mean_absolute_error: 0.1748\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4992 - mean_absolute_error: 0.4992 - val_loss: 0.1751 - val_mean_absolute_error: 0.1751\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.4985 - mean_absolute_error: 0.4985 - val_loss: 0.1757 - val_mean_absolute_error: 0.1757\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4980 - mean_absolute_error: 0.4980 - val_loss: 0.1746 - val_mean_absolute_error: 0.1746\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4969 - mean_absolute_error: 0.4969 - val_loss: 0.1738 - val_mean_absolute_error: 0.1738\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.4962 - mean_absolute_error: 0.4962 - val_loss: 0.1727 - val_mean_absolute_error: 0.1727\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.4954 - mean_absolute_error: 0.4954 - val_loss: 0.1735 - val_mean_absolute_error: 0.1735\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4947 - mean_absolute_error: 0.4947 - val_loss: 0.1737 - val_mean_absolute_error: 0.1737\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.4938 - mean_absolute_error: 0.4938 - val_loss: 0.1729 - val_mean_absolute_error: 0.1729\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.4932 - mean_absolute_error: 0.4932 - val_loss: 0.1722 - val_mean_absolute_error: 0.1722\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.4926 - mean_absolute_error: 0.4926 - val_loss: 0.1728 - val_mean_absolute_error: 0.1728\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.4918 - mean_absolute_error: 0.4918 - val_loss: 0.1717 - val_mean_absolute_error: 0.1717\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.4910 - mean_absolute_error: 0.4910 - val_loss: 0.1719 - val_mean_absolute_error: 0.1719\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.4903 - mean_absolute_error: 0.4903 - val_loss: 0.1719 - val_mean_absolute_error: 0.1719\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.4897 - mean_absolute_error: 0.4897 - val_loss: 0.1723 - val_mean_absolute_error: 0.1723\n",
      "CPU times: user 20min 23s, sys: 1min 15s, total: 21min 39s\n",
      "Wall time: 1d 9h 41min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#DATA:\n",
    "#long_input_labels = invar_labels\n",
    "#short_input_labels = tensor_labels + grad_labels + vector_labels + param_labels\n",
    "histories['TBNNModel'] = compile_and_fitTBNN(\n",
    "#histories['TBNNModel'] = compile_and_fit(\n",
    "    TBNNModel,\n",
    "    'TBNNModel',\n",
    "#    [inputs_long, inputs_short],\n",
    "#    train_target,\n",
    "    max_epochs=100)#,\n",
    "    #callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Tensor_input_layer (InputLayer  [(None, 97)]        0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_8 (Normalization  (None, 97)          195         ['Tensor_input_layer[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " First_hidden_layer (Dense)     (None, 64)           6272        ['normalization_8[1][0]']        \n",
      "                                                                                                  \n",
      " Flow_parameters_input_layer (I  [(None, 9)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " Second_hidden_layer (Dense)    (None, 64)           4160        ['First_hidden_layer[0][0]']     \n",
      "                                                                                                  \n",
      " normalization_9 (Normalization  (None, 9)           19          ['Flow_parameters_input_layer[0][\n",
      " )                                                               0]']                             \n",
      "                                                                                                  \n",
      " Parameters_concatenation (Conc  (None, 73)          0           ['Second_hidden_layer[0][0]',    \n",
      " atenate)                                                         'normalization_9[1][0]']        \n",
      "                                                                                                  \n",
      " Last_hidden_layer (Dense)      (None, 5)            370         ['Parameters_concatenation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,016\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 214\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.6990 - mean_absolute_error: 0.6990 - val_loss: 0.2046 - val_mean_absolute_error: 0.2046\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.5742 - mean_absolute_error: 0.5742 - val_loss: 0.1994 - val_mean_absolute_error: 0.1994\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.5608 - mean_absolute_error: 0.5608 - val_loss: 0.1947 - val_mean_absolute_error: 0.1947\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 4s 38ms/step - loss: 0.5543 - mean_absolute_error: 0.5543 - val_loss: 0.1913 - val_mean_absolute_error: 0.1913\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.5456 - mean_absolute_error: 0.5456 - val_loss: 0.1910 - val_mean_absolute_error: 0.1910\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.5334 - mean_absolute_error: 0.5334 - val_loss: 0.1832 - val_mean_absolute_error: 0.1832\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.5106 - mean_absolute_error: 0.5106 - val_loss: 0.1722 - val_mean_absolute_error: 0.1722\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.4635 - mean_absolute_error: 0.4635 - val_loss: 0.1546 - val_mean_absolute_error: 0.1546\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 4s 38ms/step - loss: 0.3686 - mean_absolute_error: 0.3686 - val_loss: 0.1049 - val_mean_absolute_error: 0.1049\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.2296 - mean_absolute_error: 0.2296 - val_loss: 0.0619 - val_mean_absolute_error: 0.0619\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.1092 - mean_absolute_error: 0.1092 - val_loss: 0.0610 - val_mean_absolute_error: 0.0610\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.0461 - val_mean_absolute_error: 0.0461\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 4s 38ms/step - loss: 0.0712 - mean_absolute_error: 0.0712 - val_loss: 0.0248 - val_mean_absolute_error: 0.0248\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0591 - mean_absolute_error: 0.0591 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0518 - mean_absolute_error: 0.0518 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0527 - mean_absolute_error: 0.0527 - val_loss: 0.0374 - val_mean_absolute_error: 0.0374\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0492 - mean_absolute_error: 0.0492 - val_loss: 0.0233 - val_mean_absolute_error: 0.0233\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0459 - mean_absolute_error: 0.0459 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0464 - mean_absolute_error: 0.0464 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0410 - mean_absolute_error: 0.0410 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0443 - mean_absolute_error: 0.0443 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0413 - mean_absolute_error: 0.0413 - val_loss: 0.0332 - val_mean_absolute_error: 0.0332\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0473 - mean_absolute_error: 0.0473 - val_loss: 0.0120 - val_mean_absolute_error: 0.0120\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0444 - mean_absolute_error: 0.0444 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0386 - mean_absolute_error: 0.0386 - val_loss: 0.0133 - val_mean_absolute_error: 0.0133\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0414 - mean_absolute_error: 0.0414 - val_loss: 0.0260 - val_mean_absolute_error: 0.0260\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 6s 48ms/step - loss: 0.0438 - mean_absolute_error: 0.0438 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0428 - mean_absolute_error: 0.0428 - val_loss: 0.0302 - val_mean_absolute_error: 0.0302\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0387 - mean_absolute_error: 0.0387 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0398 - mean_absolute_error: 0.0398 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0435 - mean_absolute_error: 0.0435 - val_loss: 0.0134 - val_mean_absolute_error: 0.0134\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0410 - mean_absolute_error: 0.0410 - val_loss: 0.0191 - val_mean_absolute_error: 0.0191\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0406 - mean_absolute_error: 0.0406 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 4s 38ms/step - loss: 0.0373 - mean_absolute_error: 0.0373 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0391 - mean_absolute_error: 0.0391 - val_loss: 0.0277 - val_mean_absolute_error: 0.0277\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0385 - mean_absolute_error: 0.0385 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0384 - mean_absolute_error: 0.0384 - val_loss: 0.0178 - val_mean_absolute_error: 0.0178\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0383 - mean_absolute_error: 0.0383 - val_loss: 0.0323 - val_mean_absolute_error: 0.0323\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0377 - mean_absolute_error: 0.0377 - val_loss: 0.0181 - val_mean_absolute_error: 0.0181\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0353 - mean_absolute_error: 0.0353 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0384 - mean_absolute_error: 0.0384 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.0388 - mean_absolute_error: 0.0388 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0399 - mean_absolute_error: 0.0399 - val_loss: 0.0421 - val_mean_absolute_error: 0.0421\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0382 - mean_absolute_error: 0.0382 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0578 - mean_absolute_error: 0.0578 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0344 - mean_absolute_error: 0.0344 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.0358 - mean_absolute_error: 0.0358 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0356 - mean_absolute_error: 0.0356 - val_loss: 0.0357 - val_mean_absolute_error: 0.0357\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0394 - mean_absolute_error: 0.0394 - val_loss: 0.0156 - val_mean_absolute_error: 0.0156\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0371 - mean_absolute_error: 0.0371 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0331 - mean_absolute_error: 0.0331 - val_loss: 0.0080 - val_mean_absolute_error: 0.0080\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0364 - mean_absolute_error: 0.0364 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0342 - mean_absolute_error: 0.0342 - val_loss: 0.0291 - val_mean_absolute_error: 0.0291\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0389 - mean_absolute_error: 0.0389 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0358 - mean_absolute_error: 0.0358 - val_loss: 0.0148 - val_mean_absolute_error: 0.0148\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0347 - mean_absolute_error: 0.0347 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0355 - mean_absolute_error: 0.0355 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0371 - mean_absolute_error: 0.0371 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0373 - val_mean_absolute_error: 0.0373\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0288 - val_mean_absolute_error: 0.0288\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0338 - mean_absolute_error: 0.0338 - val_loss: 0.0184 - val_mean_absolute_error: 0.0184\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0343 - mean_absolute_error: 0.0343 - val_loss: 0.0091 - val_mean_absolute_error: 0.0091\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0343 - mean_absolute_error: 0.0343 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 5s 40ms/step - loss: 0.0360 - mean_absolute_error: 0.0360 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0350 - mean_absolute_error: 0.0350 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0337 - mean_absolute_error: 0.0337 - val_loss: 0.0092 - val_mean_absolute_error: 0.0092\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0363 - mean_absolute_error: 0.0363 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0293 - mean_absolute_error: 0.0293 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 5s 46ms/step - loss: 0.0295 - mean_absolute_error: 0.0295 - val_loss: 0.0109 - val_mean_absolute_error: 0.0109\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0358 - mean_absolute_error: 0.0358 - val_loss: 0.0120 - val_mean_absolute_error: 0.0120\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.0340 - mean_absolute_error: 0.0340 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 6s 49ms/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0133 - val_mean_absolute_error: 0.0133\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0354 - mean_absolute_error: 0.0354 - val_loss: 0.0262 - val_mean_absolute_error: 0.0262\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0114 - val_mean_absolute_error: 0.0114\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.0336 - mean_absolute_error: 0.0336 - val_loss: 0.0231 - val_mean_absolute_error: 0.0231\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0102 - val_mean_absolute_error: 0.0102\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0278 - mean_absolute_error: 0.0278 - val_loss: 0.0131 - val_mean_absolute_error: 0.0131\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0281 - mean_absolute_error: 0.0281 - val_loss: 0.0138 - val_mean_absolute_error: 0.0138\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0343 - mean_absolute_error: 0.0343 - val_loss: 0.0182 - val_mean_absolute_error: 0.0182\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0377 - mean_absolute_error: 0.0377 - val_loss: 0.0189 - val_mean_absolute_error: 0.0189\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.0304 - mean_absolute_error: 0.0304 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 6s 48ms/step - loss: 0.0360 - mean_absolute_error: 0.0360 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0293 - mean_absolute_error: 0.0293 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0336 - mean_absolute_error: 0.0336 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0184 - val_mean_absolute_error: 0.0184\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0182 - val_mean_absolute_error: 0.0182\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0160 - val_mean_absolute_error: 0.0160\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 5s 39ms/step - loss: 0.0302 - mean_absolute_error: 0.0302 - val_loss: 0.0118 - val_mean_absolute_error: 0.0118\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0336 - mean_absolute_error: 0.0336 - val_loss: 0.0136 - val_mean_absolute_error: 0.0136\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0407 - mean_absolute_error: 0.0407 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0296 - mean_absolute_error: 0.0296 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "CPU times: user 14min 43s, sys: 49.5 s, total: 15min 32s\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#DATA:\n",
    "#long_input_labels = tensor_labels + grad_labels + vector_labels + param_labels\n",
    "#short_input_labels = invar_labels\n",
    "\n",
    "histories['TBNNModel_changed_branches'] = compile_and_fitTBNN(\n",
    "#histories['TBNNModel'] = compile_and_fit(\n",
    "    TBNNModel_changed_branches,\n",
    "    'TBNNModel_changed_branches',\n",
    "#    [inputs_long, inputs_short],\n",
    "#    train_target,\n",
    "    max_epochs=100)#,\n",
    "    #callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Tensor_input_layer (InputLayer  [(None, 97)]        0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 97)          195         ['Tensor_input_layer[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " First_hidden_layer (Dense)     (None, 64)           6272        ['normalization_1[0][0]']        \n",
      "                                                                                                  \n",
      " Flow_parameters_input_layer (I  [(None, 9)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " Second_hidden_layer (Dense)    (None, 64)           4160        ['First_hidden_layer[0][0]']     \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 9)           19          ['Flow_parameters_input_layer[0][\n",
      " )                                                               0]']                             \n",
      "                                                                                                  \n",
      " Parameters_concatenation (Conc  (None, 73)          0           ['Second_hidden_layer[0][0]',    \n",
      " atenate)                                                         'normalization_2[0][0]']        \n",
      "                                                                                                  \n",
      " Last_hidden_layer (Dense)      (None, 5)            370         ['Parameters_concatenation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,016\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 214\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 6s 44ms/step - loss: 0.7084 - mean_absolute_error: 0.7084 - val_loss: 0.2099 - val_mean_absolute_error: 0.2099\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.5749 - mean_absolute_error: 0.5749 - val_loss: 0.2016 - val_mean_absolute_error: 0.2016\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.5607 - mean_absolute_error: 0.5607 - val_loss: 0.1975 - val_mean_absolute_error: 0.1975\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.5518 - mean_absolute_error: 0.5518 - val_loss: 0.1939 - val_mean_absolute_error: 0.1939\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.5433 - mean_absolute_error: 0.5433 - val_loss: 0.1879 - val_mean_absolute_error: 0.1879\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 5s 41ms/step - loss: 0.5301 - mean_absolute_error: 0.5301 - val_loss: 0.1825 - val_mean_absolute_error: 0.1825\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.5091 - mean_absolute_error: 0.5091 - val_loss: 0.1767 - val_mean_absolute_error: 0.1767\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.4701 - mean_absolute_error: 0.4701 - val_loss: 0.1535 - val_mean_absolute_error: 0.1535\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.3938 - mean_absolute_error: 0.3938 - val_loss: 0.1184 - val_mean_absolute_error: 0.1184\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.2739 - mean_absolute_error: 0.2739 - val_loss: 0.0667 - val_mean_absolute_error: 0.0667\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.1419 - mean_absolute_error: 0.1419 - val_loss: 0.0379 - val_mean_absolute_error: 0.0379\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0886 - mean_absolute_error: 0.0886 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0705 - mean_absolute_error: 0.0705 - val_loss: 0.0400 - val_mean_absolute_error: 0.0400\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0701 - mean_absolute_error: 0.0701 - val_loss: 0.0709 - val_mean_absolute_error: 0.0709\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0560 - mean_absolute_error: 0.0560 - val_loss: 0.0404 - val_mean_absolute_error: 0.0404\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0558 - mean_absolute_error: 0.0558 - val_loss: 0.0133 - val_mean_absolute_error: 0.0133\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0484 - mean_absolute_error: 0.0484 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0491 - mean_absolute_error: 0.0491 - val_loss: 0.0257 - val_mean_absolute_error: 0.0257\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0467 - mean_absolute_error: 0.0467 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0510 - mean_absolute_error: 0.0510 - val_loss: 0.0404 - val_mean_absolute_error: 0.0404\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 5s 38ms/step - loss: 0.0430 - mean_absolute_error: 0.0430 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0461 - mean_absolute_error: 0.0461 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0462 - mean_absolute_error: 0.0462 - val_loss: 0.0286 - val_mean_absolute_error: 0.0286\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0439 - mean_absolute_error: 0.0439 - val_loss: 0.0229 - val_mean_absolute_error: 0.0229\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0413 - mean_absolute_error: 0.0413 - val_loss: 0.0183 - val_mean_absolute_error: 0.0183\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0397 - mean_absolute_error: 0.0397 - val_loss: 0.0277 - val_mean_absolute_error: 0.0277\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0459 - mean_absolute_error: 0.0459 - val_loss: 0.0413 - val_mean_absolute_error: 0.0413\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0441 - mean_absolute_error: 0.0441 - val_loss: 0.0251 - val_mean_absolute_error: 0.0251\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0433 - mean_absolute_error: 0.0433 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0421 - mean_absolute_error: 0.0421 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0396 - mean_absolute_error: 0.0396 - val_loss: 0.0193 - val_mean_absolute_error: 0.0193\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0396 - mean_absolute_error: 0.0396 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0423 - mean_absolute_error: 0.0423 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0367 - mean_absolute_error: 0.0367 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0371 - mean_absolute_error: 0.0371 - val_loss: 0.0287 - val_mean_absolute_error: 0.0287\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0385 - mean_absolute_error: 0.0385 - val_loss: 0.0299 - val_mean_absolute_error: 0.0299\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0397 - mean_absolute_error: 0.0397 - val_loss: 0.0170 - val_mean_absolute_error: 0.0170\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0364 - mean_absolute_error: 0.0364 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0384 - mean_absolute_error: 0.0384 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0377 - mean_absolute_error: 0.0377 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0410 - mean_absolute_error: 0.0410 - val_loss: 0.0181 - val_mean_absolute_error: 0.0181\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0364 - mean_absolute_error: 0.0364 - val_loss: 0.0101 - val_mean_absolute_error: 0.0101\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0411 - mean_absolute_error: 0.0411 - val_loss: 0.0116 - val_mean_absolute_error: 0.0116\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0386 - mean_absolute_error: 0.0386 - val_loss: 0.0103 - val_mean_absolute_error: 0.0103\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 4s 33ms/step - loss: 0.0379 - mean_absolute_error: 0.0379 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0355 - mean_absolute_error: 0.0355 - val_loss: 0.0076 - val_mean_absolute_error: 0.0076\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0366 - mean_absolute_error: 0.0366 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0373 - mean_absolute_error: 0.0373 - val_loss: 0.0263 - val_mean_absolute_error: 0.0263\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0356 - mean_absolute_error: 0.0356 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0365 - mean_absolute_error: 0.0365 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.0357 - mean_absolute_error: 0.0357 - val_loss: 0.0303 - val_mean_absolute_error: 0.0303\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0349 - mean_absolute_error: 0.0349 - val_loss: 0.0174 - val_mean_absolute_error: 0.0174\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0362 - mean_absolute_error: 0.0362 - val_loss: 0.0089 - val_mean_absolute_error: 0.0089\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0395 - mean_absolute_error: 0.0395 - val_loss: 0.0189 - val_mean_absolute_error: 0.0189\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0344 - mean_absolute_error: 0.0344 - val_loss: 0.0340 - val_mean_absolute_error: 0.0340\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0361 - mean_absolute_error: 0.0361 - val_loss: 0.0168 - val_mean_absolute_error: 0.0168\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0344 - mean_absolute_error: 0.0344 - val_loss: 0.0095 - val_mean_absolute_error: 0.0095\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.0375 - mean_absolute_error: 0.0375 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0390 - mean_absolute_error: 0.0390 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0334 - mean_absolute_error: 0.0334 - val_loss: 0.0269 - val_mean_absolute_error: 0.0269\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0351 - mean_absolute_error: 0.0351 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0393 - mean_absolute_error: 0.0393 - val_loss: 0.0186 - val_mean_absolute_error: 0.0186\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0084 - val_mean_absolute_error: 0.0084\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 4s 34ms/step - loss: 0.0361 - mean_absolute_error: 0.0361 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0345 - mean_absolute_error: 0.0345 - val_loss: 0.0184 - val_mean_absolute_error: 0.0184\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0350 - mean_absolute_error: 0.0350 - val_loss: 0.0163 - val_mean_absolute_error: 0.0163\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0409 - val_mean_absolute_error: 0.0409\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0349 - mean_absolute_error: 0.0349 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0357 - mean_absolute_error: 0.0357 - val_loss: 0.0229 - val_mean_absolute_error: 0.0229\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0359 - mean_absolute_error: 0.0359 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0349 - mean_absolute_error: 0.0349 - val_loss: 0.0105 - val_mean_absolute_error: 0.0105\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0334 - mean_absolute_error: 0.0334 - val_loss: 0.0112 - val_mean_absolute_error: 0.0112\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0093 - val_mean_absolute_error: 0.0093\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0233 - val_mean_absolute_error: 0.0233\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0151 - val_mean_absolute_error: 0.0151\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0314 - mean_absolute_error: 0.0314 - val_loss: 0.0132 - val_mean_absolute_error: 0.0132\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0330 - mean_absolute_error: 0.0330 - val_loss: 0.0095 - val_mean_absolute_error: 0.0095\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0334 - mean_absolute_error: 0.0334 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0335 - mean_absolute_error: 0.0335 - val_loss: 0.0107 - val_mean_absolute_error: 0.0107\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0356 - mean_absolute_error: 0.0356 - val_loss: 0.0087 - val_mean_absolute_error: 0.0087\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0371 - mean_absolute_error: 0.0371 - val_loss: 0.0102 - val_mean_absolute_error: 0.0102\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0342 - mean_absolute_error: 0.0342 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0340 - mean_absolute_error: 0.0340 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0329 - mean_absolute_error: 0.0329 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0342 - mean_absolute_error: 0.0342 - val_loss: 0.0135 - val_mean_absolute_error: 0.0135\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0333 - mean_absolute_error: 0.0333 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0337 - mean_absolute_error: 0.0337 - val_loss: 0.0144 - val_mean_absolute_error: 0.0144\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0286 - mean_absolute_error: 0.0286 - val_loss: 0.0100 - val_mean_absolute_error: 0.0100\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 4s 35ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 4s 37ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0112 - val_mean_absolute_error: 0.0112\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0301 - mean_absolute_error: 0.0301 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 4s 36ms/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
      "CPU times: user 13min 38s, sys: 45.4 s, total: 14min 23s\n",
      "Wall time: 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#DATA:\n",
    "#shuffled_data\n",
    "#long_input_labels = tensor_labels + grad_labels + vector_labels + param_labels\n",
    "#short_input_labels = invar_labels\n",
    "\n",
    "TBNNModel_changed_branches_2 = keras.Model(\n",
    "    inputs=[inputs_long, inputs_short],\n",
    "    outputs=outputs,\n",
    ")\n",
    "\n",
    "histories['TBNNModel_changed_branches_2'] = compile_and_fitTBNN(\n",
    "    TBNNModel_changed_branches_2,\n",
    "    'TBNNModel_changed_branches_2',\n",
    "    max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Tensor_input_layer (InputLayer  [(None, 97)]        0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " normalization_4 (Normalization  (None, 97)          195         ['Tensor_input_layer[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " First_hidden_layer (Dense)     (None, 64)           6272        ['normalization_4[3][0]']        \n",
      "                                                                                                  \n",
      " Flow_parameters_input_layer (I  [(None, 9)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " Second_hidden_layer (Dense)    (None, 64)           4160        ['First_hidden_layer[0][0]']     \n",
      "                                                                                                  \n",
      " normalization_5 (Normalization  (None, 9)           19          ['Flow_parameters_input_layer[0][\n",
      " )                                                               0]']                             \n",
      "                                                                                                  \n",
      " Parameters_concatenation (Conc  (None, 73)          0           ['Second_hidden_layer[0][0]',    \n",
      " atenate)                                                         'normalization_5[3][0]']        \n",
      "                                                                                                  \n",
      " Last_hidden_layer (Dense)      (None, 5)            370         ['Parameters_concatenation[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,016\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 214\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "120/120 [==============================] - 8s 61ms/step - loss: 0.7250 - mean_absolute_error: 0.7250 - val_loss: 0.2133 - val_mean_absolute_error: 0.2133\n",
      "Epoch 2/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.5772 - mean_absolute_error: 0.5772 - val_loss: 0.1994 - val_mean_absolute_error: 0.1994\n",
      "Epoch 3/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5622 - mean_absolute_error: 0.5622 - val_loss: 0.1966 - val_mean_absolute_error: 0.1966\n",
      "Epoch 4/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5544 - mean_absolute_error: 0.5544 - val_loss: 0.1938 - val_mean_absolute_error: 0.1938\n",
      "Epoch 5/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5463 - mean_absolute_error: 0.5463 - val_loss: 0.1880 - val_mean_absolute_error: 0.1880\n",
      "Epoch 6/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.5329 - mean_absolute_error: 0.5329 - val_loss: 0.1840 - val_mean_absolute_error: 0.1840\n",
      "Epoch 7/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.5093 - mean_absolute_error: 0.5093 - val_loss: 0.1704 - val_mean_absolute_error: 0.1704\n",
      "Epoch 8/200\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.4621 - mean_absolute_error: 0.4621 - val_loss: 0.1453 - val_mean_absolute_error: 0.1453\n",
      "Epoch 9/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.3740 - mean_absolute_error: 0.3740 - val_loss: 0.1187 - val_mean_absolute_error: 0.1187\n",
      "Epoch 10/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.2432 - mean_absolute_error: 0.2432 - val_loss: 0.0888 - val_mean_absolute_error: 0.0888\n",
      "Epoch 11/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.1315 - mean_absolute_error: 0.1315 - val_loss: 0.0319 - val_mean_absolute_error: 0.0319\n",
      "Epoch 12/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0946 - mean_absolute_error: 0.0946 - val_loss: 0.0428 - val_mean_absolute_error: 0.0428\n",
      "Epoch 13/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0723 - mean_absolute_error: 0.0723 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 14/200\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0607 - mean_absolute_error: 0.0607 - val_loss: 0.0343 - val_mean_absolute_error: 0.0343\n",
      "Epoch 15/200\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.0523 - mean_absolute_error: 0.0523 - val_loss: 0.0169 - val_mean_absolute_error: 0.0169\n",
      "Epoch 16/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0513 - mean_absolute_error: 0.0513 - val_loss: 0.0241 - val_mean_absolute_error: 0.0241\n",
      "Epoch 17/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0503 - mean_absolute_error: 0.0503 - val_loss: 0.0296 - val_mean_absolute_error: 0.0296\n",
      "Epoch 18/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0477 - mean_absolute_error: 0.0477 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 19/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0498 - mean_absolute_error: 0.0498 - val_loss: 0.0368 - val_mean_absolute_error: 0.0368\n",
      "Epoch 20/200\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0489 - mean_absolute_error: 0.0489 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 21/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0454 - mean_absolute_error: 0.0454 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 22/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0433 - mean_absolute_error: 0.0433 - val_loss: 0.0152 - val_mean_absolute_error: 0.0152\n",
      "Epoch 23/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0409 - mean_absolute_error: 0.0409 - val_loss: 0.0285 - val_mean_absolute_error: 0.0285\n",
      "Epoch 24/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0419 - mean_absolute_error: 0.0419 - val_loss: 0.0504 - val_mean_absolute_error: 0.0504\n",
      "Epoch 25/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0451 - mean_absolute_error: 0.0451 - val_loss: 0.0140 - val_mean_absolute_error: 0.0140\n",
      "Epoch 26/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0430 - mean_absolute_error: 0.0430 - val_loss: 0.0368 - val_mean_absolute_error: 0.0368\n",
      "Epoch 27/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0399 - mean_absolute_error: 0.0399 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 28/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0446 - mean_absolute_error: 0.0446 - val_loss: 0.0158 - val_mean_absolute_error: 0.0158\n",
      "Epoch 29/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0451 - mean_absolute_error: 0.0451 - val_loss: 0.0273 - val_mean_absolute_error: 0.0273\n",
      "Epoch 30/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0409 - mean_absolute_error: 0.0409 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 31/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0413 - mean_absolute_error: 0.0413 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 32/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0412 - mean_absolute_error: 0.0412 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 33/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0387 - mean_absolute_error: 0.0387 - val_loss: 0.0327 - val_mean_absolute_error: 0.0327\n",
      "Epoch 34/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0406 - mean_absolute_error: 0.0406 - val_loss: 0.0119 - val_mean_absolute_error: 0.0119\n",
      "Epoch 35/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0389 - mean_absolute_error: 0.0389 - val_loss: 0.0185 - val_mean_absolute_error: 0.0185\n",
      "Epoch 36/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0398 - mean_absolute_error: 0.0398 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 37/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0380 - mean_absolute_error: 0.0380 - val_loss: 0.0293 - val_mean_absolute_error: 0.0293\n",
      "Epoch 38/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0390 - mean_absolute_error: 0.0390 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 39/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0365 - mean_absolute_error: 0.0365 - val_loss: 0.0116 - val_mean_absolute_error: 0.0116\n",
      "Epoch 40/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0364 - mean_absolute_error: 0.0364 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
      "Epoch 41/200\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0393 - mean_absolute_error: 0.0393 - val_loss: 0.0319 - val_mean_absolute_error: 0.0319\n",
      "Epoch 42/200\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0387 - mean_absolute_error: 0.0387 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 43/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0349 - mean_absolute_error: 0.0349 - val_loss: 0.0222 - val_mean_absolute_error: 0.0222\n",
      "Epoch 44/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0342 - mean_absolute_error: 0.0342 - val_loss: 0.0137 - val_mean_absolute_error: 0.0137\n",
      "Epoch 45/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0386 - mean_absolute_error: 0.0386 - val_loss: 0.0182 - val_mean_absolute_error: 0.0182\n",
      "Epoch 46/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0384 - mean_absolute_error: 0.0384 - val_loss: 0.0128 - val_mean_absolute_error: 0.0128\n",
      "Epoch 47/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0365 - mean_absolute_error: 0.0365 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 48/200\n",
      "120/120 [==============================] - 7s 63ms/step - loss: 0.0388 - mean_absolute_error: 0.0388 - val_loss: 0.0264 - val_mean_absolute_error: 0.0264\n",
      "Epoch 49/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0368 - mean_absolute_error: 0.0368 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 50/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0388 - mean_absolute_error: 0.0388 - val_loss: 0.0294 - val_mean_absolute_error: 0.0294\n",
      "Epoch 51/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0369 - mean_absolute_error: 0.0369 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 52/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0249 - val_mean_absolute_error: 0.0249\n",
      "Epoch 53/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0380 - mean_absolute_error: 0.0380 - val_loss: 0.0255 - val_mean_absolute_error: 0.0255\n",
      "Epoch 54/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0366 - mean_absolute_error: 0.0366 - val_loss: 0.0150 - val_mean_absolute_error: 0.0150\n",
      "Epoch 55/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0350 - mean_absolute_error: 0.0350 - val_loss: 0.0143 - val_mean_absolute_error: 0.0143\n",
      "Epoch 56/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0373 - mean_absolute_error: 0.0373 - val_loss: 0.0099 - val_mean_absolute_error: 0.0099\n",
      "Epoch 57/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0244 - val_mean_absolute_error: 0.0244\n",
      "Epoch 58/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0399 - mean_absolute_error: 0.0399 - val_loss: 0.0130 - val_mean_absolute_error: 0.0130\n",
      "Epoch 59/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 60/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 61/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0344 - mean_absolute_error: 0.0344 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
      "Epoch 62/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0360 - mean_absolute_error: 0.0360 - val_loss: 0.0228 - val_mean_absolute_error: 0.0228\n",
      "Epoch 63/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0359 - mean_absolute_error: 0.0359 - val_loss: 0.0176 - val_mean_absolute_error: 0.0176\n",
      "Epoch 64/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0301 - mean_absolute_error: 0.0301 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
      "Epoch 65/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 66/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0146 - val_mean_absolute_error: 0.0146\n",
      "Epoch 67/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0380 - mean_absolute_error: 0.0380 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
      "Epoch 68/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0382 - mean_absolute_error: 0.0382 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 69/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 70/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0351 - mean_absolute_error: 0.0351 - val_loss: 0.0236 - val_mean_absolute_error: 0.0236\n",
      "Epoch 71/200\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0335 - mean_absolute_error: 0.0335 - val_loss: 0.0326 - val_mean_absolute_error: 0.0326\n",
      "Epoch 72/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0391 - mean_absolute_error: 0.0391 - val_loss: 0.0276 - val_mean_absolute_error: 0.0276\n",
      "Epoch 73/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0376 - mean_absolute_error: 0.0376 - val_loss: 0.0271 - val_mean_absolute_error: 0.0271\n",
      "Epoch 74/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0257 - val_mean_absolute_error: 0.0257\n",
      "Epoch 75/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0346 - mean_absolute_error: 0.0346 - val_loss: 0.0237 - val_mean_absolute_error: 0.0237\n",
      "Epoch 76/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0331 - mean_absolute_error: 0.0331 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 77/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0353 - mean_absolute_error: 0.0353 - val_loss: 0.0320 - val_mean_absolute_error: 0.0320\n",
      "Epoch 78/200\n",
      "120/120 [==============================] - 44668s 375s/step - loss: 0.0368 - mean_absolute_error: 0.0368 - val_loss: 0.0250 - val_mean_absolute_error: 0.0250\n",
      "Epoch 79/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0260 - val_mean_absolute_error: 0.0260\n",
      "Epoch 80/200\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0335 - mean_absolute_error: 0.0335 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 81/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0340 - val_mean_absolute_error: 0.0340\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0372 - mean_absolute_error: 0.0372 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 83/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0351 - mean_absolute_error: 0.0351 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 84/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
      "Epoch 85/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0338 - mean_absolute_error: 0.0338 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 86/200\n",
      "120/120 [==============================] - 3857s 32s/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0145 - val_mean_absolute_error: 0.0145\n",
      "Epoch 87/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0328 - mean_absolute_error: 0.0328 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
      "Epoch 88/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0346 - mean_absolute_error: 0.0346 - val_loss: 0.0187 - val_mean_absolute_error: 0.0187\n",
      "Epoch 89/200\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0351 - mean_absolute_error: 0.0351 - val_loss: 0.0247 - val_mean_absolute_error: 0.0247\n",
      "Epoch 90/200\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 91/200\n",
      "120/120 [==============================] - 8s 71ms/step - loss: 0.0332 - mean_absolute_error: 0.0332 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 92/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0366 - mean_absolute_error: 0.0366 - val_loss: 0.0126 - val_mean_absolute_error: 0.0126\n",
      "Epoch 93/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0345 - mean_absolute_error: 0.0345 - val_loss: 0.0292 - val_mean_absolute_error: 0.0292\n",
      "Epoch 94/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0352 - mean_absolute_error: 0.0352 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 95/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0337 - mean_absolute_error: 0.0337 - val_loss: 0.0181 - val_mean_absolute_error: 0.0181\n",
      "Epoch 96/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0353 - mean_absolute_error: 0.0353 - val_loss: 0.0221 - val_mean_absolute_error: 0.0221\n",
      "Epoch 97/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
      "Epoch 98/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 99/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0128 - val_mean_absolute_error: 0.0128\n",
      "Epoch 100/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0104 - val_mean_absolute_error: 0.0104\n",
      "Epoch 101/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0341 - mean_absolute_error: 0.0341 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 102/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0319 - mean_absolute_error: 0.0319 - val_loss: 0.0094 - val_mean_absolute_error: 0.0094\n",
      "Epoch 103/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
      "Epoch 104/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0329 - mean_absolute_error: 0.0329 - val_loss: 0.0118 - val_mean_absolute_error: 0.0118\n",
      "Epoch 105/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0188 - val_mean_absolute_error: 0.0188\n",
      "Epoch 106/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0351 - mean_absolute_error: 0.0351 - val_loss: 0.0331 - val_mean_absolute_error: 0.0331\n",
      "Epoch 107/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0159 - val_mean_absolute_error: 0.0159\n",
      "Epoch 108/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0107 - val_mean_absolute_error: 0.0107\n",
      "Epoch 109/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0298 - mean_absolute_error: 0.0298 - val_loss: 0.0253 - val_mean_absolute_error: 0.0253\n",
      "Epoch 110/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 111/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "Epoch 112/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 113/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0338 - mean_absolute_error: 0.0338 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 114/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0325 - mean_absolute_error: 0.0325 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 115/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0325 - mean_absolute_error: 0.0325 - val_loss: 0.0181 - val_mean_absolute_error: 0.0181\n",
      "Epoch 116/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0254 - val_mean_absolute_error: 0.0254\n",
      "Epoch 117/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0288 - mean_absolute_error: 0.0288 - val_loss: 0.0105 - val_mean_absolute_error: 0.0105\n",
      "Epoch 118/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0301 - mean_absolute_error: 0.0301 - val_loss: 0.0187 - val_mean_absolute_error: 0.0187\n",
      "Epoch 119/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0345 - mean_absolute_error: 0.0345 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
      "Epoch 120/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0126 - val_mean_absolute_error: 0.0126\n",
      "Epoch 121/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0181 - val_mean_absolute_error: 0.0181\n",
      "Epoch 122/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0312 - mean_absolute_error: 0.0312 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "Epoch 123/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0327 - mean_absolute_error: 0.0327 - val_loss: 0.0114 - val_mean_absolute_error: 0.0114\n",
      "Epoch 124/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0177 - val_mean_absolute_error: 0.0177\n",
      "Epoch 125/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0090 - val_mean_absolute_error: 0.0090\n",
      "Epoch 126/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0299 - mean_absolute_error: 0.0299 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 127/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0334 - mean_absolute_error: 0.0334 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
      "Epoch 128/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 129/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0334 - mean_absolute_error: 0.0334 - val_loss: 0.0104 - val_mean_absolute_error: 0.0104\n",
      "Epoch 130/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0079 - val_mean_absolute_error: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0298 - mean_absolute_error: 0.0298 - val_loss: 0.0189 - val_mean_absolute_error: 0.0189\n",
      "Epoch 132/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0324 - mean_absolute_error: 0.0324 - val_loss: 0.0166 - val_mean_absolute_error: 0.0166\n",
      "Epoch 133/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0301 - mean_absolute_error: 0.0301 - val_loss: 0.0074 - val_mean_absolute_error: 0.0074\n",
      "Epoch 134/200\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 135/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0348 - mean_absolute_error: 0.0348 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
      "Epoch 136/200\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0335 - mean_absolute_error: 0.0335 - val_loss: 0.0175 - val_mean_absolute_error: 0.0175\n",
      "Epoch 137/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0135 - val_mean_absolute_error: 0.0135\n",
      "Epoch 138/200\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
      "Epoch 139/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0326 - mean_absolute_error: 0.0326 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 140/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0346 - mean_absolute_error: 0.0346 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 141/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0270 - mean_absolute_error: 0.0270 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
      "Epoch 142/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0269 - mean_absolute_error: 0.0269 - val_loss: 0.0136 - val_mean_absolute_error: 0.0136\n",
      "Epoch 143/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0296 - mean_absolute_error: 0.0296 - val_loss: 0.0105 - val_mean_absolute_error: 0.0105\n",
      "Epoch 144/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0301 - mean_absolute_error: 0.0301 - val_loss: 0.0179 - val_mean_absolute_error: 0.0179\n",
      "Epoch 145/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0322 - mean_absolute_error: 0.0322 - val_loss: 0.0191 - val_mean_absolute_error: 0.0191\n",
      "Epoch 146/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0321 - mean_absolute_error: 0.0321 - val_loss: 0.0106 - val_mean_absolute_error: 0.0106\n",
      "Epoch 147/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0095 - val_mean_absolute_error: 0.0095\n",
      "Epoch 148/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0182 - val_mean_absolute_error: 0.0182\n",
      "Epoch 149/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0299 - mean_absolute_error: 0.0299 - val_loss: 0.0108 - val_mean_absolute_error: 0.0108\n",
      "Epoch 150/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0297 - mean_absolute_error: 0.0297 - val_loss: 0.0161 - val_mean_absolute_error: 0.0161\n",
      "Epoch 151/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0306 - mean_absolute_error: 0.0306 - val_loss: 0.0149 - val_mean_absolute_error: 0.0149\n",
      "Epoch 152/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0307 - mean_absolute_error: 0.0307 - val_loss: 0.0077 - val_mean_absolute_error: 0.0077\n",
      "Epoch 153/200\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0117 - val_mean_absolute_error: 0.0117\n",
      "Epoch 154/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0313 - mean_absolute_error: 0.0313 - val_loss: 0.0300 - val_mean_absolute_error: 0.0300\n",
      "Epoch 155/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0155 - val_mean_absolute_error: 0.0155\n",
      "Epoch 156/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0310 - mean_absolute_error: 0.0310 - val_loss: 0.0256 - val_mean_absolute_error: 0.0256\n",
      "Epoch 157/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0316 - mean_absolute_error: 0.0316 - val_loss: 0.0283 - val_mean_absolute_error: 0.0283\n",
      "Epoch 158/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0318 - mean_absolute_error: 0.0318 - val_loss: 0.0121 - val_mean_absolute_error: 0.0121\n",
      "Epoch 159/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0270 - mean_absolute_error: 0.0270 - val_loss: 0.0123 - val_mean_absolute_error: 0.0123\n",
      "Epoch 160/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0286 - mean_absolute_error: 0.0286 - val_loss: 0.0252 - val_mean_absolute_error: 0.0252\n",
      "Epoch 161/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0315 - mean_absolute_error: 0.0315 - val_loss: 0.0168 - val_mean_absolute_error: 0.0168\n",
      "Epoch 162/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0304 - mean_absolute_error: 0.0304 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
      "Epoch 163/200\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0282 - mean_absolute_error: 0.0282 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
      "Epoch 164/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0293 - mean_absolute_error: 0.0293 - val_loss: 0.0102 - val_mean_absolute_error: 0.0102\n",
      "Epoch 165/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0320 - mean_absolute_error: 0.0320 - val_loss: 0.0147 - val_mean_absolute_error: 0.0147\n",
      "Epoch 166/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0299 - mean_absolute_error: 0.0299 - val_loss: 0.0157 - val_mean_absolute_error: 0.0157\n",
      "Epoch 167/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0293 - mean_absolute_error: 0.0293 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
      "Epoch 168/200\n",
      "120/120 [==============================] - 7s 59ms/step - loss: 0.0282 - mean_absolute_error: 0.0282 - val_loss: 0.0154 - val_mean_absolute_error: 0.0154\n",
      "Epoch 169/200\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0305 - mean_absolute_error: 0.0305 - val_loss: 0.0152 - val_mean_absolute_error: 0.0152\n",
      "Epoch 170/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0282 - mean_absolute_error: 0.0282 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 171/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0296 - mean_absolute_error: 0.0296 - val_loss: 0.0106 - val_mean_absolute_error: 0.0106\n",
      "Epoch 172/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0288 - mean_absolute_error: 0.0288 - val_loss: 0.0127 - val_mean_absolute_error: 0.0127\n",
      "Epoch 173/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0295 - mean_absolute_error: 0.0295 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 174/200\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0260 - mean_absolute_error: 0.0260 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 175/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0292 - mean_absolute_error: 0.0292 - val_loss: 0.0307 - val_mean_absolute_error: 0.0307\n",
      "Epoch 176/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0311 - mean_absolute_error: 0.0311 - val_loss: 0.0322 - val_mean_absolute_error: 0.0322\n",
      "Epoch 177/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0291 - mean_absolute_error: 0.0291 - val_loss: 0.0111 - val_mean_absolute_error: 0.0111\n",
      "Epoch 178/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0255 - mean_absolute_error: 0.0255 - val_loss: 0.0172 - val_mean_absolute_error: 0.0172\n",
      "Epoch 179/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0317 - mean_absolute_error: 0.0317 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200\n",
      "120/120 [==============================] - 7s 58ms/step - loss: 0.0308 - mean_absolute_error: 0.0308 - val_loss: 0.0173 - val_mean_absolute_error: 0.0173\n",
      "Epoch 181/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0279 - mean_absolute_error: 0.0279 - val_loss: 0.0122 - val_mean_absolute_error: 0.0122\n",
      "Epoch 182/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0309 - mean_absolute_error: 0.0309 - val_loss: 0.0138 - val_mean_absolute_error: 0.0138\n",
      "Epoch 183/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0282 - mean_absolute_error: 0.0282 - val_loss: 0.0109 - val_mean_absolute_error: 0.0109\n",
      "Epoch 184/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0297 - mean_absolute_error: 0.0297 - val_loss: 0.0162 - val_mean_absolute_error: 0.0162\n",
      "Epoch 185/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0285 - mean_absolute_error: 0.0285 - val_loss: 0.0124 - val_mean_absolute_error: 0.0124\n",
      "Epoch 186/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0276 - mean_absolute_error: 0.0276 - val_loss: 0.0245 - val_mean_absolute_error: 0.0245\n",
      "Epoch 187/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0268 - mean_absolute_error: 0.0268 - val_loss: 0.0115 - val_mean_absolute_error: 0.0115\n",
      "Epoch 188/200\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.0282 - mean_absolute_error: 0.0282 - val_loss: 0.0165 - val_mean_absolute_error: 0.0165\n",
      "Epoch 189/200\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0275 - mean_absolute_error: 0.0275 - val_loss: 0.0110 - val_mean_absolute_error: 0.0110\n",
      "Epoch 190/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0286 - mean_absolute_error: 0.0286 - val_loss: 0.0129 - val_mean_absolute_error: 0.0129\n",
      "Epoch 191/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0292 - mean_absolute_error: 0.0292 - val_loss: 0.0141 - val_mean_absolute_error: 0.0141\n",
      "Epoch 192/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0296 - mean_absolute_error: 0.0296 - val_loss: 0.0092 - val_mean_absolute_error: 0.0092\n",
      "Epoch 193/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0289 - mean_absolute_error: 0.0289 - val_loss: 0.0125 - val_mean_absolute_error: 0.0125\n",
      "Epoch 194/200\n",
      "120/120 [==============================] - 6s 53ms/step - loss: 0.0325 - mean_absolute_error: 0.0325 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 195/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0273 - mean_absolute_error: 0.0273 - val_loss: 0.0104 - val_mean_absolute_error: 0.0104\n",
      "Epoch 196/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0268 - mean_absolute_error: 0.0268 - val_loss: 0.0113 - val_mean_absolute_error: 0.0113\n",
      "Epoch 197/200\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.0323 - mean_absolute_error: 0.0323 - val_loss: 0.0119 - val_mean_absolute_error: 0.0119\n",
      "Epoch 198/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0255 - mean_absolute_error: 0.0255 - val_loss: 0.0093 - val_mean_absolute_error: 0.0093\n",
      "Epoch 199/200\n",
      "120/120 [==============================] - 6s 54ms/step - loss: 0.0294 - mean_absolute_error: 0.0294 - val_loss: 0.0171 - val_mean_absolute_error: 0.0171\n",
      "Epoch 200/200\n",
      "120/120 [==============================] - 7s 56ms/step - loss: 0.0261 - mean_absolute_error: 0.0261 - val_loss: 0.0139 - val_mean_absolute_error: 0.0139\n",
      "CPU times: user 39min 52s, sys: 2min 23s, total: 42min 15s\n",
      "Wall time: 13h 51min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#DATA:\n",
    "#shuffled_data\n",
    "#long_input_labels = tensor_labels + grad_labels + vector_labels + param_labels\n",
    "#short_input_labels = invar_labels\n",
    "\n",
    "TBNNModel_changed_branches_3 = keras.Model(\n",
    "    inputs=[inputs_long_, inputs_short_],\n",
    "    outputs=outputs,\n",
    ")\n",
    "\n",
    "histories['TBNNModel_changed_branches_3'] = compile_and_fit(\n",
    "    TBNNModel_changed_branches_3,\n",
    "    'TBNNModel_changed_branches_3',\n",
    "    [train_features_long, train_features_short],\n",
    "    train_target,\n",
    "    k = 1,\n",
    "    max_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Flow_parameters_input_layer, Tensor_input_layer with unsupported characters which will be renamed to flow_parameters_input_layer, tensor_input_layer in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/TBNNModel_shuffled_data/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/TBNNModel_shuffled_data/assets\n"
     ]
    }
   ],
   "source": [
    "#TBNNModel.save('saved_model/TBNNModel_shuffled_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBNNModel_prediction_prepared = preparePrediction(TBNNModel_prediction, testData)\n",
    "writePrediction(TBNNModel_prediction_prepared[['dU0', 'dU1', 'dU2']], 'vector', testTSL, MLturbRANSfolder ,'dU')\n",
    "writePrediction(TBNNModel_prediction_prepared[['dp']], 'scalar', testTSL, MLturbRANSfolder ,'dp')\n",
    "writePrediction(TBNNModel_prediction_prepared[['dAW']], 'scalar', testTSL, MLturbRANSfolder ,'dAW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['TBNNModel_shuffled_data'] = TBNNModel.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TBNNModel_shuffled_data</th>\n",
       "      <td>0.287408</td>\n",
       "      <td>0.287408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_shuffled_data_train_check</th>\n",
       "      <td>0.288300</td>\n",
       "      <td>0.288300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel</th>\n",
       "      <td>0.424738</td>\n",
       "      <td>0.424738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_train_check</th>\n",
       "      <td>0.426027</td>\n",
       "      <td>0.426027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_changed_branches</th>\n",
       "      <td>0.040257</td>\n",
       "      <td>0.040257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_changed_branches_train_check</th>\n",
       "      <td>0.039990</td>\n",
       "      <td>0.039990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0         1\n",
       "TBNNModel_shuffled_data                 0.287408  0.287408\n",
       "TBNNModel_shuffled_data_train_check     0.288300  0.288300\n",
       "TBNNModel                               0.424738  0.424738\n",
       "TBNNModel_train_check                   0.426027  0.426027\n",
       "TBNNModel_changed_branches              0.040257  0.040257\n",
       "TBNNModel_changed_branches_train_check  0.039990  0.039990"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TBNNModel_changed_branches_2</th>\n",
       "      <td>0.033976</td>\n",
       "      <td>0.033976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_changed_branches_2_train_check</th>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.034008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_changed_branches_3</th>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.027513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBNNModel_changed_branches_3_train_check</th>\n",
       "      <td>0.027574</td>\n",
       "      <td>0.027574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0         1\n",
       "TBNNModel_changed_branches_2              0.033976  0.033976\n",
       "TBNNModel_changed_branches_2_train_check  0.034008  0.034008\n",
       "TBNNModel_changed_branches_3              0.027513  0.027513\n",
       "TBNNModel_changed_branches_3_train_check  0.027574  0.027574"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['TBNNModel_shuffled_data_train_check'] = TBNNModel.evaluate(\n",
    "    [train_features_long, train_features_short],\n",
    "    train_target,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['TBNNModel'] = TBNNModel.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)\n",
    "full_dnn_models['TBNNModel_train_check'] = TBNNModel.evaluate(\n",
    "    [train_features_long, train_features_short],\n",
    "    train_target,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['TBNNModel_changed_branches'] = TBNNModel_changed_branches.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)\n",
    "full_dnn_models['TBNNModel_changed_branches_train_check'] = TBNNModel_changed_branches.evaluate(\n",
    "    [train_features_long, train_features_short],\n",
    "    train_target,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['TBNNModel_changed_branches_2'] = TBNNModel_changed_branches_2.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)\n",
    "full_dnn_models['TBNNModel_changed_branches_2_train_check'] = TBNNModel_changed_branches_2.evaluate(\n",
    "    [train_features_long, train_features_short],\n",
    "    train_target,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['TBNNModel_changed_branches_3'] = TBNNModel_changed_branches_3.evaluate(\n",
    "    [test_features_long, test_features_short],\n",
    "    test_target,\n",
    "    verbose=0)\n",
    "full_dnn_models['TBNNModel_changed_branches_3_train_check'] = TBNNModel_changed_branches_3.evaluate(\n",
    "    [train_features_long, train_features_short],\n",
    "    train_target,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "#plt.ylim([0., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "#plt.ylim([0., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p saved_model\n",
    "#lnModel.save('lnModel.h5')\n",
    "#lnModel = load_model('lnModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def TBNNModel_optimizer(hp):\n",
    "#    hp_units1 = hp.Int('units1', min_value=8, max_value=80, step=8)\n",
    "#    hp_units2 = hp.Int('units2', min_value=8, max_value=80, step=8)\n",
    "#    #hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "#    hp_activation = hp.Choice('activation', values=['elu', 'relu'])\n",
    "#    \n",
    "#    inputs_no_tensors = keras.Input(shape=(len(train_features_no_tensors.columns),),\n",
    "#                                    name='Flow_parameters_input_layer')\n",
    "#    inputs_tensors = keras.Input(shape=(len(train_features_tensors.columns),),\n",
    "#                                 name='Tensor_input_layer')\n",
    "#    norm_no_tensors = normalizer_no_tensors(inputs_no_tensors)\n",
    "#    norm_tensors = normalizer_tensors(inputs_tensors)\n",
    "#    denseLayer1 = layers.Dense(units=hp_units1,\n",
    "#                               activation=hp_activation,\n",
    "#                               name='First_hidden_layer')(norm_no_tensors)\n",
    "#    denseLayer2 = layers.Dense(units=hp_units2,\n",
    "#                               activation=hp_activation,\n",
    "#                               name='Second_hidden_layer')(denseLayer1)\n",
    "#    concat = layers.concatenate([denseLayer2, norm_tensors],\n",
    "#                            name='Parameters_concatenation')\n",
    "#    outputs = layers.Dense(len(train_labels.columns), name='Last_hidden_layer')(concat)\n",
    "#    TBNNModel = keras.Model(\n",
    "#        inputs=[inputs_no_tensors, inputs_tensors],\n",
    "#        outputs=outputs,\n",
    "#    )\n",
    "#    \n",
    "#    TBNNModel.compile(\n",
    "#        optimizer=get_optimizer(),\n",
    "#        #optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "#        #optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "#        loss='mean_absolute_error',\n",
    "#        metrics=[tf.keras.metrics.MeanAbsoluteError(name='mean_absolute_error')])\n",
    "#    return TBNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner = kt.Hyperband(TBNNModel_optimizer,\n",
    "#                     objective='val_loss',\n",
    "#                     max_epochs=10,\n",
    "#                     factor=3,\n",
    "#                     directory='TBNNModelHpTuning',\n",
    "#                     project_name='TBNNModelHpBest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#tuner.search(\n",
    "#    [train_features_no_tensors, train_features_tensors],\n",
    "#    train_labels,\n",
    "#    epochs=50,\n",
    "#    validation_split=0.2,\n",
    "#    callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "#best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "#\n",
    "#print(f\"\"\"\n",
    "#The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "#layer is {best_hps.get('units1')}, the optimal number of units in the second densely-connected\n",
    "#layer is {best_hps.get('units2')}, the optimal activation function\n",
    "#is {best_hps.get('activation')}.\n",
    "#\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#TBNNModelHpBest = tuner.hypermodel.build(best_hps)\n",
    "#histories['TBNNModelHpBest'] = TBNNModelHpBest.fit(\n",
    "#    [train_features_no_tensors, train_features_tensors],\n",
    "#    train_labels,\n",
    "#    epochs=50,\n",
    "#    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_model_1 = keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(N_LABELS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "histories['full_dnn_model_1'] = compile_and_fit(\n",
    "    full_dnn_model_1,\n",
    "    'full_dnn_model_1',\n",
    "    max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['full_dnn_model_1'] = full_dnn_model_1.evaluate(\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_model_2 = keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(N_LABELS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "histories['full_dnn_model_2'] = compile_and_fit(\n",
    "    full_dnn_model_2,\n",
    "    'full_dnn_model_2',\n",
    "    max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['full_dnn_model_2'] = full_dnn_model_2.evaluate(\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_model_3 = keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(N_LABELS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "histories['full_dnn_model_3'] = compile_and_fit(\n",
    "    full_dnn_model_3,\n",
    "    'full_dnn_model_3',\n",
    "    max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['full_dnn_model_3'] = full_dnn_model_3.evaluate(\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_model_4 = keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(N_LABELS)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "histories['full_dnn_model_4'] = compile_and_fit(\n",
    "    full_dnn_model_4,\n",
    "    'full_dnn_model_4',\n",
    "    max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['full_dnn_model_4'] = full_dnn_model_4.evaluate(\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerMultiplication(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(LayerMultiplication, self).__init__()\n",
    "        self.units = units\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name='w')\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name='b')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.math.exp(tf.matmul(tf.math.log(tf.maximum(inputs, -2)+3), self.w) + self.b)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"w\": self.w,\n",
    "            \"b\": self.b,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_UPAW = tf.keras.layers.Normalization(axis=-1, mean=mean_UPAW, variance=var_UPAW)\n",
    "normalizer_SR = tf.keras.layers.Normalization(axis=-1, mean=mean_SR, variance=var_SR)\n",
    "normalizer_UPAWSR = tf.keras.layers.Normalization(axis=-1, mean=mean_UPAWSR, variance=var_UPAWSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lnModel\n",
    "inputs_UPAWSR = keras.Input(shape=(len(train_features_UPAWSR.columns),))\n",
    "norm_UPAWSR = normalizer_UPAWSR(inputs_UPAWSR)\n",
    "multiplication = LayerMultiplication(len(train_features_UPAWSR.columns))(norm_UPAWSR)\n",
    "linMembers = layers.concatenate([norm_UPAWSR, multiplication])\n",
    "denseLayer1 = layers.Dense(64)(linMembers)\n",
    "denseLayer2 = layers.Dense(64)(denseLayer1)\n",
    "#denseLayer3 = layers.Dense(64)(denseLayer2)\n",
    "outputs = layers.Dense(len(train_labels.columns))(denseLayer2)\n",
    "lnModel = keras.Model(\n",
    "    inputs=inputs_UPAWSR,\n",
    "    outputs=outputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_UPAWSR.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(lnModel, \"multi_input_and_output_model.png\", show_layer_names=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "histories['lnModel'] = compile_and_fit(\n",
    "    lnModel,\n",
    "    'lnModel',\n",
    "    train_features=train_features_UPAWSR,\n",
    "    train_labels=train_labels,\n",
    "    max_epochs=50)#,\n",
    "    #callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dnn_models['lnModel'] = lnModel.evaluate(\n",
    "    test_features_UPAWSR,\n",
    "    test_labels,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'mean_absolute_error')\n",
    "plotter.plot(histories)\n",
    "plt.ylim([0., 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_dnn_models).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#full_dnn_model_3_prediction = pd.DataFrame(\n",
    "#    data=full_dnn_model_3.predict(test_center_features),\n",
    "#    columns=test_center_labels.columns)\n",
    "#full_dnn_model_3_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#TBNNModel_prediction = pd.DataFrame(\n",
    "#    data=TBNNModel.predict(test_center_features),\n",
    "#    columns=test_center_labels.columns)\n",
    "#full_dnn_model_3_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_dnn_model_3_prediction_prepared = preparePrediction(full_dnn_model_3_prediction, testCenterData)\n",
    "#writePrediction(full_dnn_model_3_prediction_prepared[['dU0', 'dU1', 'dU2']], 'vector', testCenterTSL, MLturbRANSfolder ,'dU')\n",
    "#writePrediction(full_dnn_model_3_prediction_prepared[['dp']], 'scalar', testCenterTSL, MLturbRANSfolder ,'dp')\n",
    "#writePrediction(full_dnn_model_3_prediction_prepared[['dAW']], 'scalar', testCenterTSL, MLturbRANSfolder ,'dAW')\n",
    "\n",
    "#TBNNModel_prediction_prepared = preparePrediction(TBNNModel_prediction, testCenterData)\n",
    "#writePrediction(TBNNModel_prediction_prepared[['dU0', 'dU1', 'dU2']], 'vector', testCenterTSL, MLturbRANSfolder ,'dU')\n",
    "#writePrediction(TBNNModel_prediction_prepared[['dp']], 'scalar', testCenterTSL, MLturbRANSfolder ,'dp')\n",
    "#writePrediction(TBNNModel_prediction_prepared[['dAW']], 'scalar', testCenterTSL, MLturbRANSfolder ,'dAW')\n",
    "\n",
    "#testKECenterDataPrepared = prepareInit(testKECenterData)\n",
    "#writePrediction(testKECenterData[['dU0', 'dU1', 'dU2']], 'vector', testCenterTSL, KEturbRANSfolder ,'dU')\n",
    "#writePrediction(testKECenterData[['dp']], 'scalar', testCenterTSL, KEturbRANSfolder ,'dp')\n",
    "#writePrediction(testKECenterData[['dAW']], 'scalar', testCenterTSL, KEturbRANSfolder ,'dAW')\n",
    "\n",
    "#testKWCenterDataPrepared = prepareInit(testKWCenterData)\n",
    "#writePrediction(testKWCenterData[['dU0', 'dU1', 'dU2']], 'vector', testCenterTSL, KWturbRANSfolder ,'dU')\n",
    "#writePrediction(testKWCenterData[['dp']], 'scalar', testCenterTSL, KWturbRANSfolder ,'dp')\n",
    "#writePrediction(testKWCenterData[['dAW']], 'scalar', testCenterTSL, KWturbRANSfolder ,'dAW')\n",
    "\n",
    "#print(testCenterTSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testKECenterData.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testKWCenterData.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBNNModel_prediction_prepared.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
